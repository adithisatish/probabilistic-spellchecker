{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 276 Programming Assignment 2: Spelling Corrector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Overview\n",
    "\n",
    "In this assignment, we will build a probabilistic spelling corrector to automatically correct errors in queries. More formally, given a (possibly corrupt) raw query $R$, our goal is to find the intended query $Q$ which maximizes the probability $P(Q\\mid R)$. That is, we want to guess the query which the user probably meant to submit. By Bayes' Theorem we have\n",
    "$$\n",
    "    P(Q\\mid R) = \\frac{P(R\\mid Q)P(Q)}{P(R)}\\propto P(R\\mid Q)P(Q).\n",
    "$$\n",
    "Since our goal is to find the value of $Q$ which maximizes $P(Q\\mid R)$, this shows it is sufficient to maximize $P(R\\mid Q)P(Q)$. With the above formulation in mind, we will build a probabilistic spelling corrector consisting of 4 parts:\n",
    "  1. **Language Model.**\n",
    "      Estimates the prior distribution of unigrams and bigrams, allowing us to estimate $P(Q)$. We will use maximum-likelihood estimation, which counts the occurrences of token unigrams and bigrams in the training corpus in order to determine their prior probabilities.\n",
    "  2. **Edit Probability Model.**\n",
    "      Estimates the likelihood of errors that may occur in a query, which allows us to estimate $P(R\\mid Q)$. In particular, this component estimates the probability of characters being mistakenly deleted, inserted, substituted, or transposed in a query term.\n",
    "  3. **Candidate Generator.**\n",
    "      Takes a raw query $R$ submitted by the user, and generates candidates for $Q$.\n",
    "  4. **Candidate Scorer.**\n",
    "      Combines (1), (2), and (3) to compute $Q^{*} = \\arg\\max_{Q}P(Q\\mid R)$. That is, for each $Q$ generated by the candidate generator, the scorer uses the language model to estimate $P(Q)$ and uses the edit probability model to estimate $P(R\\mid Q)$, and finally chooses $Q$ which maximizes $P(Q)P(R\\mid Q)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Assignment Details\n",
    "\n",
    "The assignment is due at **4:00 PM PST on Tuesday, May 7th, 2019**. We have split the assignment up into the following parts:\n",
    "  1. [Task 1: Spelling Correction with Uniform Edit Costs](#uniform): **55%** of your total grade for this assignment depends on a correctly implemented solution for task 1. Your solution will be evaluated on a hidden test set, and full credit will be given to models that are within 1% of the staff implementation's test-set accuracy or higher. We do not publish the test set queries or our accuracy on the test set. However, as a guideline for performance, the staff implementation with uniform edit probability model gets **82.42% on the dev set.** We will give partial credit on a non-linear scale (which disproportionately favors models that are closer to our threshold for full credit, as an encouragement to squeeze out more performance improvements).\n",
    "  2. [Task 2: Spelling Correction with Empirical Edit Costs](#empirical): **25%** of your total grade is based on your implementation of task 2. Full credit will be granted for accuracy levels within 1% of the staff implementation's test-set accuracy or higher. Again, we do not publish our test set accuracy, but the staff implementation with empirical edit probability model gets **87.91% on the dev set.** As with Task 1, we will give partial for lower accuracy levels, we will give partial credit on a non-linear scale, with credit accruing more rapidly as your solution gets closer to the target.\n",
    "  3. [Written Report](#written): **20%** of your grade is based on the 1-2 page report that you will submit through Gradescope. See [Section VI](#written) for instructions and grading breakdown.\n",
    "  4. [Extra Credit (Optional)](#extra): **Up to 10%** extra credit will be awarded for implementing extensions, with an explanation in the report. It is not necessary for the extensions to radically improve accuracy to get credit. As described in [Section VII](#extra), you can also get a small amount of extra credit if your system is a top performer in terms of accuracy or running time.\n",
    "\n",
    "The submission procedure is the same as in PA1, but we repeat the instructions here for your reference:\n",
    "  - This assignment should be done in teams of two or individually. Assignments are graded the same for one and two person teams.\n",
    "  - The notebook will automatically generate Python files in `submission` folder. To submit your assignment, **upload the Python files to the PA2-code assignment on Gradescope.** Note that you need to upload all the individual files in the `submission` folder without zipping it.\n",
    "  - While solving the assignment, do **NOT** change class and method names, otherwise the autograder tests will fail.\n",
    "  - You'll also have to **upload a PDF version of the notebook (which would be primarily used to grade your report section of the notebook) to PA2-PDF assignment on Gradescope.** Note that directly converting the PDF truncates code cells. To get a usable PDF version, first click on `File > Print Preview`, which will open in a new tab, then print to PDF using your browser's print functionality.\n",
    "  - After uploading the PDF make sure you tag all the relevant pages to each question. We reserve the right to penalize for mistagged submissions.\n",
    "  - If you are solving the assignment in a team of two, add the other student as a group member after submitting the assignment. Do **NOT** submit the same assignment twice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Note on Numerical Stability\n",
    "\n",
    "Many of the probabilities we will encounter in this assignment are very small. When we multiply many small numbers together, there is a risk of [underﬂow](https://en.wikipedia.org/wiki/Arithmetic_underflow). Therefore, it is common practice to perform this type of probability calculation in log space. Recall that:\n",
    "  1. The log function is monotonically increasing, therefore $\\arg\\max p = \\arg\\max\\log p$.\n",
    "  2. We have $\\log(pq) = \\log p + \\log q$, and by extension $\\log\\left(\\prod_{i} p_i\\right) = \\sum_{i}\\log p_i$.\n",
    "\n",
    "As a result, if we want to maximize $P(\\textbf{x}) = P(x_1)P(x_2)\\cdots P(x_n)$, we can equivalently maximize $\\log P(\\textbf{x}) = \\log P(x_1) + \\log P(x_2) + \\cdots + \\log P(x_n)$. **For numerical stability, we recommend that you use this log-space formulation throughout the assignment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dataset\"></a>\n",
    "## III. Dataset\n",
    "\n",
    "The dataset you will be working with for this assignment is available as a zip file at [this link](http://web.stanford.edu/class/cs276/pa/pa2-data.zip). The unzipped data directory will contain the following subdirectories:\n",
    "  - **Language Modeling Morpus (`pa2-data/corpus/`).** 99,904 documents crawled from the stanford.edu domain. The corpus is organized in a block structure found at `pa2-data/corpus/`, where you'll find 10 files. Each line in a file represents the text of a single document. You will use the tokens in these documents to build a language model.\n",
    "  - **Query Training Set (`pa2-data/training_set/`).** 819,722 pairs of misspelled queries and their corresponding corrected versions, with each pair separated by an edit distance of at most one. The two queries are tab-separated in the file `pa2-data/training_set/edit1s.txt`. You will use this data to build a probability model for the \"noisy channel\" of spelling errors.\n",
    "  - **Query Dev Set (`pa2-data/dev_set`).** 455 pairs of misspelled and corrected queries, which you will use to measure the performance of your model.  There are three files in `pa2-data/dev_set/`: the (possibly) misspelled queries are in `queries.txt`, corrected versions are in `gold.txt`, and Google's suggested spelling corrections are in `google.txt`.\n",
    "  \n",
    "Run the following code blocks to import packages, download, and unzip the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autograding_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%tee submission/imports.py\n",
    "\n",
    "# Import modules\n",
    "import math\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "# from numpy import argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='uniform'></a>\n",
    "## IV. Task 1: Spelling Correction with Uniform Edit Costs (55%)\n",
    "\n",
    "### IV.1. Language Model\n",
    "\n",
    "We will now build a language model to estimate $P(Q)$ from the training corpus. We will treat $Q$ as a sequence of terms $(w_1, \\ldots, w_n)$ whose probability is computed as\n",
    "$$\n",
    "P(w_1, \\ldots, w_n) = P(w_1)P(w_2\\mid w_1)\\cdots P(w_n\\mid w_{n-1}),\n",
    "$$\n",
    "where $P(w_1)$ is the unigram probability of term $w_1$, and $P(w_{i}\\mid w_{i-1})$ is the bigram probability of $(w_{i-1}, w_i)$ for $i \\in \\{2, \\ldots, n\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV.1.1. Calculating Unigram and Bigram Probabilities\n",
    "\n",
    "Our language model will use the maximum likelihood estimates (MLE) for both probabilities, which turn out to be their observed frequencies:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    P_{\\text{MLE}}(w_i) & = \\frac{\\texttt{count}(w_i)}{T},\n",
    "    &\n",
    "    P_{\\text{MLE}}(w_i\\mid w_{i-1}) & = \\frac{\\texttt{count}((w_{i}, w_{i-1}))}{\\texttt{count}(w_{i-1})},\n",
    "\\end{align*}\n",
    "$$\n",
    "where $T$ is the total number of tokens in our corpus, and where $\\texttt{count}$ simply counts occurrences of unigrams or bigrams in the corpus. In summary, computing unigram probabilities $P(w_i)$ and bigram probabilities $P(w_{i}\\mid w_{i-1})$ is a simple matter of counting the unigrams and bigrams that appear throughout the corpus.\n",
    "\n",
    "Fill out the following code block to count the unigrams and bigrams in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%tee submission/language_model_part1.py\n",
    "\n",
    "class LanguageModel:\n",
    "    \"\"\"Models prior probability of unigrams and bigrams.\"\"\"\n",
    "\n",
    "    def __init__(self, corpus_dir='pa2-data/corpus', lambda_=0.1):\n",
    "        \"\"\"Iterates over all whitespace-separated tokens in each file in\n",
    "        `corpus_dir`, and counts the number of occurrences of each unigram and\n",
    "        bigram. Also keeps track of the total number of tokens in the corpus.\n",
    "\n",
    "        Args:\n",
    "            corpus_dir (str): Path to directory containing corpus.\n",
    "            lambda_ (float): Interpolation factor for smoothing by unigram-bigram\n",
    "                interpolation. You only need to save `lambda_` as an attribute for now, and\n",
    "                it will be used later in `LanguageModel.get_bigram_logp`. See Section\n",
    "                IV.1.2. below for further explanation.\n",
    "        \"\"\"\n",
    "        self.lambda_ = lambda_\n",
    "        self.total_num_tokens = 0        # Counts total number of tokens in the corpus\n",
    "        \n",
    "        self.unigram_counts = {}          # Initialize dictionary to maintain unigram counts\n",
    "        self.bigram_counts ={}            # Initialize dictionary to maintain bigram counts\n",
    "        \n",
    "        for i in range(10):\n",
    "            file = corpus_dir + '/' + str(i) + '.txt'\n",
    "            with open(file, 'r') as fp:\n",
    "                doc = fp.read()\n",
    "                doc = doc.split()\n",
    "                self.total_num_tokens += len(doc)\n",
    "                for tok_id in range(len(doc)):\n",
    "                    try:\n",
    "                        self.unigram_counts[doc[tok_id]]+=1\n",
    "                    except:\n",
    "                        self.unigram_counts[doc[tok_id]]=1\n",
    "                    try:\n",
    "                        self.bigram_counts[doc[tok_id]+ \" \" + doc[tok_id+1]]+=1\n",
    "                    except:\n",
    "                        if(tok_id!=len(doc)-1):\n",
    "                            self.bigram_counts[doc[tok_id]+ \" \" + doc[tok_id+1]]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have counted the unigrams and bigrams in our corpus, we will add methods for computing query probabilities. First, however, a note about handling bigrams which never occur in our corpus:\n",
    "\n",
    "<a id='smoothing'></a>\n",
    "#### IV.1.2. Smoothing by Interpolation\n",
    "\n",
    "The unigram probability model will also serve as our vocabulary, since we are making the assumption that our query language is derived from our document corpus. As a result, we do not need to perform [Laplace smoothing](https://en.wikipedia.org/wiki/Additive_smoothing) on our unigram probabilities, since our candidates will be drawn from this very vocabulary. However, even if we have two query terms that are both members of our query language, there is no guarantee that their corresponding *bigram* appears in our training corpus. To handle this data sparsity problem, we will *interpolate* unigram and bigram probabilities to get our ﬁnal conditional probability estimates:\n",
    "$$\n",
    "P(w_2\\mid w_1) = \\lambda P_{\\text{MLE}}(w_2) + (1 - \\lambda)P_{\\text{MLE}}(w_2\\mid w_1).\n",
    "$$\n",
    "Try setting $\\lambda$ to a small value (say, 0.1) in the beginning, and experiment later with varying this parameter to see if you can get better correction accuracies on the development dataset. However, be careful not to overﬁt your development dataset. (You might consider reserving a small portion of your development data to tune the parameters).\n",
    "\n",
    "Fill out the functions below to complete our `LanguageModel` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%tee submission/language_model_part2.py\n",
    "\n",
    "# NOTE: Syntax on the following line just extends the `LanguageModel` class\n",
    "class LanguageModel(LanguageModel):\n",
    "    def get_unigram_logp(self, unigram):\n",
    "        \"\"\"Computes the log-probability of `unigram` under this `LanguageModel`.\n",
    "\n",
    "        Args:\n",
    "            unigram (str): Unigram for which to compute the log-probability.\n",
    "\n",
    "        Returns:\n",
    "            log_p (float): Log-probability of `unigram` under this\n",
    "                `LanguageModel`.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.unigram_counts[unigram] / self.total_num_tokens\n",
    "        except:\n",
    "            return 0.000000000000000001                      \n",
    "\n",
    "    def get_bigram_logp(self, w_1, w_2):\n",
    "        \"\"\"Computes the log-probability of `unigram` under this `LanguageModel`.\n",
    "\n",
    "        Note:\n",
    "            Use self.lambda_ for the unigram-bigram interpolation factor.\n",
    "\n",
    "        Args:\n",
    "            w_1 (str): First word in bigram.\n",
    "            w_2 (str): Second word in bigram.\n",
    "\n",
    "        Returns:\n",
    "            log_p (float): Log-probability of `bigram` under this\n",
    "                `LanguageModel`.\n",
    "        \"\"\"\n",
    "        try: \n",
    "            return math.log(self.lambda_*self.get_unigram_logp(w_2) + (1 - self.lambda_)*(self.bigram_counts[w_1 + \" \" + w_2]/self.unigram_counts[w_1]), 10)\n",
    "\n",
    "        except:\n",
    "            return -18\n",
    "\n",
    "    def get_query_logp(self, query):\n",
    "        \"\"\"Computes the log-probability of `query` under this `LanguageModel`.\n",
    "\n",
    "        Args:\n",
    "            query (str): Whitespace-delimited sequence of terms in the query.\n",
    "\n",
    "        Returns:\n",
    "            log_p (float): Log-probability assigned to the query under this\n",
    "                `LanguageModel`.\n",
    "        \"\"\"\n",
    "        query = query.split()\n",
    "        \n",
    "        # Implementing the P(w1,...wn) formula\n",
    "        probability_product = 0\n",
    "        for i in range(1,len(query)):\n",
    "            probability_product = probability_product + self.get_bigram_logp(query[i - 1], query[i])\n",
    "        probability_product = probability_product + math.log(self.get_unigram_logp(query[0]), 10)            # log(unigram) because get_unigram_logp() does not return log\n",
    "        return probability_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(\"stanford university\") == 0.08400910983345951\n",
      "P(\"stanfrod universit\") == 1.2497632217906412e-11\n",
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Make sure your implementation passes the following sanity checks\n",
    "# Note: Constructing the language model could take 30 seconds or longer\n",
    "# We suggest using `tqdm` to track progress in your `LanguageModel.__init__` function.\n",
    "lm = LanguageModel()\n",
    "\n",
    "assert len(lm.unigram_counts) == 347071, 'Invalid num. unigrams: {}'.format(len(lm.unigram_counts))\n",
    "assert len(lm.bigram_counts) == 4497257, 'Invalid num. bigrams: {}'.format(len(lm.bigram_counts))\n",
    "assert lm.total_num_tokens == 25498340, 'Invalid num. tokens: {}'.format(lm.total_num_tokens)\n",
    "\n",
    "# Test a reasonable query with and without typos (you should try your own)!\n",
    "query_wo_typo = \"stanford university\"\n",
    "query_w_typo = \"stanfrod universit\"\n",
    "\n",
    "p_wo_typo = math.exp(lm.get_query_logp(query_wo_typo))                           # WHY exp???\n",
    "p_w_typo = math.exp(lm.get_query_logp(query_w_typo))\n",
    "print('P(\"{}\") == {}'.format(query_wo_typo, p_wo_typo))\n",
    "print('P(\"{}\") == {}'.format(query_w_typo, p_w_typo))\n",
    "if p_wo_typo <= p_w_typo:\n",
    "    print('\\nAre you sure \"{}\" should be assigned higher probability than \"{}\"?'\n",
    "          .format(query_w_typo, query_wo_typo))\n",
    "print('All tests passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV.2. Edit Probability Model\n",
    "\n",
    "The edit probability model attempts to estimate $P(R\\mid Q)$. That is, for a fixed candidate query $Q$, the edit probability model estimates the probability that a (possibly corrupt) raw query $R$ was submitted. We quantify the distance between the candidate query $Q$ and the actual input $R$ using the [Damerau-Levenshtein distance](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance). In Damerau-Levenshtein distance, the possible edits are **insertion**, **deletion**, **substitution**, and **transposition**, each involving single characters as operands. We have provided a base class for `EditCostModel`s below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%tee submission/base_edit_probability_model.py\n",
    "\n",
    "class BaseEditProbabilityModel:\n",
    "    def get_edit_logp(self, edited, original):\n",
    "        \"\"\"Gets the log-probability of editing `original` to arrive at `edited`.\n",
    "        The `original` and `edited` arguments are both single terms that are at\n",
    "        most one edit apart.\n",
    "        \n",
    "        Note: The order of the arguments is chosen so that it reads like an\n",
    "        assignment expression:\n",
    "            > edited := EDIT_FUNCTION(original)\n",
    "        or, alternatively, you can think of it as a (unnormalized) conditional probability:\n",
    "            > log P(edited | original)\n",
    "\n",
    "        Args:\n",
    "            edited (str): Edited term.\n",
    "            original (str): Original term.\n",
    "\n",
    "        Returns:\n",
    "            logp (float): Log-probability of `edited` given `original`\n",
    "                under this `EditProbabilityModel`.\n",
    "                \n",
    "        \"\"\"\n",
    "        raise NotImplementedError  # Force subclass to implement this method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It is important to understand that `get_edit_logp` will be called with `original` and `edited` each being single terms that are at most 1 edit apart.** Moreover, its outputs need not be normalized probabilities that sum to 1 over all possible edits to `original` (you can think of the return value more as a \"likelihood score\" than a true probability). We provide an example usage below for clarity:\n",
    "```python\n",
    "epm = EditProbabilityModelSubclass(...)  # You will define such a subclass later\n",
    "original = 'stanford'\n",
    "edited = 'stanfrod'                      # Edited by transposing 'o' and 'r'\n",
    "score = epm.get_edit_logp(edited, original)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV.2.1. Uniform-Cost Edit Model\n",
    "\n",
    "As a first pass, we will implement a *uniform-cost edit model.* This model simplifies the computation of the edit probability by assuming that every individual edit in the Damerau-Levenshtein distance has the same probability. You should try a range of values for your uniform edit probability, but in the beginning 0.01 - 0.10 is appropriate. One important thing to remember in building your model is that the user's input query $R$ may indeed be the right one in a majority of cases (*i.e.,* $R = Q$). Thus we typically choose a high ﬁxed probability for `edited == original`; a reasonable range is 0.90 - 0.95.\n",
    "\n",
    "The edit probability model that you construct here will be used when you rank candidates for query corrections. The candidate generator (described in the next section) will make one edit at a time, and it will call the edit probability model each time it makes a single edit to a term, summing log-probabilities for multi-edit changes. Therefore, all you need to do in this part is to calculate the probability of `edited` given that it is **at most one edit from `original`.** This means that `get_edit_logp` will be very simple in this case.\n",
    "\n",
    "Fill out the following class to implement a uniform-cost edit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%tee submission/uniform_edit_probability_model.py\n",
    "\n",
    "class UniformEditProbabilityModel(BaseEditProbabilityModel):\n",
    "    def __init__(self, edit_prob=0.05):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            edit_prob (float): Probability of a single edit occurring, where\n",
    "                an edit is an insertion, deletion, substitution, or transposition,\n",
    "                as defined by the Damerau-Levenshtein distance.\n",
    "        \"\"\"\n",
    "        self.edit_prob = edit_prob\n",
    "\n",
    "    def get_edit_logp(self, edited, original):\n",
    "        \"\"\"Gets the log-probability of editing `original` to arrive at `edited`.\n",
    "        The `original` and `edited` arguments are both single terms that are at\n",
    "        most one edit apart.\n",
    "        \n",
    "        Note: The order of the arguments is chosen so that it reads like an\n",
    "        assignment expression:\n",
    "            > edited := EDIT_FUNCTION(original)\n",
    "        or, alternatively, you can think of it as a (unnormalized) conditional probability:\n",
    "            > log P(edited | original)\n",
    "\n",
    "        Args:\n",
    "            edited (str): Edited term.\n",
    "            original (str): Original term.\n",
    "\n",
    "        Returns:\n",
    "            logp (float): Log-probability of `edited` given `original`\n",
    "                under this `EditProbabilityModel`.\n",
    "        \"\"\"\n",
    "        prob = 0.0\n",
    "        if edited == original:\n",
    "            prob = 1 - 0.4 # Fixed probablity\n",
    "        else:\n",
    "            prob = 0.4                                  \n",
    "        return math.log(prob, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.39794000867203755"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EDIT_PROB = 0.4\n",
    "epm = UniformEditProbabilityModel(edit_prob=EDIT_PROB)\n",
    "edited, original = 'did you go to stanford on university at stranforde', 'did you go to stranford on unversit at stranforde'\n",
    "epm.get_edit_logp(edited, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.4768300356208153"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(0.8,10)            # -0.0223\n",
    "#math.log(0.05, 10)           # -1.301\n",
    "\n",
    "# -12*-0.096\n",
    "lm.get_bigram_logp(\"stranford\", \"unviersity\") + math.log(lm.get_unigram_logp(\"stranford\"), 10)\n",
    "\n",
    "# -2.4*-0.69\n",
    "lm.get_bigram_logp(\"stanford\", \"university\") + math.log(lm.get_unigram_logp(\"stanford\"), 10)\n",
    "\n",
    "#cs.get_score(\"stranford unviersity\", epm.get_edit_logp(\"stranford unviersity\", \"stranford unviersity\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you pass the following sanity checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "EDIT_PROB = 0.4\n",
    "epm = UniformEditProbabilityModel(edit_prob=EDIT_PROB)\n",
    "\n",
    "# Test a basic edit\n",
    "edited, original = 'stanfrod', 'stanford'\n",
    "assert math.isclose(epm.get_edit_logp(edited, original), math.log(EDIT_PROB, 10))\n",
    "\n",
    "# Test a non-edit\n",
    "assert math.isclose(epm.get_edit_logp(original, original), math.log(1. - EDIT_PROB, 10))\n",
    "\n",
    "print('All tests passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV.3. Candidate Generator\n",
    "\n",
    "Recall that the candidate generator takes a raw query $R$ submitted by the user, and generates candidates for the intended query $Q$. Since we know that more than 97% of spelling errors are found within an edit distance of 2 from the user's intended query, we encourage you to consider possible query corrections that are within distance 2 of $R$. This is the approach taken by Peter Norvig in [his essay on spelling correction](http://norvig.com/spell-correct.html). However, it is not tractable to use a pure \"brute force\" generator that produces all possible strings within distance 2 of $R$, because for any $R$ of non-trivial length, the number of candidates would be enormous. Thus we would have to evaluate the language and edit probability models on a huge number of candidates.\n",
    "\n",
    "\n",
    "#### IV.3.1. Candidate Generator with Restricted Search Space\n",
    "\n",
    "We can make the naïve approach tractable by aggressively narrowing down the search space while generating candidates. There are many valid approaches to efficient candidate generation, but here are a few basic ideas:\n",
    "  - Begin by looking at *each individual term* in the query string $R$, and consider all possible edits that are distance 1 from that term.\n",
    "  - Remember that you might consider hyphens and/or spaces as elements of your character set. This will allow you to consider some relatively common errors, like when a space is accidentally inserted in a word, or two terms in the query were mistakenly separated by a space when they should actually be joined.\n",
    "  - Each time you generate an edit to a term, make sure that the edited term appears in the dictionary. (Remember that we have assumed that all words in a valid candidate query will be found in our training corpus, as mentioned above in [Section IV.1.2](#smoothing) above).\n",
    "  - If you have generated possible edits to multiple individual terms, take the Cartesian product over these terms to produce a complete candidate query that includes edits to multiple terms. (But remember that you probably shouldn't go beyond a total edit distance of 2 for the query overall).\n",
    "  \n",
    "Again, there are many possible extensions and variations on the strategies mentioned here. We encourage you to explore some diﬀerent options, and then describe in your written report the strategies that you ultimately used, and how you optimized their performance. Note that **solutions that exhaustively generate and score all possible query candidates at edit distances 1 and 2 will run too slowly and will not receive full credit.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%tee submission/candidate_generator.py\n",
    "\n",
    "# CHANGES IN THIS VERSION - COMMENTS MADE AT LINE #73, #87\n",
    "\n",
    "class CandidateGenerator:\n",
    "    # Alphabet to use for insertion and substitution\n",
    "    alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
    "                'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
    "                '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "                ' ', ',', '.', '-']\n",
    "\n",
    "    def __init__(self, lm, epm):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            lm (LanguageModel): Language model to use for prior probabilities, P(Q).\n",
    "            epm (EditProbabilityModel): Edit probability model to use for P(R|Q).\n",
    "        \"\"\"\n",
    "        self.lm = lm\n",
    "        self.epm = epm\n",
    "        self.vocab = set(lm.unigram_counts.keys())\n",
    "\n",
    "    def get_num_oov(self, query):\n",
    "        \"\"\"Get the number of out-of-vocabulary (OOV) words in `query`.\"\"\"\n",
    "        return sum(1 for w in query.strip().split()\n",
    "                   if w not in self.lm.unigram_counts)\n",
    "\n",
    "    def filter_and_yield(self, query, lp):\n",
    "        if query.strip() and self.get_num_oov(query) == 0:\n",
    "            yield query, lp\n",
    "            \n",
    "    def in_vocab(self, words):\n",
    "        return set(word for word in words if word in self.vocab)\n",
    "    \n",
    "    def edit_distance_one(self, word):\n",
    "        splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "        deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "        replaces   = [L + c + R[1:]           for L, R in splits if R for c in self.alphabet]\n",
    "        inserts    = [L + c + R               for L, R in splits for c in self.alphabet]\n",
    "        \n",
    "        return set(deletes + transposes + replaces + inserts)\n",
    "    \n",
    "    def edit_distance_two(self, word):\n",
    "        return set(e2 for e1 in self.edit_distance_one(word) for e2 in self.edit_distance_one(e1))\n",
    "    \n",
    "    def get_candidates(self, query):\n",
    "        \"\"\"Starts from `query`, and performs EDITS OF DISTANCE <=2 to get new\n",
    "        candidate queries. To make scoring tractable, only returns/yields\n",
    "        candidates that satisfy certain criteria (ideas for such criteria are\n",
    "        described in bullet points above).\n",
    "\n",
    "        Hint: We suggest you implement a helper function that takes a term and\n",
    "            generates all possible edits of distance one from that term.\n",
    "            It should probably only return edits that are in the vocabulary\n",
    "            (i.e., edits for which `self.get_num_oov(edited) == 0`).\n",
    "\n",
    "        Args:\n",
    "            query (str): Starting query.\n",
    "\n",
    "        Returns:\n",
    "            Iterable over tuples (cdt, cdt_edit_logp) of candidates and\n",
    "                their associated edit log-probabilities. Return value could be\n",
    "                a list or a generator yielding tuples of this form.\n",
    "        \"\"\"\n",
    "        \n",
    "        terms = query.strip().split()                   # List of terms in the query\n",
    "        \n",
    "        distance_one = []                               # Stores one edit distance terms  [[candidate terms,...], [index of word in query]]\n",
    "        distance_two = []                               # Stores two edit distance terms  [[candidate terms,...], [index of word in query]]\n",
    "        \n",
    "        pos = 0\n",
    "        \n",
    "#         It's a list. Dictionary -> Repeated words gives errors. There are better ways of doing it, but lists are simple\n",
    "        terms_dict = []                            \n",
    "        \n",
    "        for i in range(len(terms)): \n",
    "            terms_dict.append([terms[i], i])\n",
    "        \n",
    "        for key, value in terms_dict:\n",
    "            temp = self.edit_distance_one(key)\n",
    "                \n",
    "            distance_one.append([temp, value])\n",
    "            distance_two.append([self.edit_distance_two(key).difference(temp), value])     # OPTIMIZATION 1: 'difference' to avoid duplicates\n",
    "\n",
    "            \n",
    "            \n",
    "#       very_berry_temp->doesn't matter\n",
    "#       Basically, the 2nd try and except for both accepted1 and accepted2 makes sure we add the position,\n",
    "#       even if there are NO edited terms present in the vocab. In such a case, add the query term itself\n",
    "#       as the value.\n",
    "\n",
    "        # OPTIMIZATION 2 : Remove one edited terms not in vocab\n",
    "        accepted1 = {}                                 # Stores accepted 1-edit distance terms. {index:{terms,}}\n",
    "        for termsEdited, index in distance_one:\n",
    "            for j in termsEdited:\n",
    "                if j in self.vocab:\n",
    "                    try:\n",
    "                        accepted1[index].add(j)\n",
    "                    except:\n",
    "                        accepted1[index] = {j,}\n",
    "            try: \n",
    "                very_berry_temp = accepted1[index]\n",
    "            except:\n",
    "                accepted1[index] = {terms[index], }\n",
    "                        \n",
    "        accepted2 = {}                                # Stores accepted 2-edit distance terms. {index:{terms,}}\n",
    "        for termsEdited, index in distance_two:\n",
    "            sampledSet = itertools.islice(termsEdited, 3)\n",
    "            for j in termsEdited:\n",
    "                if j in self.vocab:\n",
    "                    try:\n",
    "                        accepted2[index].add(j)\n",
    "                    except:\n",
    "                        accepted2[index] = {j,}\n",
    "            try: \n",
    "                very_berry_temp = accepted2[index]\n",
    "            except:\n",
    "                accepted2[index] = {terms[index], }\n",
    "        \n",
    "        # Generate Candidate Queries with one-edit and zero-edit distance replacements\n",
    "        terms_indexed = [[k, v] for k,v in terms_dict]                      # {current_word : index_in_query}\n",
    "        query_terms = terms\n",
    "        candidate_queries_1 = []                                                    # Final candidate query list of one-edit replacements\n",
    "        cq = []                                                                     # Temporary list of candidate queries\n",
    "        candidate = \"\"                                                              # Temporary candidate\n",
    "        for i in range(len(terms_indexed)-1):\n",
    "            i_word, i_index = terms_indexed[i][0], terms_indexed[i][1]\n",
    "            candidate = ' '.join(query_terms[:i_index])                      # i = consider i'th to_be_edited word to be the first replacement\n",
    "                                                                             # Candidate includes all words upto the i'th word as-is.\n",
    "            for edited_word in accepted1[i_index]:\n",
    "                if candidate:                                                # if to handle correct addition of whitespaces\n",
    "                    cq.append(candidate + \" \" + edited_word)\n",
    "                else:\n",
    "                    cq.append(edited_word)\n",
    "                                                                             # cq holds all possible queries with correction on the i'th term (and upto ith)\n",
    "                                                                             # Next step: Generate all possible queries hereforth\n",
    "            if candidate:                                                    # Include un-edited current word as well\n",
    "                cq.append(candidate + \" \" + i_word)\n",
    "            else:\n",
    "                cq.append(i_word)\n",
    "                \n",
    "            j = i+1\n",
    "            candidate = \"\"\n",
    "            \n",
    "            cq2 = []\n",
    "            for ind in cq: \n",
    "                cq2.append(ind + \" \" + ' '.join(query_terms[i_index + 1:]))\n",
    "            candidate_queries_1 += cq2                                   # Add completed queries to the final list\n",
    "            \n",
    "            while(j<len(terms_indexed)):\n",
    "                j_word, j_index = terms_indexed[j][0], terms_indexed[j][1]   # Next Incorrect word and Index of the next incorrect word\n",
    "                candidate = ' '.join(query_terms[i_index+1:j_index])         # All the correct words in between the prev incorrect and current incorrect\n",
    "                cq2 = []                                                     # Temporary Candidate Query List\n",
    "                for edited_word in accepted1[j_index]:\n",
    "                    for ind in range(len(cq)):                               # Append correct words in between + edited terms to the half-candidate queries and complete\n",
    "                        if candidate:\n",
    "                            cq2.append(cq[ind] + \" \" + candidate + \" \" + edited_word + \" \" + ' '.join(query_terms[j_index+1:]))\n",
    "                        else:\n",
    "                            cq2.append(cq[ind] + \" \" + edited_word + \" \" + ' '.join(query_terms[j_index+1:]))\n",
    "                j+=1                                                         # Next incorrect word\n",
    "                candidate_queries_1 += cq2                                   # Add completed queries to the final list\n",
    "                \n",
    "            cq = []\n",
    "            \n",
    "        '''\n",
    "        print(\"\\n---------------------ONE EDIT DISTANCE--------------------------\\n\")\n",
    "        print(candidate_queries_1)\n",
    "        print(\"\\n---------------------                 --------------------------\\n\")\n",
    "        '''\n",
    "                \n",
    "        # Generate Candidate Queries with a Single two-edit replacement\n",
    "        \n",
    "        pos = 0\n",
    "        candidate_queries_2 = []\n",
    "        candidate = \"\"\n",
    "        query_terms = terms\n",
    "        for term, value in terms_dict:\n",
    "            for i in accepted2[pos]:\n",
    "                candidate_queries_2.append(candidate + i + \" \" + ' '.join(query_terms[pos+1:]))\n",
    "            candidate += term + \" \"                                     # Exclude correction of current incorrect term and append as-is.\n",
    "            pos += 1\n",
    "        '''\n",
    "        print(\"\\n---------------------TWO EDIT DISTANCE--------------------------\\n\")\n",
    "        print(candidate_queries_2)\n",
    "        print(\"\\n---------------------                 --------------------------\\n\")\n",
    "        '''\n",
    "                \n",
    "        \n",
    "        # Adding my doubts here:\n",
    "        '''\n",
    "        1. Candidate generation has to be done for each term - but how will the cartesian product work?\n",
    "        2. How to ensure cartesian product terms have edit distance <= 2? \n",
    "        3. Once we get the valid candidate queries, epms for each word have to be summed or multiplied?\n",
    "        4. All the above steps still seems extremely computationally expensive? How do you optimize it?\n",
    "        '''\n",
    "        \n",
    "        # Yield the unedited query first\n",
    "        # We provide this line as an example of how to use `self.filter_and_yield`\n",
    "        candidate = candidate_queries_1 + candidate_queries_2\n",
    "        res= []\n",
    "        for edited_query in candidate: \n",
    "            #yield from self.filter_and_yield(query, self.epm.get_edit_logp(edited_query, query))\n",
    "            res.append([edited_query.strip(), self.epm.get_edit_logp(edited_query.strip(), query)])\n",
    "            \n",
    "        #res.remove([query, math.log(0.8, 10)]) # TOREMOVE ORIGINAL QUERY FROM LIST. SHOULD NOT BE THERE\n",
    "        #print(res)\n",
    "        return res\n",
    "        \n",
    "        \n",
    "model = CandidateGenerator(LanguageModel(), UniformEditProbabilityModel(BaseEditProbabilityModel))\n",
    "#model.get_candidates(\"did you go to stranford on unversit at stranforde\")\n",
    "#model.get_candidates('stranford unviersity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['page 1 page 2 page', -0.39794000867203755],\n",
       " ['paige 1 page 2 page', -0.39794000867203755],\n",
       " ['paggi 1 page 2 page', -0.39794000867203755],\n",
       " ['bagge 1 page 2 page', -0.39794000867203755],\n",
       " ['hagge 1 page 2 page', -0.39794000867203755],\n",
       " ['pogge 1 page 2 page', -0.39794000867203755],\n",
       " ['pagge 1 page 2 page', -0.22184874961635637],\n",
       " ['page u page 2 page', -0.39794000867203755],\n",
       " ['paige u page 2 page', -0.39794000867203755],\n",
       " ['paggi u page 2 page', -0.39794000867203755],\n",
       " ['bagge u page 2 page', -0.39794000867203755],\n",
       " ['hagge u page 2 page', -0.39794000867203755],\n",
       " ['pogge u page 2 page', -0.39794000867203755],\n",
       " ['pagge u page 2 page', -0.39794000867203755],\n",
       " ['page i1 page 2 page', -0.39794000867203755],\n",
       " ['paige i1 page 2 page', -0.39794000867203755],\n",
       " ['paggi i1 page 2 page', -0.39794000867203755],\n",
       " ['bagge i1 page 2 page', -0.39794000867203755],\n",
       " ['hagge i1 page 2 page', -0.39794000867203755],\n",
       " ['pogge i1 page 2 page', -0.39794000867203755],\n",
       " ['pagge i1 page 2 page', -0.39794000867203755],\n",
       " ['page g page 2 page', -0.39794000867203755],\n",
       " ['paige g page 2 page', -0.39794000867203755],\n",
       " ['paggi g page 2 page', -0.39794000867203755],\n",
       " ['bagge g page 2 page', -0.39794000867203755],\n",
       " ['hagge g page 2 page', -0.39794000867203755],\n",
       " ['pogge g page 2 page', -0.39794000867203755],\n",
       " ['pagge g page 2 page', -0.39794000867203755],\n",
       " ['page 1n page 2 page', -0.39794000867203755],\n",
       " ['paige 1n page 2 page', -0.39794000867203755],\n",
       " ['paggi 1n page 2 page', -0.39794000867203755],\n",
       " ['bagge 1n page 2 page', -0.39794000867203755],\n",
       " ['hagge 1n page 2 page', -0.39794000867203755],\n",
       " ['pogge 1n page 2 page', -0.39794000867203755],\n",
       " ['pagge 1n page 2 page', -0.39794000867203755],\n",
       " ['page 1b page 2 page', -0.39794000867203755],\n",
       " ['paige 1b page 2 page', -0.39794000867203755],\n",
       " ['paggi 1b page 2 page', -0.39794000867203755],\n",
       " ['bagge 1b page 2 page', -0.39794000867203755],\n",
       " ['hagge 1b page 2 page', -0.39794000867203755],\n",
       " ['pogge 1b page 2 page', -0.39794000867203755],\n",
       " ['pagge 1b page 2 page', -0.39794000867203755],\n",
       " ['page 1f page 2 page', -0.39794000867203755],\n",
       " ['paige 1f page 2 page', -0.39794000867203755],\n",
       " ['paggi 1f page 2 page', -0.39794000867203755],\n",
       " ['bagge 1f page 2 page', -0.39794000867203755],\n",
       " ['hagge 1f page 2 page', -0.39794000867203755],\n",
       " ['pogge 1f page 2 page', -0.39794000867203755],\n",
       " ['pagge 1f page 2 page', -0.39794000867203755],\n",
       " ['page y page 2 page', -0.39794000867203755],\n",
       " ['paige y page 2 page', -0.39794000867203755],\n",
       " ['paggi y page 2 page', -0.39794000867203755],\n",
       " ['bagge y page 2 page', -0.39794000867203755],\n",
       " ['hagge y page 2 page', -0.39794000867203755],\n",
       " ['pogge y page 2 page', -0.39794000867203755],\n",
       " ['pagge y page 2 page', -0.39794000867203755],\n",
       " ['page 16 page 2 page', -0.39794000867203755],\n",
       " ['paige 16 page 2 page', -0.39794000867203755],\n",
       " ['paggi 16 page 2 page', -0.39794000867203755],\n",
       " ['bagge 16 page 2 page', -0.39794000867203755],\n",
       " ['hagge 16 page 2 page', -0.39794000867203755],\n",
       " ['pogge 16 page 2 page', -0.39794000867203755],\n",
       " ['pagge 16 page 2 page', -0.39794000867203755],\n",
       " ['page m1 page 2 page', -0.39794000867203755],\n",
       " ['paige m1 page 2 page', -0.39794000867203755],\n",
       " ['paggi m1 page 2 page', -0.39794000867203755],\n",
       " ['bagge m1 page 2 page', -0.39794000867203755],\n",
       " ['hagge m1 page 2 page', -0.39794000867203755],\n",
       " ['pogge m1 page 2 page', -0.39794000867203755],\n",
       " ['pagge m1 page 2 page', -0.39794000867203755],\n",
       " ['page 1i page 2 page', -0.39794000867203755],\n",
       " ['paige 1i page 2 page', -0.39794000867203755],\n",
       " ['paggi 1i page 2 page', -0.39794000867203755],\n",
       " ['bagge 1i page 2 page', -0.39794000867203755],\n",
       " ['hagge 1i page 2 page', -0.39794000867203755],\n",
       " ['pogge 1i page 2 page', -0.39794000867203755],\n",
       " ['pagge 1i page 2 page', -0.39794000867203755],\n",
       " ['page e1 page 2 page', -0.39794000867203755],\n",
       " ['paige e1 page 2 page', -0.39794000867203755],\n",
       " ['paggi e1 page 2 page', -0.39794000867203755],\n",
       " ['bagge e1 page 2 page', -0.39794000867203755],\n",
       " ['hagge e1 page 2 page', -0.39794000867203755],\n",
       " ['pogge e1 page 2 page', -0.39794000867203755],\n",
       " ['pagge e1 page 2 page', -0.39794000867203755],\n",
       " ['page k page 2 page', -0.39794000867203755],\n",
       " ['paige k page 2 page', -0.39794000867203755],\n",
       " ['paggi k page 2 page', -0.39794000867203755],\n",
       " ['bagge k page 2 page', -0.39794000867203755],\n",
       " ['hagge k page 2 page', -0.39794000867203755],\n",
       " ['pogge k page 2 page', -0.39794000867203755],\n",
       " ['pagge k page 2 page', -0.39794000867203755],\n",
       " ['page a1 page 2 page', -0.39794000867203755],\n",
       " ['paige a1 page 2 page', -0.39794000867203755],\n",
       " ['paggi a1 page 2 page', -0.39794000867203755],\n",
       " ['bagge a1 page 2 page', -0.39794000867203755],\n",
       " ['hagge a1 page 2 page', -0.39794000867203755],\n",
       " ['pogge a1 page 2 page', -0.39794000867203755],\n",
       " ['pagge a1 page 2 page', -0.39794000867203755],\n",
       " ['page d1 page 2 page', -0.39794000867203755],\n",
       " ['paige d1 page 2 page', -0.39794000867203755],\n",
       " ['paggi d1 page 2 page', -0.39794000867203755],\n",
       " ['bagge d1 page 2 page', -0.39794000867203755],\n",
       " ['hagge d1 page 2 page', -0.39794000867203755],\n",
       " ['pogge d1 page 2 page', -0.39794000867203755],\n",
       " ['pagge d1 page 2 page', -0.39794000867203755],\n",
       " ['page 01 page 2 page', -0.39794000867203755],\n",
       " ['paige 01 page 2 page', -0.39794000867203755],\n",
       " ['paggi 01 page 2 page', -0.39794000867203755],\n",
       " ['bagge 01 page 2 page', -0.39794000867203755],\n",
       " ['hagge 01 page 2 page', -0.39794000867203755],\n",
       " ['pogge 01 page 2 page', -0.39794000867203755],\n",
       " ['pagge 01 page 2 page', -0.39794000867203755],\n",
       " ['page j1 page 2 page', -0.39794000867203755],\n",
       " ['paige j1 page 2 page', -0.39794000867203755],\n",
       " ['paggi j1 page 2 page', -0.39794000867203755],\n",
       " ['bagge j1 page 2 page', -0.39794000867203755],\n",
       " ['hagge j1 page 2 page', -0.39794000867203755],\n",
       " ['pogge j1 page 2 page', -0.39794000867203755],\n",
       " ['pagge j1 page 2 page', -0.39794000867203755],\n",
       " ['page 1o page 2 page', -0.39794000867203755],\n",
       " ['paige 1o page 2 page', -0.39794000867203755],\n",
       " ['paggi 1o page 2 page', -0.39794000867203755],\n",
       " ['bagge 1o page 2 page', -0.39794000867203755],\n",
       " ['hagge 1o page 2 page', -0.39794000867203755],\n",
       " ['pogge 1o page 2 page', -0.39794000867203755],\n",
       " ['pagge 1o page 2 page', -0.39794000867203755],\n",
       " ['page o page 2 page', -0.39794000867203755],\n",
       " ['paige o page 2 page', -0.39794000867203755],\n",
       " ['paggi o page 2 page', -0.39794000867203755],\n",
       " ['bagge o page 2 page', -0.39794000867203755],\n",
       " ['hagge o page 2 page', -0.39794000867203755],\n",
       " ['pogge o page 2 page', -0.39794000867203755],\n",
       " ['pagge o page 2 page', -0.39794000867203755],\n",
       " ['page 1s page 2 page', -0.39794000867203755],\n",
       " ['paige 1s page 2 page', -0.39794000867203755],\n",
       " ['paggi 1s page 2 page', -0.39794000867203755],\n",
       " ['bagge 1s page 2 page', -0.39794000867203755],\n",
       " ['hagge 1s page 2 page', -0.39794000867203755],\n",
       " ['pogge 1s page 2 page', -0.39794000867203755],\n",
       " ['pagge 1s page 2 page', -0.39794000867203755],\n",
       " ['page x1 page 2 page', -0.39794000867203755],\n",
       " ['paige x1 page 2 page', -0.39794000867203755],\n",
       " ['paggi x1 page 2 page', -0.39794000867203755],\n",
       " ['bagge x1 page 2 page', -0.39794000867203755],\n",
       " ['hagge x1 page 2 page', -0.39794000867203755],\n",
       " ['pogge x1 page 2 page', -0.39794000867203755],\n",
       " ['pagge x1 page 2 page', -0.39794000867203755],\n",
       " ['page c page 2 page', -0.39794000867203755],\n",
       " ['paige c page 2 page', -0.39794000867203755],\n",
       " ['paggi c page 2 page', -0.39794000867203755],\n",
       " ['bagge c page 2 page', -0.39794000867203755],\n",
       " ['hagge c page 2 page', -0.39794000867203755],\n",
       " ['pogge c page 2 page', -0.39794000867203755],\n",
       " ['pagge c page 2 page', -0.39794000867203755],\n",
       " ['page 1v page 2 page', -0.39794000867203755],\n",
       " ['paige 1v page 2 page', -0.39794000867203755],\n",
       " ['paggi 1v page 2 page', -0.39794000867203755],\n",
       " ['bagge 1v page 2 page', -0.39794000867203755],\n",
       " ['hagge 1v page 2 page', -0.39794000867203755],\n",
       " ['pogge 1v page 2 page', -0.39794000867203755],\n",
       " ['pagge 1v page 2 page', -0.39794000867203755],\n",
       " ['page n page 2 page', -0.39794000867203755],\n",
       " ['paige n page 2 page', -0.39794000867203755],\n",
       " ['paggi n page 2 page', -0.39794000867203755],\n",
       " ['bagge n page 2 page', -0.39794000867203755],\n",
       " ['hagge n page 2 page', -0.39794000867203755],\n",
       " ['pogge n page 2 page', -0.39794000867203755],\n",
       " ['pagge n page 2 page', -0.39794000867203755],\n",
       " ['page 1l page 2 page', -0.39794000867203755],\n",
       " ['paige 1l page 2 page', -0.39794000867203755],\n",
       " ['paggi 1l page 2 page', -0.39794000867203755],\n",
       " ['bagge 1l page 2 page', -0.39794000867203755],\n",
       " ['hagge 1l page 2 page', -0.39794000867203755],\n",
       " ['pogge 1l page 2 page', -0.39794000867203755],\n",
       " ['pagge 1l page 2 page', -0.39794000867203755],\n",
       " ['page 1x page 2 page', -0.39794000867203755],\n",
       " ['paige 1x page 2 page', -0.39794000867203755],\n",
       " ['paggi 1x page 2 page', -0.39794000867203755],\n",
       " ['bagge 1x page 2 page', -0.39794000867203755],\n",
       " ['hagge 1x page 2 page', -0.39794000867203755],\n",
       " ['pogge 1x page 2 page', -0.39794000867203755],\n",
       " ['pagge 1x page 2 page', -0.39794000867203755],\n",
       " ['page 12 page 2 page', -0.39794000867203755],\n",
       " ['paige 12 page 2 page', -0.39794000867203755],\n",
       " ['paggi 12 page 2 page', -0.39794000867203755],\n",
       " ['bagge 12 page 2 page', -0.39794000867203755],\n",
       " ['hagge 12 page 2 page', -0.39794000867203755],\n",
       " ['pogge 12 page 2 page', -0.39794000867203755],\n",
       " ['pagge 12 page 2 page', -0.39794000867203755],\n",
       " ['page 6 page 2 page', -0.39794000867203755],\n",
       " ['paige 6 page 2 page', -0.39794000867203755],\n",
       " ['paggi 6 page 2 page', -0.39794000867203755],\n",
       " ['bagge 6 page 2 page', -0.39794000867203755],\n",
       " ['hagge 6 page 2 page', -0.39794000867203755],\n",
       " ['pogge 6 page 2 page', -0.39794000867203755],\n",
       " ['pagge 6 page 2 page', -0.39794000867203755],\n",
       " ['page 11 page 2 page', -0.39794000867203755],\n",
       " ['paige 11 page 2 page', -0.39794000867203755],\n",
       " ['paggi 11 page 2 page', -0.39794000867203755],\n",
       " ['bagge 11 page 2 page', -0.39794000867203755],\n",
       " ['hagge 11 page 2 page', -0.39794000867203755],\n",
       " ['pogge 11 page 2 page', -0.39794000867203755],\n",
       " ['pagge 11 page 2 page', -0.39794000867203755],\n",
       " ['page r1 page 2 page', -0.39794000867203755],\n",
       " ['paige r1 page 2 page', -0.39794000867203755],\n",
       " ['paggi r1 page 2 page', -0.39794000867203755],\n",
       " ['bagge r1 page 2 page', -0.39794000867203755],\n",
       " ['hagge r1 page 2 page', -0.39794000867203755],\n",
       " ['pogge r1 page 2 page', -0.39794000867203755],\n",
       " ['pagge r1 page 2 page', -0.39794000867203755],\n",
       " ['page w page 2 page', -0.39794000867203755],\n",
       " ['paige w page 2 page', -0.39794000867203755],\n",
       " ['paggi w page 2 page', -0.39794000867203755],\n",
       " ['bagge w page 2 page', -0.39794000867203755],\n",
       " ['hagge w page 2 page', -0.39794000867203755],\n",
       " ['pogge w page 2 page', -0.39794000867203755],\n",
       " ['pagge w page 2 page', -0.39794000867203755],\n",
       " ['page f page 2 page', -0.39794000867203755],\n",
       " ['paige f page 2 page', -0.39794000867203755],\n",
       " ['paggi f page 2 page', -0.39794000867203755],\n",
       " ['bagge f page 2 page', -0.39794000867203755],\n",
       " ['hagge f page 2 page', -0.39794000867203755],\n",
       " ['pogge f page 2 page', -0.39794000867203755],\n",
       " ['pagge f page 2 page', -0.39794000867203755],\n",
       " ['page a page 2 page', -0.39794000867203755],\n",
       " ['paige a page 2 page', -0.39794000867203755],\n",
       " ['paggi a page 2 page', -0.39794000867203755],\n",
       " ['bagge a page 2 page', -0.39794000867203755],\n",
       " ['hagge a page 2 page', -0.39794000867203755],\n",
       " ['pogge a page 2 page', -0.39794000867203755],\n",
       " ['pagge a page 2 page', -0.39794000867203755],\n",
       " ['page 91 page 2 page', -0.39794000867203755],\n",
       " ['paige 91 page 2 page', -0.39794000867203755],\n",
       " ['paggi 91 page 2 page', -0.39794000867203755],\n",
       " ['bagge 91 page 2 page', -0.39794000867203755],\n",
       " ['hagge 91 page 2 page', -0.39794000867203755],\n",
       " ['pogge 91 page 2 page', -0.39794000867203755],\n",
       " ['pagge 91 page 2 page', -0.39794000867203755],\n",
       " ['page i page 2 page', -0.39794000867203755],\n",
       " ['paige i page 2 page', -0.39794000867203755],\n",
       " ['paggi i page 2 page', -0.39794000867203755],\n",
       " ['bagge i page 2 page', -0.39794000867203755],\n",
       " ['hagge i page 2 page', -0.39794000867203755],\n",
       " ['pogge i page 2 page', -0.39794000867203755],\n",
       " ['pagge i page 2 page', -0.39794000867203755],\n",
       " ['page k1 page 2 page', -0.39794000867203755],\n",
       " ['paige k1 page 2 page', -0.39794000867203755],\n",
       " ['paggi k1 page 2 page', -0.39794000867203755],\n",
       " ['bagge k1 page 2 page', -0.39794000867203755],\n",
       " ['hagge k1 page 2 page', -0.39794000867203755],\n",
       " ['pogge k1 page 2 page', -0.39794000867203755],\n",
       " ['pagge k1 page 2 page', -0.39794000867203755],\n",
       " ['page s1 page 2 page', -0.39794000867203755],\n",
       " ['paige s1 page 2 page', -0.39794000867203755],\n",
       " ['paggi s1 page 2 page', -0.39794000867203755],\n",
       " ['bagge s1 page 2 page', -0.39794000867203755],\n",
       " ['hagge s1 page 2 page', -0.39794000867203755],\n",
       " ['pogge s1 page 2 page', -0.39794000867203755],\n",
       " ['pagge s1 page 2 page', -0.39794000867203755],\n",
       " ['page o1 page 2 page', -0.39794000867203755],\n",
       " ['paige o1 page 2 page', -0.39794000867203755],\n",
       " ['paggi o1 page 2 page', -0.39794000867203755],\n",
       " ['bagge o1 page 2 page', -0.39794000867203755],\n",
       " ['hagge o1 page 2 page', -0.39794000867203755],\n",
       " ['pogge o1 page 2 page', -0.39794000867203755],\n",
       " ['pagge o1 page 2 page', -0.39794000867203755],\n",
       " ['page y1 page 2 page', -0.39794000867203755],\n",
       " ['paige y1 page 2 page', -0.39794000867203755],\n",
       " ['paggi y1 page 2 page', -0.39794000867203755],\n",
       " ['bagge y1 page 2 page', -0.39794000867203755],\n",
       " ['hagge y1 page 2 page', -0.39794000867203755],\n",
       " ['pogge y1 page 2 page', -0.39794000867203755],\n",
       " ['pagge y1 page 2 page', -0.39794000867203755],\n",
       " ['page 1p page 2 page', -0.39794000867203755],\n",
       " ['paige 1p page 2 page', -0.39794000867203755],\n",
       " ['paggi 1p page 2 page', -0.39794000867203755],\n",
       " ['bagge 1p page 2 page', -0.39794000867203755],\n",
       " ['hagge 1p page 2 page', -0.39794000867203755],\n",
       " ['pogge 1p page 2 page', -0.39794000867203755],\n",
       " ['pagge 1p page 2 page', -0.39794000867203755],\n",
       " ['page 1z page 2 page', -0.39794000867203755],\n",
       " ['paige 1z page 2 page', -0.39794000867203755],\n",
       " ['paggi 1z page 2 page', -0.39794000867203755],\n",
       " ['bagge 1z page 2 page', -0.39794000867203755],\n",
       " ['hagge 1z page 2 page', -0.39794000867203755],\n",
       " ['pogge 1z page 2 page', -0.39794000867203755],\n",
       " ['pagge 1z page 2 page', -0.39794000867203755],\n",
       " ['page 51 page 2 page', -0.39794000867203755],\n",
       " ['paige 51 page 2 page', -0.39794000867203755],\n",
       " ['paggi 51 page 2 page', -0.39794000867203755],\n",
       " ['bagge 51 page 2 page', -0.39794000867203755],\n",
       " ['hagge 51 page 2 page', -0.39794000867203755],\n",
       " ['pogge 51 page 2 page', -0.39794000867203755],\n",
       " ['pagge 51 page 2 page', -0.39794000867203755],\n",
       " ['page 1h page 2 page', -0.39794000867203755],\n",
       " ['paige 1h page 2 page', -0.39794000867203755],\n",
       " ['paggi 1h page 2 page', -0.39794000867203755],\n",
       " ['bagge 1h page 2 page', -0.39794000867203755],\n",
       " ['hagge 1h page 2 page', -0.39794000867203755],\n",
       " ['pogge 1h page 2 page', -0.39794000867203755],\n",
       " ['pagge 1h page 2 page', -0.39794000867203755],\n",
       " ['page 1t page 2 page', -0.39794000867203755],\n",
       " ['paige 1t page 2 page', -0.39794000867203755],\n",
       " ['paggi 1t page 2 page', -0.39794000867203755],\n",
       " ['bagge 1t page 2 page', -0.39794000867203755],\n",
       " ['hagge 1t page 2 page', -0.39794000867203755],\n",
       " ['pogge 1t page 2 page', -0.39794000867203755],\n",
       " ['pagge 1t page 2 page', -0.39794000867203755],\n",
       " ['page 8 page 2 page', -0.39794000867203755],\n",
       " ['paige 8 page 2 page', -0.39794000867203755],\n",
       " ['paggi 8 page 2 page', -0.39794000867203755],\n",
       " ['bagge 8 page 2 page', -0.39794000867203755],\n",
       " ['hagge 8 page 2 page', -0.39794000867203755],\n",
       " ['pogge 8 page 2 page', -0.39794000867203755],\n",
       " ['pagge 8 page 2 page', -0.39794000867203755],\n",
       " ['page e page 2 page', -0.39794000867203755],\n",
       " ['paige e page 2 page', -0.39794000867203755],\n",
       " ['paggi e page 2 page', -0.39794000867203755],\n",
       " ['bagge e page 2 page', -0.39794000867203755],\n",
       " ['hagge e page 2 page', -0.39794000867203755],\n",
       " ['pogge e page 2 page', -0.39794000867203755],\n",
       " ['pagge e page 2 page', -0.39794000867203755],\n",
       " ['page 81 page 2 page', -0.39794000867203755],\n",
       " ['paige 81 page 2 page', -0.39794000867203755],\n",
       " ['paggi 81 page 2 page', -0.39794000867203755],\n",
       " ['bagge 81 page 2 page', -0.39794000867203755],\n",
       " ['hagge 81 page 2 page', -0.39794000867203755],\n",
       " ['pogge 81 page 2 page', -0.39794000867203755],\n",
       " ['pagge 81 page 2 page', -0.39794000867203755],\n",
       " ['page d page 2 page', -0.39794000867203755],\n",
       " ['paige d page 2 page', -0.39794000867203755],\n",
       " ['paggi d page 2 page', -0.39794000867203755],\n",
       " ['bagge d page 2 page', -0.39794000867203755],\n",
       " ['hagge d page 2 page', -0.39794000867203755],\n",
       " ['pogge d page 2 page', -0.39794000867203755],\n",
       " ['pagge d page 2 page', -0.39794000867203755],\n",
       " ['page 10 page 2 page', -0.39794000867203755],\n",
       " ['paige 10 page 2 page', -0.39794000867203755],\n",
       " ['paggi 10 page 2 page', -0.39794000867203755],\n",
       " ['bagge 10 page 2 page', -0.39794000867203755],\n",
       " ['hagge 10 page 2 page', -0.39794000867203755],\n",
       " ['pogge 10 page 2 page', -0.39794000867203755],\n",
       " ['pagge 10 page 2 page', -0.39794000867203755],\n",
       " ['page 0 page 2 page', -0.39794000867203755],\n",
       " ['paige 0 page 2 page', -0.39794000867203755],\n",
       " ['paggi 0 page 2 page', -0.39794000867203755],\n",
       " ['bagge 0 page 2 page', -0.39794000867203755],\n",
       " ['hagge 0 page 2 page', -0.39794000867203755],\n",
       " ['pogge 0 page 2 page', -0.39794000867203755],\n",
       " ['pagge 0 page 2 page', -0.39794000867203755],\n",
       " ['page 1k page 2 page', -0.39794000867203755],\n",
       " ['paige 1k page 2 page', -0.39794000867203755],\n",
       " ['paggi 1k page 2 page', -0.39794000867203755],\n",
       " ['bagge 1k page 2 page', -0.39794000867203755],\n",
       " ['hagge 1k page 2 page', -0.39794000867203755],\n",
       " ['pogge 1k page 2 page', -0.39794000867203755],\n",
       " ['pagge 1k page 2 page', -0.39794000867203755],\n",
       " ['page s page 2 page', -0.39794000867203755],\n",
       " ['paige s page 2 page', -0.39794000867203755],\n",
       " ['paggi s page 2 page', -0.39794000867203755],\n",
       " ['bagge s page 2 page', -0.39794000867203755],\n",
       " ['hagge s page 2 page', -0.39794000867203755],\n",
       " ['pogge s page 2 page', -0.39794000867203755],\n",
       " ['pagge s page 2 page', -0.39794000867203755],\n",
       " ['page 2 page 2 page', -0.39794000867203755],\n",
       " ['paige 2 page 2 page', -0.39794000867203755],\n",
       " ['paggi 2 page 2 page', -0.39794000867203755],\n",
       " ['bagge 2 page 2 page', -0.39794000867203755],\n",
       " ['hagge 2 page 2 page', -0.39794000867203755],\n",
       " ['pogge 2 page 2 page', -0.39794000867203755],\n",
       " ['pagge 2 page 2 page', -0.39794000867203755],\n",
       " ['page 15 page 2 page', -0.39794000867203755],\n",
       " ['paige 15 page 2 page', -0.39794000867203755],\n",
       " ['paggi 15 page 2 page', -0.39794000867203755],\n",
       " ['bagge 15 page 2 page', -0.39794000867203755],\n",
       " ['hagge 15 page 2 page', -0.39794000867203755],\n",
       " ['pogge 15 page 2 page', -0.39794000867203755],\n",
       " ['pagge 15 page 2 page', -0.39794000867203755],\n",
       " ['page p1 page 2 page', -0.39794000867203755],\n",
       " ['paige p1 page 2 page', -0.39794000867203755],\n",
       " ['paggi p1 page 2 page', -0.39794000867203755],\n",
       " ['bagge p1 page 2 page', -0.39794000867203755],\n",
       " ['hagge p1 page 2 page', -0.39794000867203755],\n",
       " ['pogge p1 page 2 page', -0.39794000867203755],\n",
       " ['pagge p1 page 2 page', -0.39794000867203755],\n",
       " ['page 1r page 2 page', -0.39794000867203755],\n",
       " ['paige 1r page 2 page', -0.39794000867203755],\n",
       " ['paggi 1r page 2 page', -0.39794000867203755],\n",
       " ['bagge 1r page 2 page', -0.39794000867203755],\n",
       " ['hagge 1r page 2 page', -0.39794000867203755],\n",
       " ['pogge 1r page 2 page', -0.39794000867203755],\n",
       " ['pagge 1r page 2 page', -0.39794000867203755],\n",
       " ['page 1c page 2 page', -0.39794000867203755],\n",
       " ['paige 1c page 2 page', -0.39794000867203755],\n",
       " ['paggi 1c page 2 page', -0.39794000867203755],\n",
       " ['bagge 1c page 2 page', -0.39794000867203755],\n",
       " ['hagge 1c page 2 page', -0.39794000867203755],\n",
       " ['pogge 1c page 2 page', -0.39794000867203755],\n",
       " ['pagge 1c page 2 page', -0.39794000867203755],\n",
       " ['page 18 page 2 page', -0.39794000867203755],\n",
       " ['paige 18 page 2 page', -0.39794000867203755],\n",
       " ['paggi 18 page 2 page', -0.39794000867203755],\n",
       " ['bagge 18 page 2 page', -0.39794000867203755],\n",
       " ['hagge 18 page 2 page', -0.39794000867203755],\n",
       " ['pogge 18 page 2 page', -0.39794000867203755],\n",
       " ['pagge 18 page 2 page', -0.39794000867203755],\n",
       " ['page z1 page 2 page', -0.39794000867203755],\n",
       " ['paige z1 page 2 page', -0.39794000867203755],\n",
       " ['paggi z1 page 2 page', -0.39794000867203755],\n",
       " ['bagge z1 page 2 page', -0.39794000867203755],\n",
       " ['hagge z1 page 2 page', -0.39794000867203755],\n",
       " ['pogge z1 page 2 page', -0.39794000867203755],\n",
       " ['pagge z1 page 2 page', -0.39794000867203755],\n",
       " ['page f1 page 2 page', -0.39794000867203755],\n",
       " ['paige f1 page 2 page', -0.39794000867203755],\n",
       " ['paggi f1 page 2 page', -0.39794000867203755],\n",
       " ['bagge f1 page 2 page', -0.39794000867203755],\n",
       " ['hagge f1 page 2 page', -0.39794000867203755],\n",
       " ['pogge f1 page 2 page', -0.39794000867203755],\n",
       " ['pagge f1 page 2 page', -0.39794000867203755],\n",
       " ['page p page 2 page', -0.39794000867203755],\n",
       " ['paige p page 2 page', -0.39794000867203755],\n",
       " ['paggi p page 2 page', -0.39794000867203755],\n",
       " ['bagge p page 2 page', -0.39794000867203755],\n",
       " ['hagge p page 2 page', -0.39794000867203755],\n",
       " ['pogge p page 2 page', -0.39794000867203755],\n",
       " ['pagge p page 2 page', -0.39794000867203755],\n",
       " ['page 1y page 2 page', -0.39794000867203755],\n",
       " ['paige 1y page 2 page', -0.39794000867203755],\n",
       " ['paggi 1y page 2 page', -0.39794000867203755],\n",
       " ['bagge 1y page 2 page', -0.39794000867203755],\n",
       " ['hagge 1y page 2 page', -0.39794000867203755],\n",
       " ['pogge 1y page 2 page', -0.39794000867203755],\n",
       " ['pagge 1y page 2 page', -0.39794000867203755],\n",
       " ['page r page 2 page', -0.39794000867203755],\n",
       " ['paige r page 2 page', -0.39794000867203755],\n",
       " ['paggi r page 2 page', -0.39794000867203755],\n",
       " ['bagge r page 2 page', -0.39794000867203755],\n",
       " ['hagge r page 2 page', -0.39794000867203755],\n",
       " ['pogge r page 2 page', -0.39794000867203755],\n",
       " ['pagge r page 2 page', -0.39794000867203755],\n",
       " ['page 1a page 2 page', -0.39794000867203755],\n",
       " ['paige 1a page 2 page', -0.39794000867203755],\n",
       " ['paggi 1a page 2 page', -0.39794000867203755],\n",
       " ['bagge 1a page 2 page', -0.39794000867203755],\n",
       " ['hagge 1a page 2 page', -0.39794000867203755],\n",
       " ['pogge 1a page 2 page', -0.39794000867203755],\n",
       " ['pagge 1a page 2 page', -0.39794000867203755],\n",
       " ['page c1 page 2 page', -0.39794000867203755],\n",
       " ['paige c1 page 2 page', -0.39794000867203755],\n",
       " ['paggi c1 page 2 page', -0.39794000867203755],\n",
       " ['bagge c1 page 2 page', -0.39794000867203755],\n",
       " ['hagge c1 page 2 page', -0.39794000867203755],\n",
       " ['pogge c1 page 2 page', -0.39794000867203755],\n",
       " ['pagge c1 page 2 page', -0.39794000867203755],\n",
       " ['page z page 2 page', -0.39794000867203755],\n",
       " ['paige z page 2 page', -0.39794000867203755],\n",
       " ['paggi z page 2 page', -0.39794000867203755],\n",
       " ['bagge z page 2 page', -0.39794000867203755],\n",
       " ['hagge z page 2 page', -0.39794000867203755],\n",
       " ['pogge z page 2 page', -0.39794000867203755],\n",
       " ['pagge z page 2 page', -0.39794000867203755],\n",
       " ['page b page 2 page', -0.39794000867203755],\n",
       " ['paige b page 2 page', -0.39794000867203755],\n",
       " ['paggi b page 2 page', -0.39794000867203755],\n",
       " ['bagge b page 2 page', -0.39794000867203755],\n",
       " ['hagge b page 2 page', -0.39794000867203755],\n",
       " ['pogge b page 2 page', -0.39794000867203755],\n",
       " ['pagge b page 2 page', -0.39794000867203755],\n",
       " ['page 41 page 2 page', -0.39794000867203755],\n",
       " ['paige 41 page 2 page', -0.39794000867203755],\n",
       " ['paggi 41 page 2 page', -0.39794000867203755],\n",
       " ['bagge 41 page 2 page', -0.39794000867203755],\n",
       " ['hagge 41 page 2 page', -0.39794000867203755],\n",
       " ['pogge 41 page 2 page', -0.39794000867203755],\n",
       " ['pagge 41 page 2 page', -0.39794000867203755],\n",
       " ['page h page 2 page', -0.39794000867203755],\n",
       " ['paige h page 2 page', -0.39794000867203755],\n",
       " ['paggi h page 2 page', -0.39794000867203755],\n",
       " ['bagge h page 2 page', -0.39794000867203755],\n",
       " ['hagge h page 2 page', -0.39794000867203755],\n",
       " ['pogge h page 2 page', -0.39794000867203755],\n",
       " ['pagge h page 2 page', -0.39794000867203755],\n",
       " ['page g1 page 2 page', -0.39794000867203755],\n",
       " ['paige g1 page 2 page', -0.39794000867203755],\n",
       " ['paggi g1 page 2 page', -0.39794000867203755],\n",
       " ['bagge g1 page 2 page', -0.39794000867203755],\n",
       " ['hagge g1 page 2 page', -0.39794000867203755],\n",
       " ['pogge g1 page 2 page', -0.39794000867203755],\n",
       " ['pagge g1 page 2 page', -0.39794000867203755],\n",
       " ['page 1w page 2 page', -0.39794000867203755],\n",
       " ['paige 1w page 2 page', -0.39794000867203755],\n",
       " ['paggi 1w page 2 page', -0.39794000867203755],\n",
       " ['bagge 1w page 2 page', -0.39794000867203755],\n",
       " ['hagge 1w page 2 page', -0.39794000867203755],\n",
       " ['pogge 1w page 2 page', -0.39794000867203755],\n",
       " ['pagge 1w page 2 page', -0.39794000867203755],\n",
       " ['page m page 2 page', -0.39794000867203755],\n",
       " ['paige m page 2 page', -0.39794000867203755],\n",
       " ['paggi m page 2 page', -0.39794000867203755],\n",
       " ['bagge m page 2 page', -0.39794000867203755],\n",
       " ['hagge m page 2 page', -0.39794000867203755],\n",
       " ['pogge m page 2 page', -0.39794000867203755],\n",
       " ['pagge m page 2 page', -0.39794000867203755],\n",
       " ['page b1 page 2 page', -0.39794000867203755],\n",
       " ['paige b1 page 2 page', -0.39794000867203755],\n",
       " ['paggi b1 page 2 page', -0.39794000867203755],\n",
       " ['bagge b1 page 2 page', -0.39794000867203755],\n",
       " ['hagge b1 page 2 page', -0.39794000867203755],\n",
       " ['pogge b1 page 2 page', -0.39794000867203755],\n",
       " ['pagge b1 page 2 page', -0.39794000867203755],\n",
       " ['page j page 2 page', -0.39794000867203755],\n",
       " ['paige j page 2 page', -0.39794000867203755],\n",
       " ['paggi j page 2 page', -0.39794000867203755],\n",
       " ['bagge j page 2 page', -0.39794000867203755],\n",
       " ['hagge j page 2 page', -0.39794000867203755],\n",
       " ['pogge j page 2 page', -0.39794000867203755],\n",
       " ['pagge j page 2 page', -0.39794000867203755],\n",
       " ['page 1j page 2 page', -0.39794000867203755],\n",
       " ['paige 1j page 2 page', -0.39794000867203755],\n",
       " ['paggi 1j page 2 page', -0.39794000867203755],\n",
       " ['bagge 1j page 2 page', -0.39794000867203755],\n",
       " ['hagge 1j page 2 page', -0.39794000867203755],\n",
       " ['pogge 1j page 2 page', -0.39794000867203755],\n",
       " ['pagge 1j page 2 page', -0.39794000867203755],\n",
       " ['page h1 page 2 page', -0.39794000867203755],\n",
       " ['paige h1 page 2 page', -0.39794000867203755],\n",
       " ['paggi h1 page 2 page', -0.39794000867203755],\n",
       " ['bagge h1 page 2 page', -0.39794000867203755],\n",
       " ['hagge h1 page 2 page', -0.39794000867203755],\n",
       " ['pogge h1 page 2 page', -0.39794000867203755],\n",
       " ['pagge h1 page 2 page', -0.39794000867203755],\n",
       " ['page 21 page 2 page', -0.39794000867203755],\n",
       " ['paige 21 page 2 page', -0.39794000867203755],\n",
       " ['paggi 21 page 2 page', -0.39794000867203755],\n",
       " ['bagge 21 page 2 page', -0.39794000867203755],\n",
       " ['hagge 21 page 2 page', -0.39794000867203755],\n",
       " ['pogge 21 page 2 page', -0.39794000867203755],\n",
       " ['pagge 21 page 2 page', -0.39794000867203755],\n",
       " ['page 14 page 2 page', -0.39794000867203755],\n",
       " ['paige 14 page 2 page', -0.39794000867203755],\n",
       " ['paggi 14 page 2 page', -0.39794000867203755],\n",
       " ['bagge 14 page 2 page', -0.39794000867203755],\n",
       " ['hagge 14 page 2 page', -0.39794000867203755],\n",
       " ['pogge 14 page 2 page', -0.39794000867203755],\n",
       " ['pagge 14 page 2 page', -0.39794000867203755],\n",
       " ['page u1 page 2 page', -0.39794000867203755],\n",
       " ['paige u1 page 2 page', -0.39794000867203755],\n",
       " ['paggi u1 page 2 page', -0.39794000867203755],\n",
       " ['bagge u1 page 2 page', -0.39794000867203755],\n",
       " ['hagge u1 page 2 page', -0.39794000867203755],\n",
       " ['pogge u1 page 2 page', -0.39794000867203755],\n",
       " ['pagge u1 page 2 page', -0.39794000867203755],\n",
       " ['page 1q page 2 page', -0.39794000867203755],\n",
       " ['paige 1q page 2 page', -0.39794000867203755],\n",
       " ['paggi 1q page 2 page', -0.39794000867203755],\n",
       " ['bagge 1q page 2 page', -0.39794000867203755],\n",
       " ['hagge 1q page 2 page', -0.39794000867203755],\n",
       " ['pogge 1q page 2 page', -0.39794000867203755],\n",
       " ['pagge 1q page 2 page', -0.39794000867203755],\n",
       " ['page 1d page 2 page', -0.39794000867203755],\n",
       " ['paige 1d page 2 page', -0.39794000867203755],\n",
       " ['paggi 1d page 2 page', -0.39794000867203755],\n",
       " ['bagge 1d page 2 page', -0.39794000867203755],\n",
       " ['hagge 1d page 2 page', -0.39794000867203755],\n",
       " ['pogge 1d page 2 page', -0.39794000867203755],\n",
       " ['pagge 1d page 2 page', -0.39794000867203755],\n",
       " ['page 1u page 2 page', -0.39794000867203755],\n",
       " ['paige 1u page 2 page', -0.39794000867203755],\n",
       " ['paggi 1u page 2 page', -0.39794000867203755],\n",
       " ['bagge 1u page 2 page', -0.39794000867203755],\n",
       " ['hagge 1u page 2 page', -0.39794000867203755],\n",
       " ['pogge 1u page 2 page', -0.39794000867203755],\n",
       " ['pagge 1u page 2 page', -0.39794000867203755],\n",
       " ['page v page 2 page', -0.39794000867203755],\n",
       " ['paige v page 2 page', -0.39794000867203755],\n",
       " ['paggi v page 2 page', -0.39794000867203755],\n",
       " ['bagge v page 2 page', -0.39794000867203755],\n",
       " ['hagge v page 2 page', -0.39794000867203755],\n",
       " ['pogge v page 2 page', -0.39794000867203755],\n",
       " ['pagge v page 2 page', -0.39794000867203755],\n",
       " ['page 4 page 2 page', -0.39794000867203755],\n",
       " ['paige 4 page 2 page', -0.39794000867203755],\n",
       " ['paggi 4 page 2 page', -0.39794000867203755],\n",
       " ['bagge 4 page 2 page', -0.39794000867203755],\n",
       " ['hagge 4 page 2 page', -0.39794000867203755],\n",
       " ['pogge 4 page 2 page', -0.39794000867203755],\n",
       " ['pagge 4 page 2 page', -0.39794000867203755],\n",
       " ['page 17 page 2 page', -0.39794000867203755],\n",
       " ['paige 17 page 2 page', -0.39794000867203755],\n",
       " ['paggi 17 page 2 page', -0.39794000867203755],\n",
       " ['bagge 17 page 2 page', -0.39794000867203755],\n",
       " ['hagge 17 page 2 page', -0.39794000867203755],\n",
       " ['pogge 17 page 2 page', -0.39794000867203755],\n",
       " ['pagge 17 page 2 page', -0.39794000867203755],\n",
       " ['page 1e page 2 page', -0.39794000867203755],\n",
       " ['paige 1e page 2 page', -0.39794000867203755],\n",
       " ['paggi 1e page 2 page', -0.39794000867203755],\n",
       " ['bagge 1e page 2 page', -0.39794000867203755],\n",
       " ['hagge 1e page 2 page', -0.39794000867203755],\n",
       " ['pogge 1e page 2 page', -0.39794000867203755],\n",
       " ['pagge 1e page 2 page', -0.39794000867203755],\n",
       " ['page 1m page 2 page', -0.39794000867203755],\n",
       " ['paige 1m page 2 page', -0.39794000867203755],\n",
       " ['paggi 1m page 2 page', -0.39794000867203755],\n",
       " ['bagge 1m page 2 page', -0.39794000867203755],\n",
       " ['hagge 1m page 2 page', -0.39794000867203755],\n",
       " ['pogge 1m page 2 page', -0.39794000867203755],\n",
       " ['pagge 1m page 2 page', -0.39794000867203755],\n",
       " ['page 1 page 2 page', -0.39794000867203755],\n",
       " ['paige 1 page 2 page', -0.39794000867203755],\n",
       " ['paggi 1 page 2 page', -0.39794000867203755],\n",
       " ['bagge 1 page 2 page', -0.39794000867203755],\n",
       " ['hagge 1 page 2 page', -0.39794000867203755],\n",
       " ['pogge 1 page 2 page', -0.39794000867203755],\n",
       " ['pagge 1 page 2 page', -0.22184874961635637],\n",
       " ['page t page 2 page', -0.39794000867203755],\n",
       " ['paige t page 2 page', -0.39794000867203755],\n",
       " ['paggi t page 2 page', -0.39794000867203755],\n",
       " ['bagge t page 2 page', -0.39794000867203755],\n",
       " ['hagge t page 2 page', -0.39794000867203755],\n",
       " ['pogge t page 2 page', -0.39794000867203755],\n",
       " ['pagge t page 2 page', -0.39794000867203755],\n",
       " ['page 5 page 2 page', -0.39794000867203755],\n",
       " ['paige 5 page 2 page', -0.39794000867203755],\n",
       " ['paggi 5 page 2 page', -0.39794000867203755],\n",
       " ['bagge 5 page 2 page', -0.39794000867203755],\n",
       " ['hagge 5 page 2 page', -0.39794000867203755],\n",
       " ['pogge 5 page 2 page', -0.39794000867203755],\n",
       " ['pagge 5 page 2 page', -0.39794000867203755],\n",
       " ['page w1 page 2 page', -0.39794000867203755],\n",
       " ['paige w1 page 2 page', -0.39794000867203755],\n",
       " ['paggi w1 page 2 page', -0.39794000867203755],\n",
       " ['bagge w1 page 2 page', -0.39794000867203755],\n",
       " ['hagge w1 page 2 page', -0.39794000867203755],\n",
       " ['pogge w1 page 2 page', -0.39794000867203755],\n",
       " ['pagge w1 page 2 page', -0.39794000867203755],\n",
       " ['page l page 2 page', -0.39794000867203755],\n",
       " ['paige l page 2 page', -0.39794000867203755],\n",
       " ['paggi l page 2 page', -0.39794000867203755],\n",
       " ['bagge l page 2 page', -0.39794000867203755],\n",
       " ['hagge l page 2 page', -0.39794000867203755],\n",
       " ['pogge l page 2 page', -0.39794000867203755],\n",
       " ['pagge l page 2 page', -0.39794000867203755],\n",
       " ['page 61 page 2 page', -0.39794000867203755],\n",
       " ['paige 61 page 2 page', -0.39794000867203755],\n",
       " ['paggi 61 page 2 page', -0.39794000867203755],\n",
       " ['bagge 61 page 2 page', -0.39794000867203755],\n",
       " ['hagge 61 page 2 page', -0.39794000867203755],\n",
       " ['pogge 61 page 2 page', -0.39794000867203755],\n",
       " ['pagge 61 page 2 page', -0.39794000867203755],\n",
       " ['page 71 page 2 page', -0.39794000867203755],\n",
       " ['paige 71 page 2 page', -0.39794000867203755],\n",
       " ['paggi 71 page 2 page', -0.39794000867203755],\n",
       " ['bagge 71 page 2 page', -0.39794000867203755],\n",
       " ['hagge 71 page 2 page', -0.39794000867203755],\n",
       " ['pogge 71 page 2 page', -0.39794000867203755],\n",
       " ['pagge 71 page 2 page', -0.39794000867203755],\n",
       " ['page 13 page 2 page', -0.39794000867203755],\n",
       " ['paige 13 page 2 page', -0.39794000867203755],\n",
       " ['paggi 13 page 2 page', -0.39794000867203755],\n",
       " ['bagge 13 page 2 page', -0.39794000867203755],\n",
       " ['hagge 13 page 2 page', -0.39794000867203755],\n",
       " ['pogge 13 page 2 page', -0.39794000867203755],\n",
       " ['pagge 13 page 2 page', -0.39794000867203755],\n",
       " ['page q1 page 2 page', -0.39794000867203755],\n",
       " ['paige q1 page 2 page', -0.39794000867203755],\n",
       " ['paggi q1 page 2 page', -0.39794000867203755],\n",
       " ['bagge q1 page 2 page', -0.39794000867203755],\n",
       " ['hagge q1 page 2 page', -0.39794000867203755],\n",
       " ['pogge q1 page 2 page', -0.39794000867203755],\n",
       " ['pagge q1 page 2 page', -0.39794000867203755],\n",
       " ['page 7 page 2 page', -0.39794000867203755],\n",
       " ['paige 7 page 2 page', -0.39794000867203755],\n",
       " ['paggi 7 page 2 page', -0.39794000867203755],\n",
       " ['bagge 7 page 2 page', -0.39794000867203755],\n",
       " ['hagge 7 page 2 page', -0.39794000867203755],\n",
       " ['pogge 7 page 2 page', -0.39794000867203755],\n",
       " ['pagge 7 page 2 page', -0.39794000867203755],\n",
       " ['page 3 page 2 page', -0.39794000867203755],\n",
       " ['paige 3 page 2 page', -0.39794000867203755],\n",
       " ['paggi 3 page 2 page', -0.39794000867203755],\n",
       " ['bagge 3 page 2 page', -0.39794000867203755],\n",
       " ['hagge 3 page 2 page', -0.39794000867203755],\n",
       " ['pogge 3 page 2 page', -0.39794000867203755],\n",
       " ['pagge 3 page 2 page', -0.39794000867203755],\n",
       " ['page v1 page 2 page', -0.39794000867203755],\n",
       " ['paige v1 page 2 page', -0.39794000867203755],\n",
       " ['paggi v1 page 2 page', -0.39794000867203755],\n",
       " ['bagge v1 page 2 page', -0.39794000867203755],\n",
       " ['hagge v1 page 2 page', -0.39794000867203755],\n",
       " ['pogge v1 page 2 page', -0.39794000867203755],\n",
       " ['pagge v1 page 2 page', -0.39794000867203755],\n",
       " ['page x page 2 page', -0.39794000867203755],\n",
       " ['paige x page 2 page', -0.39794000867203755],\n",
       " ['paggi x page 2 page', -0.39794000867203755],\n",
       " ['bagge x page 2 page', -0.39794000867203755],\n",
       " ['hagge x page 2 page', -0.39794000867203755],\n",
       " ['pogge x page 2 page', -0.39794000867203755],\n",
       " ['pagge x page 2 page', -0.39794000867203755],\n",
       " ['page l1 page 2 page', -0.39794000867203755],\n",
       " ['paige l1 page 2 page', -0.39794000867203755],\n",
       " ['paggi l1 page 2 page', -0.39794000867203755],\n",
       " ['bagge l1 page 2 page', -0.39794000867203755],\n",
       " ['hagge l1 page 2 page', -0.39794000867203755],\n",
       " ['pogge l1 page 2 page', -0.39794000867203755],\n",
       " ['pagge l1 page 2 page', -0.39794000867203755],\n",
       " ['page 19 page 2 page', -0.39794000867203755],\n",
       " ['paige 19 page 2 page', -0.39794000867203755],\n",
       " ['paggi 19 page 2 page', -0.39794000867203755],\n",
       " ['bagge 19 page 2 page', -0.39794000867203755],\n",
       " ['hagge 19 page 2 page', -0.39794000867203755],\n",
       " ['pogge 19 page 2 page', -0.39794000867203755],\n",
       " ['pagge 19 page 2 page', -0.39794000867203755],\n",
       " ['page 31 page 2 page', -0.39794000867203755],\n",
       " ['paige 31 page 2 page', -0.39794000867203755],\n",
       " ['paggi 31 page 2 page', -0.39794000867203755],\n",
       " ['bagge 31 page 2 page', -0.39794000867203755],\n",
       " ['hagge 31 page 2 page', -0.39794000867203755],\n",
       " ['pogge 31 page 2 page', -0.39794000867203755],\n",
       " ['pagge 31 page 2 page', -0.39794000867203755],\n",
       " ['page n1 page 2 page', -0.39794000867203755],\n",
       " ['paige n1 page 2 page', -0.39794000867203755],\n",
       " ['paggi n1 page 2 page', -0.39794000867203755],\n",
       " ['bagge n1 page 2 page', -0.39794000867203755],\n",
       " ['hagge n1 page 2 page', -0.39794000867203755],\n",
       " ['pogge n1 page 2 page', -0.39794000867203755],\n",
       " ['pagge n1 page 2 page', -0.39794000867203755],\n",
       " ['page 1g page 2 page', -0.39794000867203755],\n",
       " ['paige 1g page 2 page', -0.39794000867203755],\n",
       " ['paggi 1g page 2 page', -0.39794000867203755],\n",
       " ['bagge 1g page 2 page', -0.39794000867203755],\n",
       " ['hagge 1g page 2 page', -0.39794000867203755],\n",
       " ['pogge 1g page 2 page', -0.39794000867203755],\n",
       " ['pagge 1g page 2 page', -0.39794000867203755],\n",
       " ['page q page 2 page', -0.39794000867203755],\n",
       " ['paige q page 2 page', -0.39794000867203755],\n",
       " ['paggi q page 2 page', -0.39794000867203755],\n",
       " ['bagge q page 2 page', -0.39794000867203755],\n",
       " ['hagge q page 2 page', -0.39794000867203755],\n",
       " ['pogge q page 2 page', -0.39794000867203755],\n",
       " ['pagge q page 2 page', -0.39794000867203755],\n",
       " ['page t1 page 2 page', -0.39794000867203755],\n",
       " ['paige t1 page 2 page', -0.39794000867203755],\n",
       " ['paggi t1 page 2 page', -0.39794000867203755],\n",
       " ['bagge t1 page 2 page', -0.39794000867203755],\n",
       " ['hagge t1 page 2 page', -0.39794000867203755],\n",
       " ['pogge t1 page 2 page', -0.39794000867203755],\n",
       " ['pagge t1 page 2 page', -0.39794000867203755],\n",
       " ['page 9 page 2 page', -0.39794000867203755],\n",
       " ['paige 9 page 2 page', -0.39794000867203755],\n",
       " ['paggi 9 page 2 page', -0.39794000867203755],\n",
       " ['bagge 9 page 2 page', -0.39794000867203755],\n",
       " ['hagge 9 page 2 page', -0.39794000867203755],\n",
       " ['pogge 9 page 2 page', -0.39794000867203755],\n",
       " ['pagge 9 page 2 page', -0.39794000867203755],\n",
       " ['page 1 pge 2 page', -0.39794000867203755],\n",
       " ['paige 1 pge 2 page', -0.39794000867203755],\n",
       " ['paggi 1 pge 2 page', -0.39794000867203755],\n",
       " ['bagge 1 pge 2 page', -0.39794000867203755],\n",
       " ['hagge 1 pge 2 page', -0.39794000867203755],\n",
       " ['pogge 1 pge 2 page', -0.39794000867203755],\n",
       " ['pagge 1 pge 2 page', -0.39794000867203755],\n",
       " ['page 1 pag7 2 page', -0.39794000867203755],\n",
       " ['paige 1 pag7 2 page', -0.39794000867203755],\n",
       " ['paggi 1 pag7 2 page', -0.39794000867203755],\n",
       " ['bagge 1 pag7 2 page', -0.39794000867203755],\n",
       " ['hagge 1 pag7 2 page', -0.39794000867203755],\n",
       " ['pogge 1 pag7 2 page', -0.39794000867203755],\n",
       " ['pagge 1 pag7 2 page', -0.39794000867203755],\n",
       " ['page 1 pase 2 page', -0.39794000867203755],\n",
       " ['paige 1 pase 2 page', -0.39794000867203755],\n",
       " ['paggi 1 pase 2 page', -0.39794000867203755],\n",
       " ['bagge 1 pase 2 page', -0.39794000867203755],\n",
       " ['hagge 1 pase 2 page', -0.39794000867203755],\n",
       " ['pogge 1 pase 2 page', -0.39794000867203755],\n",
       " ['pagge 1 pase 2 page', -0.39794000867203755],\n",
       " ['page 1 poage 2 page', -0.39794000867203755],\n",
       " ['paige 1 poage 2 page', -0.39794000867203755],\n",
       " ['paggi 1 poage 2 page', -0.39794000867203755],\n",
       " ['bagge 1 poage 2 page', -0.39794000867203755],\n",
       " ['hagge 1 poage 2 page', -0.39794000867203755],\n",
       " ['pogge 1 poage 2 page', -0.39794000867203755],\n",
       " ['pagge 1 poage 2 page', -0.39794000867203755],\n",
       " ['page 1 hage 2 page', -0.39794000867203755],\n",
       " ['paige 1 hage 2 page', -0.39794000867203755],\n",
       " ['paggi 1 hage 2 page', -0.39794000867203755],\n",
       " ['bagge 1 hage 2 page', -0.39794000867203755],\n",
       " ['hagge 1 hage 2 page', -0.39794000867203755],\n",
       " ['pogge 1 hage 2 page', -0.39794000867203755],\n",
       " ['pagge 1 hage 2 page', -0.39794000867203755],\n",
       " ['page 1 aage 2 page', -0.39794000867203755],\n",
       " ['paige 1 aage 2 page', -0.39794000867203755],\n",
       " ['paggi 1 aage 2 page', -0.39794000867203755],\n",
       " ['bagge 1 aage 2 page', -0.39794000867203755],\n",
       " ['hagge 1 aage 2 page', -0.39794000867203755],\n",
       " ['pogge 1 aage 2 page', -0.39794000867203755],\n",
       " ['pagge 1 aage 2 page', -0.39794000867203755],\n",
       " ['page 1 sage 2 page', -0.39794000867203755],\n",
       " ['paige 1 sage 2 page', -0.39794000867203755],\n",
       " ['paggi 1 sage 2 page', -0.39794000867203755],\n",
       " ['bagge 1 sage 2 page', -0.39794000867203755],\n",
       " ['hagge 1 sage 2 page', -0.39794000867203755],\n",
       " ['pogge 1 sage 2 page', -0.39794000867203755],\n",
       " ['pagge 1 sage 2 page', -0.39794000867203755],\n",
       " ['page 1 pag 2 page', -0.39794000867203755],\n",
       " ['paige 1 pag 2 page', -0.39794000867203755],\n",
       " ['paggi 1 pag 2 page', -0.39794000867203755],\n",
       " ['bagge 1 pag 2 page', -0.39794000867203755],\n",
       " ['hagge 1 pag 2 page', -0.39794000867203755],\n",
       " ['pogge 1 pag 2 page', -0.39794000867203755],\n",
       " ['pagge 1 pag 2 page', -0.39794000867203755],\n",
       " ['page 1 pare 2 page', -0.39794000867203755],\n",
       " ['paige 1 pare 2 page', -0.39794000867203755],\n",
       " ['paggi 1 pare 2 page', -0.39794000867203755],\n",
       " ['bagge 1 pare 2 page', -0.39794000867203755],\n",
       " ['hagge 1 pare 2 page', -0.39794000867203755],\n",
       " ['pogge 1 pare 2 page', -0.39794000867203755],\n",
       " ['pagge 1 pare 2 page', -0.39794000867203755],\n",
       " ['page 1 page2 2 page', -0.39794000867203755],\n",
       " ['paige 1 page2 2 page', -0.39794000867203755],\n",
       " ['paggi 1 page2 2 page', -0.39794000867203755],\n",
       " ['bagge 1 page2 2 page', -0.39794000867203755],\n",
       " ['hagge 1 page2 2 page', -0.39794000867203755],\n",
       " ['pogge 1 page2 2 page', -0.39794000867203755],\n",
       " ['pagge 1 page2 2 page', -0.39794000867203755],\n",
       " ['page 1 paged 2 page', -0.39794000867203755],\n",
       " ['paige 1 paged 2 page', -0.39794000867203755],\n",
       " ['paggi 1 paged 2 page', -0.39794000867203755],\n",
       " ['bagge 1 paged 2 page', -0.39794000867203755],\n",
       " ['hagge 1 paged 2 page', -0.39794000867203755],\n",
       " ['pogge 1 paged 2 page', -0.39794000867203755],\n",
       " ['pagge 1 paged 2 page', -0.39794000867203755],\n",
       " ['page 1 pfge 2 page', -0.39794000867203755],\n",
       " ['paige 1 pfge 2 page', -0.39794000867203755],\n",
       " ['paggi 1 pfge 2 page', -0.39794000867203755],\n",
       " ['bagge 1 pfge 2 page', -0.39794000867203755],\n",
       " ['hagge 1 pfge 2 page', -0.39794000867203755],\n",
       " ['pogge 1 pfge 2 page', -0.39794000867203755],\n",
       " ['pagge 1 pfge 2 page', -0.39794000867203755],\n",
       " ['page 1 eage 2 page', -0.39794000867203755],\n",
       " ['paige 1 eage 2 page', -0.39794000867203755],\n",
       " ['paggi 1 eage 2 page', -0.39794000867203755],\n",
       " ['bagge 1 eage 2 page', -0.39794000867203755],\n",
       " ['hagge 1 eage 2 page', -0.39794000867203755],\n",
       " ['pogge 1 eage 2 page', -0.39794000867203755],\n",
       " ['pagge 1 eage 2 page', -0.39794000867203755],\n",
       " ['page 1 pake 2 page', -0.39794000867203755],\n",
       " ['paige 1 pake 2 page', -0.39794000867203755],\n",
       " ['paggi 1 pake 2 page', -0.39794000867203755],\n",
       " ['bagge 1 pake 2 page', -0.39794000867203755],\n",
       " ['hagge 1 pake 2 page', -0.39794000867203755],\n",
       " ['pogge 1 pake 2 page', -0.39794000867203755],\n",
       " ['pagge 1 pake 2 page', -0.39794000867203755],\n",
       " ['page 1 nage 2 page', -0.39794000867203755],\n",
       " ['paige 1 nage 2 page', -0.39794000867203755],\n",
       " ['paggi 1 nage 2 page', -0.39794000867203755],\n",
       " ['bagge 1 nage 2 page', -0.39794000867203755],\n",
       " ['hagge 1 nage 2 page', -0.39794000867203755],\n",
       " ['pogge 1 nage 2 page', -0.39794000867203755],\n",
       " ['pagge 1 nage 2 page', -0.39794000867203755],\n",
       " ['page 1 pawe 2 page', -0.39794000867203755],\n",
       " ['paige 1 pawe 2 page', -0.39794000867203755],\n",
       " ['paggi 1 pawe 2 page', -0.39794000867203755],\n",
       " ['bagge 1 pawe 2 page', -0.39794000867203755],\n",
       " ['hagge 1 pawe 2 page', -0.39794000867203755],\n",
       " ['pogge 1 pawe 2 page', -0.39794000867203755],\n",
       " ['pagge 1 pawe 2 page', -0.39794000867203755],\n",
       " ['page 1 paget 2 page', -0.39794000867203755],\n",
       " ['paige 1 paget 2 page', -0.39794000867203755],\n",
       " ['paggi 1 paget 2 page', -0.39794000867203755],\n",
       " ['bagge 1 paget 2 page', -0.39794000867203755],\n",
       " ['hagge 1 paget 2 page', -0.39794000867203755],\n",
       " ['pogge 1 paget 2 page', -0.39794000867203755],\n",
       " ['pagge 1 paget 2 page', -0.39794000867203755],\n",
       " ['page 1 page 2 page', -0.39794000867203755],\n",
       " ['paige 1 page 2 page', -0.39794000867203755],\n",
       " ['paggi 1 page 2 page', -0.39794000867203755],\n",
       " ['bagge 1 page 2 page', -0.39794000867203755],\n",
       " ['hagge 1 page 2 page', -0.39794000867203755],\n",
       " ['pogge 1 page 2 page', -0.39794000867203755],\n",
       " ['pagge 1 page 2 page', -0.22184874961635637],\n",
       " ['page 1 pace 2 page', -0.39794000867203755],\n",
       " ['paige 1 pace 2 page', -0.39794000867203755],\n",
       " ['paggi 1 pace 2 page', -0.39794000867203755],\n",
       " ['bagge 1 pace 2 page', -0.39794000867203755],\n",
       " ['hagge 1 pace 2 page', -0.39794000867203755],\n",
       " ['pogge 1 pace 2 page', -0.39794000867203755],\n",
       " ['pagge 1 pace 2 page', -0.39794000867203755],\n",
       " ['page 1 phage 2 page', -0.39794000867203755],\n",
       " ['paige 1 phage 2 page', -0.39794000867203755],\n",
       " ['paggi 1 phage 2 page', -0.39794000867203755],\n",
       " ['bagge 1 phage 2 page', -0.39794000867203755],\n",
       " ['hagge 1 phage 2 page', -0.39794000867203755],\n",
       " ['pogge 1 phage 2 page', -0.39794000867203755],\n",
       " ['pagge 1 phage 2 page', -0.39794000867203755],\n",
       " ['page 1 paige 2 page', -0.39794000867203755],\n",
       " ['paige 1 paige 2 page', -0.39794000867203755],\n",
       " ['paggi 1 paige 2 page', -0.39794000867203755],\n",
       " ['bagge 1 paige 2 page', -0.39794000867203755],\n",
       " ['hagge 1 paige 2 page', -0.39794000867203755],\n",
       " ['pogge 1 paige 2 page', -0.39794000867203755],\n",
       " ['pagge 1 paige 2 page', -0.39794000867203755],\n",
       " ['page 1 pave 2 page', -0.39794000867203755],\n",
       " ['paige 1 pave 2 page', -0.39794000867203755],\n",
       " ['paggi 1 pave 2 page', -0.39794000867203755],\n",
       " ['bagge 1 pave 2 page', -0.39794000867203755],\n",
       " ['hagge 1 pave 2 page', -0.39794000867203755],\n",
       " ['pogge 1 pave 2 page', -0.39794000867203755],\n",
       " ['pagge 1 pave 2 page', -0.39794000867203755],\n",
       " ['page 1 pape 2 page', -0.39794000867203755],\n",
       " ['paige 1 pape 2 page', -0.39794000867203755],\n",
       " ['paggi 1 pape 2 page', -0.39794000867203755],\n",
       " ['bagge 1 pape 2 page', -0.39794000867203755],\n",
       " ['hagge 1 pape 2 page', -0.39794000867203755],\n",
       " ['pogge 1 pape 2 page', -0.39794000867203755],\n",
       " ['pagge 1 pape 2 page', -0.39794000867203755],\n",
       " ['page 1 pane 2 page', -0.39794000867203755],\n",
       " ['paige 1 pane 2 page', -0.39794000867203755],\n",
       " ['paggi 1 pane 2 page', -0.39794000867203755],\n",
       " ['bagge 1 pane 2 page', -0.39794000867203755],\n",
       " ['hagge 1 pane 2 page', -0.39794000867203755],\n",
       " ['pogge 1 pane 2 page', -0.39794000867203755],\n",
       " ['pagge 1 pane 2 page', -0.39794000867203755],\n",
       " ['page 1 gage 2 page', -0.39794000867203755],\n",
       " ['paige 1 gage 2 page', -0.39794000867203755],\n",
       " ['paggi 1 gage 2 page', -0.39794000867203755],\n",
       " ['bagge 1 gage 2 page', -0.39794000867203755],\n",
       " ['hagge 1 gage 2 page', -0.39794000867203755],\n",
       " ['pogge 1 gage 2 page', -0.39794000867203755],\n",
       " ['pagge 1 gage 2 page', -0.39794000867203755],\n",
       " ['page 1 pager 2 page', -0.39794000867203755],\n",
       " ['paige 1 pager 2 page', -0.39794000867203755],\n",
       " ['paggi 1 pager 2 page', -0.39794000867203755],\n",
       " ['bagge 1 pager 2 page', -0.39794000867203755],\n",
       " ['hagge 1 pager 2 page', -0.39794000867203755],\n",
       " ['pogge 1 pager 2 page', -0.39794000867203755],\n",
       " ['pagge 1 pager 2 page', -0.39794000867203755],\n",
       " ['page 1 pages 2 page', -0.39794000867203755],\n",
       " ['paige 1 pages 2 page', -0.39794000867203755],\n",
       " ['paggi 1 pages 2 page', -0.39794000867203755],\n",
       " ['bagge 1 pages 2 page', -0.39794000867203755],\n",
       " ['hagge 1 pages 2 page', -0.39794000867203755],\n",
       " ['pogge 1 pages 2 page', -0.39794000867203755],\n",
       " ['pagge 1 pages 2 page', -0.39794000867203755],\n",
       " ['page 1 lage 2 page', -0.39794000867203755],\n",
       " ['paige 1 lage 2 page', -0.39794000867203755],\n",
       " ['paggi 1 lage 2 page', -0.39794000867203755],\n",
       " ['bagge 1 lage 2 page', -0.39794000867203755],\n",
       " ['hagge 1 lage 2 page', -0.39794000867203755],\n",
       " ['pogge 1 lage 2 page', -0.39794000867203755],\n",
       " ['pagge 1 lage 2 page', -0.39794000867203755],\n",
       " ['page 1 tage 2 page', -0.39794000867203755],\n",
       " ['paige 1 tage 2 page', -0.39794000867203755],\n",
       " ['paggi 1 tage 2 page', -0.39794000867203755],\n",
       " ['bagge 1 tage 2 page', -0.39794000867203755],\n",
       " ['hagge 1 tage 2 page', -0.39794000867203755],\n",
       " ['pogge 1 tage 2 page', -0.39794000867203755],\n",
       " ['pagge 1 tage 2 page', -0.39794000867203755],\n",
       " ['page 1 mage 2 page', -0.39794000867203755],\n",
       " ['paige 1 mage 2 page', -0.39794000867203755],\n",
       " ['paggi 1 mage 2 page', -0.39794000867203755],\n",
       " ['bagge 1 mage 2 page', -0.39794000867203755],\n",
       " ['hagge 1 mage 2 page', -0.39794000867203755],\n",
       " ['pogge 1 mage 2 page', -0.39794000867203755],\n",
       " ['pagge 1 mage 2 page', -0.39794000867203755],\n",
       " ['page 1 uage 2 page', -0.39794000867203755],\n",
       " ['paige 1 uage 2 page', -0.39794000867203755],\n",
       " ['paggi 1 uage 2 page', -0.39794000867203755],\n",
       " ['bagge 1 uage 2 page', -0.39794000867203755],\n",
       " ['hagge 1 uage 2 page', -0.39794000867203755],\n",
       " ['pogge 1 uage 2 page', -0.39794000867203755],\n",
       " ['pagge 1 uage 2 page', -0.39794000867203755],\n",
       " ['page 1 pade 2 page', -0.39794000867203755],\n",
       " ['paige 1 pade 2 page', -0.39794000867203755],\n",
       " ['paggi 1 pade 2 page', -0.39794000867203755],\n",
       " ['bagge 1 pade 2 page', -0.39794000867203755],\n",
       " ['hagge 1 pade 2 page', -0.39794000867203755],\n",
       " ['pogge 1 pade 2 page', -0.39794000867203755],\n",
       " ['pagge 1 pade 2 page', -0.39794000867203755],\n",
       " ['page 1 age 2 page', -0.39794000867203755],\n",
       " ['paige 1 age 2 page', -0.39794000867203755],\n",
       " ['paggi 1 age 2 page', -0.39794000867203755],\n",
       " ['bagge 1 age 2 page', -0.39794000867203755],\n",
       " ['hagge 1 age 2 page', -0.39794000867203755],\n",
       " ['pogge 1 age 2 page', -0.39794000867203755],\n",
       " ['pagge 1 age 2 page', -0.39794000867203755],\n",
       " ['page 1 plage 2 page', -0.39794000867203755],\n",
       " ['paige 1 plage 2 page', -0.39794000867203755],\n",
       " ['paggi 1 plage 2 page', -0.39794000867203755],\n",
       " ['bagge 1 plage 2 page', -0.39794000867203755],\n",
       " ['hagge 1 plage 2 page', -0.39794000867203755],\n",
       " ['pogge 1 plage 2 page', -0.39794000867203755],\n",
       " ['pagge 1 plage 2 page', -0.39794000867203755],\n",
       " ['page 1 wage 2 page', -0.39794000867203755],\n",
       " ['paige 1 wage 2 page', -0.39794000867203755],\n",
       " ['paggi 1 wage 2 page', -0.39794000867203755],\n",
       " ['bagge 1 wage 2 page', -0.39794000867203755],\n",
       " ['hagge 1 wage 2 page', -0.39794000867203755],\n",
       " ['pogge 1 wage 2 page', -0.39794000867203755],\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testcg = CandidateGenerator(lm, epm)\n",
    "testcg.get_candidates(\"pagge 1 page 2 page\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure your candidate generator passes the following sanity checks. Feel free to add more tests here as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "cg = CandidateGenerator(lm, epm)\n",
    "query = 'stanford university'\n",
    "num_candidates = 0\n",
    "did_generate_original = False\n",
    "for candidate, candidate_logp in cg.get_candidates(query):\n",
    "    num_candidates += 1\n",
    "    if candidate == query:\n",
    "        did_generate_original = True\n",
    "\n",
    "    assert cg.get_num_oov(query) == 0, \\\n",
    "        \"You should not generate queries with out-of-vocab terms ('{}' has OOV terms)\".format(candidate)\n",
    "\n",
    "assert 1e2 <= num_candidates <= 1e4, \\\n",
    "    \"You should generate between 100 and 10,000 terms (generated {})\".format(num_candidates)\n",
    "\n",
    "assert did_generate_original, \"You should generate the original query ({})\".format(query)\n",
    "\n",
    "### Begin your code\n",
    "\n",
    "### End your code\n",
    "\n",
    "print('All tests passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV.4. Candidate Scorer\n",
    "\n",
    "The candidate scorer's job is to find the most likely query $Q$ given the raw query $R$. It does this by combining the language model for $P(Q)$, the edit probability model for $P(R\\mid Q)$, and the candidate generator (to get candidates for $Q$). Formally, given raw query $R$, the candidate scorer outputs\n",
    "$$\n",
    "    Q^{*} = \\arg\\max_{Q_{i}} P(Q_{i}\\mid R) = \\arg\\max_{Q_{i}} P(R\\mid Q_{i}) P(Q_{i}),\n",
    "$$\n",
    "where the max is taken over candidate queries $Q_{i}\\in\\{Q_1, \\ldots, Q_{n}\\}$ produced by the candidate generator given $R$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV.4.1. Candidate Scorer with Weighting\n",
    "When combining probabilities from the language model and the edit probability model, we can use a parameter to weight the two models differently:\n",
    "$$\n",
    "    P(Q\\mid R)\\propto P(R\\mid Q)P(Q)^{\\mu}.\n",
    "$$\n",
    "Start out with $\\mu = 1$, and then experiment later with different values of $\\mu$ to see which one gives you the best spelling correction accuracy. Again, be careful not to overfit your development dataset. \n",
    "\n",
    "Fill out the following class to complete the spelling corrector with uniform edit cost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%tee submission/candidate_scorer.py\n",
    "\n",
    "class CandidateScorer:\n",
    "    \"\"\"Combines the `LanguageModel`, `EditProbabilityModel`, and\n",
    "    `CandidateGenerator` to produce the most likely query Q given a raw query R.\n",
    "    Since the candidate generator already uses the edit probability model, we\n",
    "    do not need to take the edit probability model as an argument in the constructor.\n",
    "    \"\"\"\n",
    "    def __init__(self, lm, cg, mu=1.):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            lm (LanguageModel): Language model for estimating P(Q).\n",
    "            cg (CandidateGenerator): Candidate generator for generating possible Q.\n",
    "            mu (float): Weighting factor for the language model (see write-up).\n",
    "                Remember that our probability computations are done in log-space.\n",
    "        \"\"\"\n",
    "        self.lm = lm\n",
    "        self.cg = cg\n",
    "        self.mu = mu\n",
    "    \n",
    "    def get_score(self, query, log_edit_prob):\n",
    "        \"\"\"Uses the language model and `log_edit_prob` to compute the final\n",
    "    b    score for a candidate `query`. Uses `mu` as weighting exponent for P(Q).\n",
    "\n",
    "        Args:\n",
    "            query (str): Candidate query.\n",
    "            log_edit_prob (float): Log-probability of candidate query given\n",
    "                original query (i.e., log(P(R|Q), where R is `query`).\n",
    "\n",
    "        Returns:\n",
    "            log_p (float): Final score for the query, i.e., the log-probability\n",
    "                of the query.\n",
    "        \"\"\"\n",
    "        ### Begin your code\n",
    "        \n",
    "        p_q = self.lm.get_query_logp(query)\n",
    "        try:\n",
    "            return log_edit_prob*p_q\n",
    "        except:\n",
    "            return -100 # Why are we returning 100 here?\n",
    "\n",
    "        ### End your code\n",
    "\n",
    "    def correct_spelling(self, r):\n",
    "        \"\"\"Corrects spelling of raw query `r` to get the intended query `q`.\n",
    "\n",
    "        Args:\n",
    "            r (str): Raw input query from the user.\n",
    "\n",
    "        Returns:\n",
    "            q (str): Spell-corrected query. That is, the query that maximizes\n",
    "                P(R|Q)*P(Q) under the language model and edit probability model,\n",
    "                restricted to Q's generated by the candidate generator.\n",
    "        \"\"\"\n",
    "        ### Begin your code\n",
    "        \n",
    "        # generate candidate queries\n",
    "        candidates = self.cg.get_candidates(r) # get candidates here using self.cg\n",
    "        final_scores = [0]*len(candidates)\n",
    "#         for i in candidates:\n",
    "#             final_scores.append(0)\n",
    "            \n",
    "        min_index = 0\n",
    "        for i in range(len(final_scores)):\n",
    "            final_scores[i] = self.get_score(candidates[i][0],candidates[i][1])\n",
    "            if(final_scores[i]<final_scores[min_index]):\n",
    "                min_index = i\n",
    "        '''        \n",
    "        for i in range(len(final_scores)):\n",
    "            print(candidates[i][0], candidates[i][1], final_scores[i])\n",
    "        print(\"\\n#######################################################################################################\\n\")\n",
    "        print(candidates[min_index][0], \"\\t\", final_scores[min_index])\n",
    "        '''\n",
    "        return candidates[min_index][0]\n",
    "\n",
    "        ### End your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building edit probability model...\n",
      "Building candidate generator...\n",
      "Building candidate scorer model...\n",
      "Running spelling corrector...\n",
      "\t'stranford unviersity' corrected to 'stanford university'\n",
      "\t'stanford unviersity' corrected to 'stanford university'\n",
      "\t'sanford university' corrected to 'stanford university'\n",
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Assumes LanguageModel lm was already built above\n",
    "print('Building edit probability model...')\n",
    "epm = UniformEditProbabilityModel()\n",
    "print('Building candidate generator...')\n",
    "cg = CandidateGenerator(lm, epm)\n",
    "print('Building candidate scorer model...')\n",
    "cs = CandidateScorer(lm, cg, mu=1.0)\n",
    "print('Running spelling corrector...')\n",
    "\n",
    "# Add your own queries here to test your spelling corrector\n",
    "queries = [('stranford unviersity', 'stanford university'),\n",
    "             ('stanford unviersity', 'stanford university'),\n",
    "             ('sanford university', 'stanford university')]\n",
    "for query, expected in queries:\n",
    "    corrected = cs.correct_spelling(query)\n",
    "    print(\"\\t'{}' corrected to '{}'\".format(query, corrected))\n",
    "    assert corrected == expected, \"Expected '{}', got '{}'\".format(expected, corrected)\n",
    "print('All tests passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV.4.2. Dev Set Evaluation (Uniform)\n",
    "\n",
    "Now that we have constructed a basic spelling corrector, we will evaluate its performance on the held-out dev set. Recall that the dev set is stored across the files in `pa2-data/dev_set/`:\n",
    "  - `queries.txt`: One raw query $R$ per line.\n",
    "  - `google.txt`: Google's corrected queries $Q$ (one per line, same order as `queries.txt`).\n",
    "  - `gold.txt`: Ground-truth queries $Q$ (again, one per line, same order).\n",
    "  \n",
    "Run the following cells to evaluate your spelling corrector on the dev set using your uniform edit probability model. We will also evaluate your model on a private test set after submission. For full credit, your spelling corrector with uniform edit probability model should achieve accuracy within 1% of the staff implementation *on the test set.* **We do not provide test set queries, but as a guideline for performance, the staff implementation gets 82.42% accuracy on the dev set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dev_eval(candidate_scorer, verbose=False):\n",
    "    \"\"\"Evaluate `candidate_scorer` on the dev set.\"\"\"\n",
    "    query_num = 1\n",
    "    yours_correct = 0\n",
    "    google_correct = 0\n",
    "    # Read originals, ground-truths, Google's predictions\n",
    "    dev_dir = 'pa2-data/dev_set/'\n",
    "    with tqdm(total=455, unit=' queries') as pbar, \\\n",
    "            open(os.path.join(dev_dir, 'queries.txt'), 'r') as query_fh, \\\n",
    "            open(os.path.join(dev_dir, 'gold.txt'), 'r') as gold_fh, \\\n",
    "            open(os.path.join(dev_dir, 'google.txt'), 'r') as google_fh:\n",
    "        while True:\n",
    "            # Read one line\n",
    "            query = query_fh.readline().rstrip('\\n')\n",
    "            print(\"Query = \", query)\n",
    "            if not query:\n",
    "                # Finished all queries\n",
    "                break\n",
    "            corrected = candidate_scorer.correct_spelling(query)\n",
    "            corrected = ' '.join(corrected.split())  # Squash multiple spaces\n",
    "            gold = gold_fh.readline().rstrip('\\n')\n",
    "            google = google_fh.readline().rstrip('\\n')\n",
    "\n",
    "            # Count whether correct\n",
    "            if corrected == gold:\n",
    "                yours_correct += 1\n",
    "            if google == gold:\n",
    "                google_correct += 1\n",
    "\n",
    "            # Print running stats\n",
    "            yours_accuracy = yours_correct / query_num * 100\n",
    "            google_accuracy = google_correct / query_num * 100\n",
    "            if verbose:\n",
    "                print('QUERY {:03d}'.format(query_num))\n",
    "                print('---------')\n",
    "                print('(original):      {}'.format(query))\n",
    "                print('(corrected):     {}'.format(corrected))\n",
    "                print('(google):        {}'.format(google))\n",
    "                print('(gold):          {}'.format(gold))\n",
    "                print('Google accuracy: {}/{} ({:5.2f}%)\\n'\n",
    "                      .format(google_correct, query_num, google_accuracy))\n",
    "                print('Your accuracy:   {}/{} ({:5.2f}%)'\n",
    "                      .format(yours_correct, query_num, yours_accuracy))\n",
    "            \n",
    "            pbar.set_postfix(google='{:5.2f}%'.format(google_accuracy),\n",
    "                             yours='{:5.2f}%'.format(yours_accuracy))\n",
    "            pbar.update()\n",
    "            query_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                             | 0/455 [00:00<?, ? queries/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  quade quad cache xontroller\n",
      "Query =  ['quade', 'quad', 'cache', 'xontroller']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                     | 1/455 [00:00<06:29,  1.17 queries/s, google=100.00%, yours=100.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  co2 in\n",
      "Query =  ['co2', 'in']\n",
      "I =  0\n",
      "I =  1\n",
      "dict_keys([0, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                       | 2/455 [00:01<05:01,  1.50 queries/s, google=50.00%, yours=50.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  powered by blacklight\n",
      "Query =  ['powered', 'by', 'blacklight']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                                       | 3/455 [00:01<05:28,  1.38 queries/s, google=66.67%, yours=66.67%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  mw tth singledays 8 as a result one may\n",
      "Query =  ['mw', 'tth', 'singledays', '8', 'as', 'a', 'result', 'one', 'may']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "I =  8\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                                       | 4/455 [00:06<13:56,  1.85s/ queries, google=50.00%, yours=50.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  when searching databases look for\n",
      "Query =  ['when', 'searching', 'databases', 'look', 'for']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                                       | 5/455 [00:07<12:25,  1.66s/ queries, google=60.00%, yours=60.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  incidence x ray absorption spectrooscopy\n",
      "Query =  ['incidence', 'x', 'ray', 'absorption', 'spectrooscopy']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                      | 6/455 [00:09<13:42,  1.83s/ queries, google=66.67%, yours=66.67%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  floor conf rm bringin our to content stanford univesity\n",
      "Query =  ['floor', 'conf', 'rm', 'bringin', 'our', 'to', 'content', 'stanford', 'univesity']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "I =  8\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▎                                                                                      | 7/455 [00:12<15:33,  2.08s/ queries, google=71.43%, yours=57.14%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  plung from great heights\n",
      "Query =  ['plung', 'from', 'great', 'heights']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                                      | 8/455 [00:13<12:12,  1.64s/ queries, google=75.00%, yours=50.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  what et is\n",
      "Query =  ['what', 'et', 'is']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▋                                                                                      | 9/455 [00:13<09:40,  1.30s/ queries, google=77.78%, yours=44.44%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  case of chained messages theon\n",
      "Query =  ['case', 'of', 'chained', 'messages', 'theon']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▉                                                                                     | 10/455 [00:14<09:12,  1.24s/ queries, google=70.00%, yours=50.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  school of earth sciences\n",
      "Query =  ['school', 'of', 'earth', 'sciences']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                                     | 11/455 [00:15<08:11,  1.11s/ queries, google=72.73%, yours=54.55%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  numbered there is one line\n",
      "Query =  ['numbered', 'there', 'is', 'one', 'line']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▎                                                                                    | 12/455 [00:16<08:08,  1.10s/ queries, google=75.00%, yours=58.33%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  artificially created entities\n",
      "Query =  ['artificially', 'created', 'entities']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▍                                                                                    | 13/455 [00:18<09:06,  1.24s/ queries, google=76.92%, yours=61.54%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  koret pavilion taube hellel house\n",
      "Query =  ['koret', 'pavilion', 'taube', 'hellel', 'house']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▋                                                                                    | 14/455 [00:19<08:32,  1.16s/ queries, google=78.57%, yours=64.29%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the fast paths\n",
      "Query =  ['the', 'fast', 'paths']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▊                                                                                    | 15/455 [00:19<06:46,  1.08 queries/s, google=80.00%, yours=66.67%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  hilton 5 14 03 webmaster recital hall map audience genral\n",
      "Query =  ['hilton', '5', '14', '03', 'webmaster', 'recital', 'hall', 'map', 'audience', 'genral']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "I =  8\n",
      "I =  9\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███                                                                                    | 16/455 [00:23<13:06,  1.79s/ queries, google=81.25%, yours=62.50%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  community partnerships renew & new\n",
      "Query =  ['community', 'partnerships', 'renew', '&', 'new']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                                   | 17/455 [00:24<12:14,  1.68s/ queries, google=76.47%, yours=64.71%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  pagge 1 page 2 page\n",
      "Query =  ['pagge', '1', 'page', '2', 'page']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▍                                                                                   | 18/455 [00:28<15:59,  2.20s/ queries, google=77.78%, yours=61.11%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  medows june 2004 halfway up\n",
      "Query =  ['medows', 'june', '2004', 'halfway', 'up']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▋                                                                                   | 19/455 [00:29<13:49,  1.90s/ queries, google=78.95%, yours=63.16%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  senor networks proceedings\n",
      "Query =  ['senor', 'networks', 'proceedings']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▊                                                                                   | 20/455 [00:30<11:55,  1.64s/ queries, google=80.00%, yours=65.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  forign affairs reporter the age\n",
      "Query =  ['forign', 'affairs', 'reporter', 'the', 'age']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████                                                                                   | 21/455 [00:34<16:09,  2.23s/ queries, google=80.95%, yours=61.90%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  they have not explictly\n",
      "Query =  ['they', 'have', 'not', 'explictly']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▏                                                                                  | 22/455 [00:35<15:13,  2.11s/ queries, google=77.27%, yours=63.64%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  t41 t 42 a43\n",
      "Query =  ['t41', 't', '42', 'a43']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▍                                                                                  | 23/455 [00:37<14:17,  1.99s/ queries, google=78.26%, yours=60.87%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  invalueable way to see what\n",
      "Query =  ['invalueable', 'way', 'to', 'see', 'what']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▌                                                                                  | 24/455 [00:40<15:47,  2.20s/ queries, google=79.17%, yours=62.50%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  huang qixing huang evangelos kalogerakis\n",
      "Query =  ['huang', 'qixing', 'huang', 'evangelos', 'kalogerakis']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▊                                                                                  | 25/455 [00:41<14:10,  1.98s/ queries, google=80.00%, yours=64.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  cife summer program2012\n",
      "Query =  ['cife', 'summer', 'program2012']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▉                                                                                  | 26/455 [00:42<12:03,  1.69s/ queries, google=80.77%, yours=61.54%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  university's faculty in 1962\n",
      "Query =  [\"university's\", 'faculty', 'in', '1962']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▏                                                                                 | 27/455 [00:45<13:17,  1.86s/ queries, google=81.48%, yours=62.96%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  serrast stanford ca\n",
      "Query =  ['serrast', 'stanford', 'ca']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▎                                                                                 | 28/455 [00:48<15:56,  2.24s/ queries, google=82.14%, yours=60.71%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  argue that fx purchases\n",
      "Query =  ['argue', 'that', 'fx', 'purchases']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▌                                                                                 | 29/455 [00:49<13:53,  1.96s/ queries, google=82.76%, yours=62.07%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  service contribution pleaze\n",
      "Query =  ['service', 'contribution', 'pleaze']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▋                                                                                 | 30/455 [00:50<12:02,  1.70s/ queries, google=80.00%, yours=63.33%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  european conference on machine\n",
      "Query =  ['european', 'conference', 'on', 'machine']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▉                                                                                 | 31/455 [00:52<12:50,  1.82s/ queries, google=80.65%, yours=64.52%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  son to a\n",
      "Query =  ['son', 'to', 'a']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████                                                                                 | 32/455 [00:53<11:25,  1.62s/ queries, google=78.12%, yours=62.50%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the proposes water\n",
      "Query =  ['the', 'proposes', 'water']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▎                                                                                | 33/455 [00:54<09:25,  1.34s/ queries, google=78.79%, yours=63.64%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the network desktop hardware and usda 1907 click\n",
      "Query =  ['the', 'network', 'desktop', 'hardware', 'and', 'usda', '1907', 'click']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▌                                                                                | 34/455 [00:56<11:22,  1.62s/ queries, google=79.41%, yours=64.71%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  a person services health\n",
      "Query =  ['a', 'person', 'services', 'health']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▋                                                                                | 35/455 [00:57<10:16,  1.47s/ queries, google=80.00%, yours=65.71%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  institute for international\n",
      "Query =  ['institute', 'for', 'international']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▉                                                                                | 36/455 [01:00<11:43,  1.68s/ queries, google=80.56%, yours=66.67%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  of the university registrar\n",
      "Query =  ['of', 'the', 'university', 'registrar']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████                                                                                | 37/455 [01:02<12:31,  1.80s/ queries, google=81.08%, yours=67.57%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  ddlm 2004 as you can\n",
      "Query =  ['ddlm', '2004', 'as', 'you', 'can']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███████▎                                                                               | 38/455 [01:03<12:31,  1.80s/ queries, google=78.95%, yours=68.42%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  been argues that the transformation\n",
      "Query =  ['been', 'argues', 'that', 'the', 'transformation']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▍                                                                               | 39/455 [01:06<14:04,  2.03s/ queries, google=79.49%, yours=69.23%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  urls of a posting and\n",
      "Query =  ['urls', 'of', 'a', 'posting', 'and']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▋                                                                               | 40/455 [01:08<13:11,  1.91s/ queries, google=80.00%, yours=70.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  with geant4 i\n",
      "Query =  ['with', 'geant4', 'i']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▊                                                                               | 41/455 [01:08<10:31,  1.52s/ queries, google=80.49%, yours=70.73%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  2012 stanford university system requirements\n",
      "Query =  ['2012', 'stanford', 'university', 'system', 'requirements']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████                                                                               | 42/455 [01:10<12:02,  1.75s/ queries, google=80.95%, yours=71.43%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  to visit the froze\n",
      "Query =  ['to', 'visit', 'the', 'froze']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████████▏                                                                              | 43/455 [01:11<10:13,  1.49s/ queries, google=79.07%, yours=69.77%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  channel podcasts panel discussion kqed's\n",
      "Query =  ['channel', 'podcasts', 'panel', 'discussion', \"kqed's\"]\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▍                                                                              | 44/455 [01:13<09:56,  1.45s/ queries, google=79.55%, yours=70.45%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  courses dfj etl lectures mayfield\n",
      "Query =  ['courses', 'dfj', 'etl', 'lectures', 'mayfield']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▌                                                                              | 45/455 [01:14<09:25,  1.38s/ queries, google=80.00%, yours=71.11%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  address is there an easy\n",
      "Query =  ['address', 'is', 'there', 'an', 'easy']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▊                                                                              | 46/455 [01:16<10:30,  1.54s/ queries, google=80.43%, yours=71.74%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  theend of an\n",
      "Query =  ['theend', 'of', 'an']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▉                                                                              | 47/455 [01:16<08:16,  1.22s/ queries, google=80.85%, yours=70.21%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  effort comercial human\n",
      "Query =  ['effort', 'comercial', 'human']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▏                                                                             | 48/455 [01:17<07:15,  1.07s/ queries, google=81.25%, yours=70.83%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  symposium detector development\n",
      "Query =  ['symposium', 'detector', 'development']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▎                                                                             | 49/455 [01:18<07:46,  1.15s/ queries, google=81.63%, yours=71.43%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  students academic programs student activiies guide lines slac i 730 0a21t\n",
      "Query =  ['students', 'academic', 'programs', 'student', 'activiies', 'guide', 'lines', 'slac', 'i', '730', '0a21t']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "I =  8\n",
      "I =  9\n",
      "I =  10\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▌                                                                             | 50/455 [01:22<12:18,  1.82s/ queries, google=82.00%, yours=70.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  students faculty & staff\n",
      "Query =  ['students', 'faculty', '&', 'staff']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▊                                                                             | 51/455 [01:23<10:38,  1.58s/ queries, google=82.35%, yours=70.59%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  for descovering and confirming in\n",
      "Query =  ['for', 'descovering', 'and', 'confirming', 'in']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█████████▉                                                                             | 52/455 [01:25<10:52,  1.62s/ queries, google=82.69%, yours=69.23%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  culure parameters and the\n",
      "Query =  ['culure', 'parameters', 'and', 'the']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▏                                                                            | 53/455 [01:26<10:40,  1.59s/ queries, google=83.02%, yours=69.81%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  no text full text\n",
      "Query =  ['no', 'text', 'full', 'text']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▎                                                                            | 54/455 [01:27<08:58,  1.34s/ queries, google=83.33%, yours=70.37%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  by modern millitary forces\n",
      "Query =  ['by', 'modern', 'millitary', 'forces']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▌                                                                            | 55/455 [01:28<08:30,  1.28s/ queries, google=83.64%, yours=69.09%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  information in the\n",
      "Query =  ['information', 'in', 'the']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▋                                                                            | 56/455 [01:30<09:34,  1.44s/ queries, google=83.93%, yours=69.64%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  services available througha off campus\n",
      "Query =  ['services', 'available', 'througha', 'off', 'campus']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████▉                                                                            | 57/455 [01:31<09:42,  1.46s/ queries, google=84.21%, yours=70.18%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  of pension fundsaving\n",
      "Query =  ['of', 'pension', 'fundsaving']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████                                                                            | 58/455 [01:32<08:29,  1.28s/ queries, google=84.48%, yours=68.97%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  j biol chem 1999\n",
      "Query =  ['j', 'biol', 'chem', '1999']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▎                                                                           | 59/455 [01:33<06:54,  1.05s/ queries, google=84.75%, yours=69.49%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  blog cs 193p iphone\n",
      "Query =  ['blog', 'cs', '193p', 'iphone']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▍                                                                           | 60/455 [01:33<05:48,  1.13 queries/s, google=85.00%, yours=70.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  3 technology 4 performance\n",
      "Query =  ['3', 'technology', '4', 'performance']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████▋                                                                           | 61/455 [01:35<07:15,  1.11s/ queries, google=85.25%, yours=70.49%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  to creating your first ontology\n",
      "Query =  ['to', 'creating', 'your', 'first', 'ontology']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████▊                                                                           | 62/455 [01:36<07:10,  1.10s/ queries, google=85.48%, yours=70.97%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  10 ubv 2\n",
      "Query =  ['10', 'ubv', '2']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████                                                                           | 63/455 [01:36<05:30,  1.19 queries/s, google=84.13%, yours=69.84%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  for sevial many abandoned\n",
      "Query =  ['for', 'sevial', 'many', 'abandoned']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▏                                                                          | 64/455 [01:37<05:28,  1.19 queries/s, google=82.81%, yours=68.75%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  are being investigated\n",
      "Query =  ['are', 'being', 'investigated']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████▍                                                                          | 65/455 [01:38<05:49,  1.12 queries/s, google=83.08%, yours=69.23%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  study of india 2008 much\n",
      "Query =  ['study', 'of', 'india', '2008', 'much']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▌                                                                          | 66/455 [01:39<06:04,  1.07 queries/s, google=83.33%, yours=69.70%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  read more no subscription requied\n",
      "Query =  ['read', 'more', 'no', 'subscription', 'requied']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▊                                                                          | 67/455 [01:41<07:53,  1.22s/ queries, google=83.58%, yours=68.66%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the software development community at\n",
      "Query =  ['the', 'software', 'development', 'community', 'at']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████                                                                          | 68/455 [01:43<09:02,  1.40s/ queries, google=83.82%, yours=69.12%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  of acual projects\n",
      "Query =  ['of', 'acual', 'projects']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▏                                                                         | 69/455 [01:43<07:20,  1.14s/ queries, google=84.06%, yours=69.57%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  continued to attrect\n",
      "Query =  ['continued', 'to', 'attrect']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████████▍                                                                         | 70/455 [01:44<06:38,  1.03s/ queries, google=84.29%, yours=68.57%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  conference lina khatib larry dimon assoc prof sean\n",
      "Query =  ['conference', 'lina', 'khatib', 'larry', 'dimon', 'assoc', 'prof', 'sean']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▌                                                                         | 71/455 [01:46<07:41,  1.20s/ queries, google=84.51%, yours=67.61%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  nathan abbott way\n",
      "Query =  ['nathan', 'abbott', 'way']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▊                                                                         | 72/455 [01:46<06:22,  1.00 queries/s, google=84.72%, yours=68.06%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  humanities and sciences\n",
      "Query =  ['humanities', 'and', 'sciences']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▉                                                                         | 73/455 [01:47<06:19,  1.01 queries/s, google=84.93%, yours=68.49%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  pert1is the panalytical x pert\n",
      "Query =  ['pert1is', 'the', 'panalytical', 'x', 'pert']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▏                                                                        | 74/455 [01:49<07:14,  1.14s/ queries, google=83.78%, yours=68.92%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  applied to blood flow\n",
      "Query =  ['applied', 'to', 'blood', 'flow']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████████████▎                                                                        | 75/455 [01:49<06:26,  1.02s/ queries, google=84.00%, yours=69.33%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  union paces but we\n",
      "Query =  ['union', 'paces', 'but', 'we']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████▌                                                                        | 76/455 [01:50<05:27,  1.16 queries/s, google=82.89%, yours=68.42%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  data from brovser opera then\n",
      "Query =  ['data', 'from', 'brovser', 'opera', 'then']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████▋                                                                        | 77/455 [01:51<05:20,  1.18 queries/s, google=83.12%, yours=68.83%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  proceedings topocs publications academic writing\n",
      "Query =  ['proceedings', 'topocs', 'publications', 'academic', 'writing']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████▉                                                                        | 78/455 [01:53<08:42,  1.39s/ queries, google=83.33%, yours=69.23%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  sulait home su\n",
      "Query =  ['sulait', 'home', 'su']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████████                                                                        | 79/455 [01:54<07:06,  1.13s/ queries, google=82.28%, yours=69.62%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  series searchworks strat\n",
      "Query =  ['series', 'searchworks', 'strat']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████▎                                                                       | 80/455 [01:55<06:45,  1.08s/ queries, google=81.25%, yours=70.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  cardwith at\n",
      "Query =  ['cardwith', 'at']\n",
      "I =  0\n",
      "I =  1\n",
      "dict_keys([0, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████▍                                                                       | 81/455 [01:55<05:28,  1.14 queries/s, google=81.48%, yours=69.14%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the houseof\n",
      "Query =  ['the', 'houseof']\n",
      "I =  0\n",
      "I =  1\n",
      "dict_keys([0, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████▋                                                                       | 82/455 [01:56<04:29,  1.38 queries/s, google=81.71%, yours=68.29%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  more free wheeling said roberts a\n",
      "Query =  ['more', 'free', 'wheeling', 'said', 'roberts', 'a']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "dict_keys([0, 1, 2, 3, 4, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████▊                                                                       | 83/455 [01:57<06:32,  1.06s/ queries, google=80.72%, yours=67.47%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the portrait page format postscript athlete if yes please\n",
      "Query =  ['the', 'portrait', 'page', 'format', 'postscript', 'athlete', 'if', 'yes', 'please']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "I =  8\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████                                                                       | 84/455 [02:00<10:16,  1.66s/ queries, google=80.95%, yours=67.86%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  california 94305 4121 650.725 1575\n",
      "Query =  ['california', '94305', '4121', '650.725', '1575']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████▎                                                                      | 85/455 [02:02<09:51,  1.60s/ queries, google=81.18%, yours=68.24%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  facilities bechtel confernce\n",
      "Query =  ['facilities', 'bechtel', 'confernce']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████▍                                                                      | 86/455 [02:03<09:02,  1.47s/ queries, google=81.40%, yours=68.60%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the atmosphere and renwable energy\n",
      "Query =  ['the', 'atmosphere', 'and', 'renwable', 'energy']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████▋                                                                      | 87/455 [02:04<08:39,  1.41s/ queries, google=81.61%, yours=68.97%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  results are adirect\n",
      "Query =  ['results', 'are', 'adirect']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████████▊                                                                      | 88/455 [02:05<07:16,  1.19s/ queries, google=81.82%, yours=68.18%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the frist paper i discuss\n",
      "Query =  ['the', 'frist', 'paper', 'i', 'discuss']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████                                                                      | 89/455 [02:06<06:52,  1.13s/ queries, google=82.02%, yours=68.54%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  winter _____ spring _____ summer\n",
      "Query =  ['winter', '_____', 'spring', '_____', 'summer']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▏                                                                     | 90/455 [02:07<06:10,  1.01s/ queries, google=82.22%, yours=68.89%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  wire mesh to hold\n",
      "Query =  ['wire', 'mesh', 'to', 'hold']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▍                                                                     | 91/455 [02:07<05:14,  1.16 queries/s, google=82.42%, yours=69.23%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  and the program\n",
      "Query =  ['and', 'the', 'program']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▌                                                                     | 92/455 [02:08<04:57,  1.22 queries/s, google=82.61%, yours=69.57%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  california boating safety\n",
      "Query =  ['california', 'boating', 'safety']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▊                                                                     | 93/455 [02:09<05:04,  1.19 queries/s, google=82.80%, yours=69.89%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  operations manager mary\n",
      "Query =  ['operations', 'manager', 'mary']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████████████████▉                                                                     | 94/455 [02:10<05:11,  1.16 queries/s, google=82.98%, yours=70.21%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the interaction greatly influences\n",
      "Query =  ['the', 'interaction', 'greatly', 'influences']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▏                                                                    | 95/455 [02:11<06:21,  1.06s/ queries, google=83.16%, yours=70.53%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  models underestimate the\n",
      "Query =  ['models', 'underestimate', 'the']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▎                                                                    | 96/455 [02:12<06:21,  1.06s/ queries, google=83.33%, yours=70.83%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  navigation contract support computer resource\n",
      "Query =  ['navigation', 'contract', 'support', 'computer', 'resource']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████████████████▌                                                                    | 97/455 [02:14<07:27,  1.25s/ queries, google=83.51%, yours=71.13%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  tocquevilles democracy in america related\n",
      "Query =  ['tocquevilles', 'democracy', 'in', 'america', 'related']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████▋                                                                    | 98/455 [02:16<08:47,  1.48s/ queries, google=83.67%, yours=70.41%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  established in1994 to\n",
      "Query =  ['established', 'in1994', 'to']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████▉                                                                    | 99/455 [02:17<07:44,  1.31s/ queries, google=83.84%, yours=69.70%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  suitedin purpose programmes bring faculty members\n",
      "Query =  ['suitedin', 'purpose', 'programmes', 'bring', 'faculty', 'members']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "dict_keys([0, 1, 2, 3, 4, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████▉                                                                   | 100/455 [02:19<08:53,  1.50s/ queries, google=83.00%, yours=69.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  foreign language standards\n",
      "Query =  ['foreign', 'language', 'standards']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████                                                                   | 101/455 [02:20<08:16,  1.40s/ queries, google=83.17%, yours=69.31%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  optical science amo in\n",
      "Query =  ['optical', 'science', 'amo', 'in']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████▎                                                                  | 102/455 [02:21<07:18,  1.24s/ queries, google=83.33%, yours=69.61%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  199708041649 laa10477 havarti cs\n",
      "Query =  ['199708041649', 'laa10477', 'havarti', 'cs']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████▍                                                                  | 103/455 [02:22<07:19,  1.25s/ queries, google=83.50%, yours=69.90%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  prograns program on\n",
      "Query =  ['prograns', 'program', 'on']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████▋                                                                  | 104/455 [02:23<06:53,  1.18s/ queries, google=83.65%, yours=69.23%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  training axes oracle financials reportmart\n",
      "Query =  ['training', 'axes', 'oracle', 'financials', 'reportmart']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████████████▊                                                                  | 105/455 [02:26<08:55,  1.53s/ queries, google=82.86%, yours=69.52%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  by catagery forums by time stanford the standford office\n",
      "Query =  ['by', 'catagery', 'forums', 'by', 'time', 'stanford', 'the', 'standford', 'office']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "I =  8\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████████                                                                  | 106/455 [02:30<13:28,  2.32s/ queries, google=83.02%, yours=68.87%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  in car use\n",
      "Query =  ['in', 'car', 'use']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████▏                                                                 | 107/455 [02:30<10:20,  1.78s/ queries, google=83.18%, yours=69.16%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  using clack network eds people publications resaerch other\n",
      "Query =  ['using', 'clack', 'network', 'eds', 'people', 'publications', 'resaerch', 'other']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████▍                                                                 | 108/455 [02:33<11:05,  1.92s/ queries, google=82.41%, yours=69.44%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  author guide fgst author dog factors that contribute to\n",
      "Query =  ['author', 'guide', 'fgst', 'author', 'dog', 'factors', 'that', 'contribute', 'to']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "I =  8\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████▌                                                                 | 109/455 [02:35<11:34,  2.01s/ queries, google=82.57%, yours=68.81%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  section 7.5 ft\n",
      "Query =  ['section', '7.5', 'ft']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████▊                                                                 | 110/455 [02:35<09:21,  1.63s/ queries, google=82.73%, yours=69.09%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  t f\n",
      "Query =  ['t', 'f']\n",
      "I =  0\n",
      "I =  1\n",
      "dict_keys([0, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████▉                                                                 | 111/455 [02:36<06:47,  1.19s/ queries, google=81.98%, yours=68.47%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  poon balaji prabhakar electrical\n",
      "Query =  ['poon', 'balaji', 'prabhakar', 'electrical']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████▏                                                                | 112/455 [02:37<06:42,  1.17s/ queries, google=82.14%, yours=68.75%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  abstract a crucial lemma in\n",
      "Query =  ['abstract', 'a', 'crucial', 'lemma', 'in']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████▎                                                                | 113/455 [02:38<06:52,  1.21s/ queries, google=82.30%, yours=69.03%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  highalnd refer the relationship\n",
      "Query =  ['highalnd', 'refer', 'the', 'relationship']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████▌                                                                | 114/455 [02:39<07:02,  1.24s/ queries, google=82.46%, yours=69.30%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  useful copyright charts and tools\n",
      "Query =  ['useful', 'copyright', 'charts', 'and', 'tools']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████▋                                                                | 115/455 [02:41<07:20,  1.30s/ queries, google=82.61%, yours=69.57%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  of a wide on how we\n",
      "Query =  ['of', 'a', 'wide', 'on', 'how', 'we']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "dict_keys([0, 1, 2, 3, 4, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████████▉                                                                | 116/455 [02:43<09:11,  1.63s/ queries, google=82.76%, yours=69.83%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  speakers to say smething one\n",
      "Query =  ['speakers', 'to', 'say', 'smething', 'one']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████████                                                                | 117/455 [02:45<09:28,  1.68s/ queries, google=82.91%, yours=69.23%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  stsm at ssrl under\n",
      "Query =  ['stsm', 'at', 'ssrl', 'under']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████████▎                                                               | 118/455 [02:46<07:32,  1.34s/ queries, google=82.20%, yours=68.64%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  chicken tenders the heisman\n",
      "Query =  ['chicken', 'tenders', 'the', 'heisman']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████████▍                                                               | 119/455 [02:46<06:44,  1.20s/ queries, google=82.35%, yours=68.91%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  rports by author\n",
      "Query =  ['rports', 'by', 'author']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████████▋                                                               | 120/455 [02:47<05:50,  1.05s/ queries, google=82.50%, yours=69.17%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  regional opinions blogs\n",
      "Query =  ['regional', 'opinions', 'blogs']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████████▊                                                               | 121/455 [02:48<05:32,  1.00 queries/s, google=82.64%, yours=69.42%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  rss increas text size\n",
      "Query =  ['rss', 'increas', 'text', 'size']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████████                                                               | 122/455 [02:49<05:08,  1.08 queries/s, google=81.97%, yours=69.67%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the costs and benifits of\n",
      "Query =  ['the', 'costs', 'and', 'benifits', 'of']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████████▏                                                              | 123/455 [02:50<06:18,  1.14s/ queries, google=82.11%, yours=69.11%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  impacts of global warming q&a\n",
      "Query =  ['impacts', 'of', 'global', 'warming', 'q&a']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████████▍                                                              | 124/455 [02:51<06:04,  1.10s/ queries, google=82.26%, yours=69.35%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  on serra turn right on\n",
      "Query =  ['on', 'serra', 'turn', 'right', 'on']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████████████████▋                                                              | 125/455 [02:53<06:26,  1.17s/ queries, google=81.60%, yours=69.60%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  contnt of this frame at kenji haertel edward krumboltz john\n",
      "Query =  ['contnt', 'of', 'this', 'frame', 'at', 'kenji', 'haertel', 'edward', 'krumboltz', 'john']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "I =  8\n",
      "I =  9\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████████████████▊                                                              | 126/455 [02:55<08:43,  1.59s/ queries, google=81.75%, yours=69.84%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  from the salon slides\n",
      "Query =  ['from', 'the', 'salon', 'slides']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████████                                                              | 127/455 [02:56<07:36,  1.39s/ queries, google=81.89%, yours=70.08%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the ring and on the\n",
      "Query =  ['the', 'ring', 'and', 'on', 'the']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████████▏                                                             | 128/455 [02:58<08:24,  1.54s/ queries, google=82.03%, yours=70.31%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  provides onlymild security\n",
      "Query =  ['provides', 'onlymild', 'security']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████████▍                                                             | 129/455 [02:59<07:20,  1.35s/ queries, google=82.17%, yours=69.77%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  ksb search the research opportunities usefull\n",
      "Query =  ['ksb', 'search', 'the', 'research', 'opportunities', 'usefull']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "dict_keys([0, 1, 2, 3, 4, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████████████████▌                                                             | 130/455 [03:02<09:39,  1.78s/ queries, google=81.54%, yours=70.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  tim don ph\n",
      "Query =  ['tim', 'don', 'ph']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████████████████▊                                                             | 131/455 [03:02<07:44,  1.43s/ queries, google=80.92%, yours=70.23%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  stanford gsb skip to nontent\n",
      "Query =  ['stanford', 'gsb', 'skip', 'to', 'nontent']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████████████████▉                                                             | 132/455 [03:04<07:13,  1.34s/ queries, google=81.06%, yours=70.45%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  dispatch of physiciannurse\n",
      "Query =  ['dispatch', 'of', 'physiciannurse']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████▏                                                            | 133/455 [03:05<07:25,  1.38s/ queries, google=81.20%, yours=69.92%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  food vs energy he\n",
      "Query =  ['food', 'vs', 'energy', 'he']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████▎                                                            | 134/455 [03:06<06:37,  1.24s/ queries, google=81.34%, yours=70.15%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  aegean sea in this well\n",
      "Query =  ['aegean', 'sea', 'in', 'this', 'well']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████▌                                                            | 135/455 [03:07<06:38,  1.24s/ queries, google=81.48%, yours=70.37%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  linguistic information plays\n",
      "Query =  ['linguistic', 'information', 'plays']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████▋                                                            | 136/455 [03:08<06:34,  1.24s/ queries, google=81.62%, yours=70.59%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  on theaper\n",
      "Query =  ['on', 'theaper']\n",
      "I =  0\n",
      "I =  1\n",
      "dict_keys([0, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████▉                                                            | 137/455 [03:09<05:04,  1.04 queries/s, google=81.02%, yours=70.07%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  content related content stanford university\n",
      "Query =  ['content', 'related', 'content', 'stanford', 'university']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████████                                                            | 138/455 [03:10<06:13,  1.18s/ queries, google=81.16%, yours=70.29%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  opportunties for motivated grad\n",
      "Query =  ['opportunties', 'for', 'motivated', 'grad']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|██████████████████████████▎                                                           | 139/455 [03:13<07:45,  1.47s/ queries, google=81.29%, yours=70.50%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  nhow for our four from\n",
      "Query =  ['nhow', 'for', 'our', 'four', 'from']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|██████████████████████████▍                                                           | 140/455 [03:13<06:48,  1.30s/ queries, google=80.71%, yours=70.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  thepper arm\n",
      "Query =  ['thepper', 'arm']\n",
      "I =  0\n",
      "I =  1\n",
      "dict_keys([0, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|██████████████████████████▋                                                           | 141/455 [03:14<05:15,  1.01s/ queries, google=80.14%, yours=69.50%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  center on food security\n",
      "Query =  ['center', 'on', 'food', 'security']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|██████████████████████████▊                                                           | 142/455 [03:16<06:37,  1.27s/ queries, google=80.28%, yours=69.72%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  up messeges are the xerox mouse\n",
      "Query =  ['up', 'messeges', 'are', 'the', 'xerox', 'mouse']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "dict_keys([0, 1, 2, 3, 4, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████████████████████                                                           | 143/455 [03:18<08:20,  1.60s/ queries, google=80.42%, yours=69.93%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  many nothave permission to\n",
      "Query =  ['many', 'nothave', 'permission', 'to']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████████▏                                                          | 144/455 [03:19<07:31,  1.45s/ queries, google=80.56%, yours=69.44%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  where she manged\n",
      "Query =  ['where', 'she', 'manged']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████████▍                                                          | 145/455 [03:20<06:11,  1.20s/ queries, google=80.69%, yours=68.97%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  304669 101719 4063882026 75360\n",
      "Query =  ['304669', '101719', '4063882026', '75360']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████████▌                                                          | 146/455 [03:21<05:53,  1.15s/ queries, google=80.14%, yours=68.49%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  football rollerblading tennis program see also\n",
      "Query =  ['football', 'rollerblading', 'tennis', 'program', 'see', 'also']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "dict_keys([0, 1, 2, 3, 4, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████████▊                                                          | 147/455 [03:23<07:13,  1.41s/ queries, google=80.27%, yours=68.71%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  data from browser\n",
      "Query =  ['data', 'from', 'browser']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████████▉                                                          | 148/455 [03:23<05:42,  1.12s/ queries, google=80.41%, yours=68.92%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  from shaw university in 1927\n",
      "Query =  ['from', 'shaw', 'university', 'in', '1927']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████▏                                                         | 149/455 [03:25<06:40,  1.31s/ queries, google=80.54%, yours=69.13%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  schlors as the\n",
      "Query =  ['schlors', 'as', 'the']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████▎                                                         | 150/455 [03:26<05:31,  1.09s/ queries, google=80.67%, yours=69.33%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  officers join alumni\n",
      "Query =  ['officers', 'join', 'alumni']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████▌                                                         | 151/455 [03:26<04:50,  1.05 queries/s, google=80.79%, yours=69.54%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  cassman pa mattson jin shun\n",
      "Query =  ['cassman', 'pa', 'mattson', 'jin', 'shun']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████████████████████▋                                                         | 152/455 [03:27<05:11,  1.03s/ queries, google=80.26%, yours=69.74%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  does not support the\n",
      "Query =  ['does', 'not', 'support', 'the']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████████████████▉                                                         | 153/455 [03:28<04:53,  1.03 queries/s, google=80.39%, yours=69.93%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  group supri d alternative website the body whuch is low\n",
      "Query =  ['group', 'supri', 'd', 'alternative', 'website', 'the', 'body', 'whuch', 'is', 'low']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "I =  8\n",
      "I =  9\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████████                                                         | 154/455 [03:32<08:33,  1.71s/ queries, google=80.52%, yours=69.48%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  ice ph d ice ph\n",
      "Query =  ['ice', 'ph', 'd', 'ice', 'ph']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████████▎                                                        | 155/455 [03:33<07:56,  1.59s/ queries, google=80.00%, yours=69.68%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  as that is the\n",
      "Query =  ['as', 'that', 'is', 'the']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████████▍                                                        | 156/455 [03:36<09:18,  1.87s/ queries, google=80.13%, yours=69.87%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  david l jaffee ms and\n",
      "Query =  ['david', 'l', 'jaffee', 'ms', 'and']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████▋                                                        | 157/455 [03:37<08:05,  1.63s/ queries, google=80.25%, yours=70.06%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  privilege on the column grantable\n",
      "Query =  ['privilege', 'on', 'the', 'column', 'grantable']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████████▊                                                        | 158/455 [03:38<07:45,  1.57s/ queries, google=80.38%, yours=70.25%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  gamma exposure constant is\n",
      "Query =  ['gamma', 'exposure', 'constant', 'is']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████████                                                        | 159/455 [03:39<06:56,  1.41s/ queries, google=80.50%, yours=70.44%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  market gardans as a\n",
      "Query =  ['market', 'gardans', 'as', 'a']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████████▏                                                       | 160/455 [03:40<05:51,  1.19s/ queries, google=80.62%, yours=70.62%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  may also be of intrest\n",
      "Query =  ['may', 'also', 'be', 'of', 'intrest']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████████▍                                                       | 161/455 [03:41<06:06,  1.25s/ queries, google=80.75%, yours=70.81%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  request form staff directorys\n",
      "Query =  ['request', 'form', 'staff', 'directorys']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████████████████████▌                                                       | 162/455 [03:42<05:49,  1.19s/ queries, google=80.25%, yours=70.99%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  come to more recent university economics departlment stanford center\n",
      "Query =  ['come', 'to', 'more', 'recent', 'university', 'economics', 'departlment', 'stanford', 'center']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "I =  8\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████████████████████▊                                                       | 163/455 [03:46<09:17,  1.91s/ queries, google=80.37%, yours=71.17%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  1 academic interview handout\n",
      "Query =  ['1', 'academic', 'interview', 'handout']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████████████████████▉                                                       | 164/455 [03:47<08:17,  1.71s/ queries, google=80.49%, yours=71.34%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  process message re transportation\n",
      "Query =  ['process', 'message', 're', 'transportation']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████▏                                                      | 165/455 [03:49<08:30,  1.76s/ queries, google=80.61%, yours=71.52%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  aims to provllde users with swrl unified theories+\n",
      "Query =  ['aims', 'to', 'provllde', 'users', 'with', 'swrl', 'unified', 'theories+']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████████████████████▍                                                      | 166/455 [03:51<08:37,  1.79s/ queries, google=80.72%, yours=71.08%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the john m olin postings and threads click\n",
      "Query =  ['the', 'john', 'm', 'olin', 'postings', 'and', 'threads', 'click']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████████▌                                                      | 167/455 [03:53<09:29,  1.98s/ queries, google=80.84%, yours=71.26%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  events tadsahi fukami historical contingency\n",
      "Query =  ['events', 'tadsahi', 'fukami', 'historical', 'contingency']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████████▊                                                      | 168/455 [03:55<08:55,  1.87s/ queries, google=80.95%, yours=71.43%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  list an d index society cd1040 file the verisions with green\n",
      "Query =  ['list', 'an', 'd', 'index', 'society', 'cd1040', 'file', 'the', 'verisions', 'with', 'green']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "I =  8\n",
      "I =  9\n",
      "I =  10\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████████████▉                                                      | 169/455 [04:00<13:53,  2.92s/ queries, google=81.07%, yours=71.01%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  ish a great tool\n",
      "Query =  ['ish', 'a', 'great', 'tool']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|████████████████████████████████▏                                                     | 170/455 [04:01<10:26,  2.20s/ queries, google=81.18%, yours=71.18%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  for ubuntu 11.04 proveding an oppertunity\n",
      "Query =  ['for', 'ubuntu', '11.04', 'proveding', 'an', 'oppertunity']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "dict_keys([0, 1, 2, 3, 4, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████████▎                                                     | 171/455 [04:02<09:34,  2.02s/ queries, google=81.29%, yours=71.35%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the cdd a social\n",
      "Query =  ['the', 'cdd', 'a', 'social']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████████▌                                                     | 172/455 [04:03<07:54,  1.68s/ queries, google=81.40%, yours=71.51%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  4581 fad 650 725 2592\n",
      "Query =  ['4581', 'fad', '650', '725', '2592']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████████▋                                                     | 173/455 [04:04<06:58,  1.48s/ queries, google=80.92%, yours=71.68%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  of newpor and\n",
      "Query =  ['of', 'newpor', 'and']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████████▉                                                     | 174/455 [04:05<05:26,  1.16s/ queries, google=81.03%, yours=71.26%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  morabito australian unions the\n",
      "Query =  ['morabito', 'australian', 'unions', 'the']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|█████████████████████████████████                                                     | 175/455 [04:06<05:20,  1.14s/ queries, google=81.14%, yours=71.43%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  members all pertinent information that\n",
      "Query =  ['members', 'all', 'pertinent', 'information', 'that']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|█████████████████████████████████▎                                                    | 176/455 [04:09<08:59,  1.93s/ queries, google=81.25%, yours=71.59%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  on call rooms graduate medical\n",
      "Query =  ['on', 'call', 'rooms', 'graduate', 'medical']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|█████████████████████████████████▍                                                    | 177/455 [04:11<08:10,  1.76s/ queries, google=81.36%, yours=71.75%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  to run the\n",
      "Query =  ['to', 'run', 'the']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|█████████████████████████████████▋                                                    | 178/455 [04:11<06:30,  1.41s/ queries, google=81.46%, yours=71.91%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  data from the browser's\n",
      "Query =  ['data', 'from', 'the', \"browser's\"]\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|█████████████████████████████████▊                                                    | 179/455 [04:12<05:33,  1.21s/ queries, google=81.56%, yours=72.07%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the wind of fredoom\n",
      "Query =  ['the', 'wind', 'of', 'fredoom']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████                                                    | 180/455 [04:13<05:00,  1.09s/ queries, google=81.67%, yours=72.22%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  provided throughout this article to\n",
      "Query =  ['provided', 'throughout', 'this', 'article', 'to']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████▏                                                   | 181/455 [04:15<05:49,  1.28s/ queries, google=81.77%, yours=72.38%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  579 sorra mall stanfor ca\n",
      "Query =  ['579', 'sorra', 'mall', 'stanfor', 'ca']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████▍                                                   | 182/455 [04:16<05:42,  1.25s/ queries, google=81.87%, yours=72.53%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  often the exit angle is\n",
      "Query =  ['often', 'the', 'exit', 'angle', 'is']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████▌                                                   | 183/455 [04:17<05:26,  1.20s/ queries, google=81.97%, yours=72.68%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  all postings outline chose\n",
      "Query =  ['all', 'postings', 'outline', 'chose']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████▊                                                   | 184/455 [04:18<04:55,  1.09s/ queries, google=81.52%, yours=72.83%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  aperson contact us\n",
      "Query =  ['aperson', 'contact', 'us']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|██████████████████████████████████▉                                                   | 185/455 [04:20<05:53,  1.31s/ queries, google=81.62%, yours=72.43%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  navigational testdirectory news center\n",
      "Query =  ['navigational', 'testdirectory', 'news', 'center']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████████▏                                                  | 186/455 [04:22<07:12,  1.61s/ queries, google=81.72%, yours=72.04%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  failure of viral capsids 2\n",
      "Query =  ['failure', 'of', 'viral', 'capsids', '2']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████████▎                                                  | 187/455 [04:24<07:49,  1.75s/ queries, google=81.82%, yours=72.19%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  stanford graduate school of business\n",
      "Query =  ['stanford', 'graduate', 'school', 'of', 'business']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████████▌                                                  | 188/455 [04:26<07:27,  1.67s/ queries, google=81.91%, yours=72.34%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  douglsas k owens\n",
      "Query =  ['douglsas', 'k', 'owens']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████████▋                                                  | 189/455 [04:26<06:00,  1.35s/ queries, google=82.01%, yours=72.49%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  1 recent comments\n",
      "Query =  ['1', 'recent', 'comments']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████████████████████████▉                                                  | 190/455 [04:27<05:07,  1.16s/ queries, google=82.11%, yours=72.63%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  won t talk to them\n",
      "Query =  ['won', 't', 'talk', 'to', 'them']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████████                                                  | 191/455 [04:28<04:44,  1.08s/ queries, google=81.68%, yours=72.77%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  data simulated data are\n",
      "Query =  ['data', 'simulated', 'data', 'are']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████████▎                                                 | 192/455 [04:29<04:29,  1.03s/ queries, google=81.77%, yours=72.92%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  cover letters interviewing strategies on\n",
      "Query =  ['cover', 'letters', 'interviewing', 'strategies', 'on']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████████▍                                                 | 193/455 [04:30<05:27,  1.25s/ queries, google=81.35%, yours=72.54%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  like for you\n",
      "Query =  ['like', 'for', 'you']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████████████████████████████▋                                                 | 194/455 [04:31<04:29,  1.03s/ queries, google=81.44%, yours=72.68%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  is due novenber typeset every book on buddism\n",
      "Query =  ['is', 'due', 'novenber', 'typeset', 'every', 'book', 'on', 'buddism']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████████████████████████████▊                                                 | 195/455 [04:33<05:59,  1.38s/ queries, google=81.54%, yours=72.82%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  cm2 g total 0.16498 cm2\n",
      "Query =  ['cm2', 'g', 'total', '0.16498', 'cm2']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████                                                 | 196/455 [04:34<05:15,  1.22s/ queries, google=81.63%, yours=72.96%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  technological inovation social\n",
      "Query =  ['technological', 'inovation', 'social']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████▏                                                | 197/455 [04:35<05:25,  1.26s/ queries, google=81.73%, yours=73.10%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  2003 director human bilolgy program\n",
      "Query =  ['2003', 'director', 'human', 'bilolgy', 'program']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████████▍                                                | 198/455 [04:36<05:10,  1.21s/ queries, google=81.82%, yours=73.23%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  mus sic links suggest a purchase\n",
      "Query =  ['mus', 'sic', 'links', 'suggest', 'a', 'purchase']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "dict_keys([0, 1, 2, 3, 4, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████████▌                                                | 199/455 [04:38<05:29,  1.29s/ queries, google=81.91%, yours=72.86%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  cite this send\n",
      "Query =  ['cite', 'this', 'send']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████████▊                                                | 200/455 [04:38<04:18,  1.01s/ queries, google=82.00%, yours=73.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  editing hints using\n",
      "Query =  ['editing', 'hints', 'using']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████████▉                                                | 201/455 [04:39<03:39,  1.16 queries/s, google=82.09%, yours=73.13%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  subject simin aneshvar\n",
      "Query =  ['subject', 'simin', 'aneshvar']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████████████▏                                               | 202/455 [04:39<03:24,  1.24 queries/s, google=82.18%, yours=73.27%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  and image date\n",
      "Query =  ['and', 'image', 'date']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████████▎                                               | 203/455 [04:40<02:58,  1.41 queries/s, google=81.77%, yours=72.91%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  of classics standford univeristy logo\n",
      "Query =  ['of', 'classics', 'standford', 'univeristy', 'logo']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████████▌                                               | 204/455 [04:41<04:02,  1.04 queries/s, google=81.86%, yours=72.55%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  programs grants & fellowships people\n",
      "Query =  ['programs', 'grants', '&', 'fellowships', 'people']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████████▋                                               | 205/455 [04:43<04:33,  1.09s/ queries, google=81.95%, yours=72.68%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  guiseppe nardulli hep ph 0111178\n",
      "Query =  ['guiseppe', 'nardulli', 'hep', 'ph', '0111178']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|██████████████████████████████████████▉                                               | 206/455 [04:44<04:35,  1.11s/ queries, google=82.04%, yours=72.82%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  fsi centers & programme the text of the postings\n",
      "Query =  ['fsi', 'centers', '&', 'programme', 'the', 'text', 'of', 'the', 'postings']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "I =  8\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|███████████████████████████████████████▏                                              | 207/455 [04:47<06:59,  1.69s/ queries, google=82.13%, yours=72.95%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  21 201204 15\n",
      "Query =  ['21', '201204', '15']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████████▎                                              | 208/455 [04:48<05:28,  1.33s/ queries, google=81.73%, yours=72.60%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  from febuary 4 2012\n",
      "Query =  ['from', 'febuary', '4', '2012']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████████▌                                              | 209/455 [04:49<05:05,  1.24s/ queries, google=81.82%, yours=72.25%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  also taught nuclear energy\n",
      "Query =  ['also', 'taught', 'nuclear', 'energy']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████████▋                                              | 210/455 [04:49<04:40,  1.14s/ queries, google=81.90%, yours=72.38%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  for distribution at\n",
      "Query =  ['for', 'distribution', 'at']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████████▉                                              | 211/455 [04:51<05:17,  1.30s/ queries, google=81.99%, yours=72.51%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  2 2x x\n",
      "Query =  ['2', '2x', 'x']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████████                                              | 212/455 [04:52<04:07,  1.02s/ queries, google=82.08%, yours=72.17%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  account s will\n",
      "Query =  ['account', 's', 'will']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████████▎                                             | 213/455 [04:52<03:53,  1.04 queries/s, google=82.16%, yours=72.30%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  unfortunately while lay users can\n",
      "Query =  ['unfortunately', 'while', 'lay', 'users', 'can']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████████▍                                             | 214/455 [04:54<05:00,  1.25s/ queries, google=82.24%, yours=72.43%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  on facebppk share on twitter\n",
      "Query =  ['on', 'facebppk', 'share', 'on', 'twitter']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████████▋                                             | 215/455 [04:56<05:11,  1.30s/ queries, google=82.33%, yours=72.56%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  ca 94305 650 329 8566\n",
      "Query =  ['ca', '94305', '650', '329', '8566']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████████████████████████▊                                             | 216/455 [04:57<05:32,  1.39s/ queries, google=82.41%, yours=72.69%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the numbwe to\n",
      "Query =  ['the', 'numbwe', 'to']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████████████                                             | 217/455 [04:58<04:17,  1.08s/ queries, google=82.49%, yours=72.81%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  very interested in worknig with\n",
      "Query =  ['very', 'interested', 'in', 'worknig', 'with']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████████████▏                                            | 218/455 [04:59<04:36,  1.17s/ queries, google=82.57%, yours=72.94%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  onsomewhat cooincidentally for\n",
      "Query =  ['onsomewhat', 'cooincidentally', 'for']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████████████▍                                            | 219/455 [05:01<05:16,  1.34s/ queries, google=82.19%, yours=72.60%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  mail code phone fax e r staf list maps\n",
      "Query =  ['mail', 'code', 'phone', 'fax', 'e', 'r', 'staf', 'list', 'maps']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "I =  8\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████████████▌                                            | 220/455 [05:04<07:03,  1.80s/ queries, google=81.82%, yours=72.27%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  my wacom graphire\n",
      "Query =  ['my', 'wacom', 'graphire']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|█████████████████████████████████████████▊                                            | 221/455 [05:04<05:34,  1.43s/ queries, google=81.90%, yours=72.40%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  which are abstract\n",
      "Query =  ['which', 'are', 'abstract']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|█████████████████████████████████████████▉                                            | 222/455 [05:05<04:46,  1.23s/ queries, google=81.98%, yours=72.52%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  & institutes professor health research science the vast majority of\n",
      "Query =  ['&', 'institutes', 'professor', 'health', 'research', 'science', 'the', 'vast', 'majority', 'of']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "I =  8\n",
      "I =  9\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████████▏                                           | 223/455 [05:10<08:44,  2.26s/ queries, google=82.06%, yours=72.65%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  guides presentations recommendations and reports\n",
      "Query =  ['guides', 'presentations', 'recommendations', 'and', 'reports']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████████▎                                           | 224/455 [05:13<10:19,  2.68s/ queries, google=82.14%, yours=72.77%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  for bflb hypernews\n",
      "Query =  ['for', 'bflb', 'hypernews']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████████████████▌                                           | 225/455 [05:14<07:59,  2.09s/ queries, google=82.22%, yours=72.89%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  for one thiing\n",
      "Query =  ['for', 'one', 'thiing']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████▋                                           | 226/455 [05:15<06:23,  1.68s/ queries, google=82.30%, yours=73.01%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  cccrma stadford edu tue sept\n",
      "Query =  ['cccrma', 'stadford', 'edu', 'tue', 'sept']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████▉                                           | 227/455 [05:16<05:35,  1.47s/ queries, google=82.38%, yours=72.69%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  david a reis fisherds\n",
      "Query =  ['david', 'a', 'reis', 'fisherds']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████████                                           | 228/455 [05:16<04:45,  1.26s/ queries, google=82.46%, yours=72.81%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  managment group name email address\n",
      "Query =  ['managment', 'group', 'name', 'email', 'address']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████████▎                                          | 229/455 [05:18<05:06,  1.35s/ queries, google=82.53%, yours=72.49%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  thanks manju sudakar inline depth\n",
      "Query =  ['thanks', 'manju', 'sudakar', 'inline', 'depth']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|███████████████████████████████████████████▍                                          | 230/455 [05:19<04:41,  1.25s/ queries, google=82.61%, yours=72.61%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  and services that focus standford univestiy all\n",
      "Query =  ['and', 'services', 'that', 'focus', 'standford', 'univestiy', 'all']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|███████████████████████████████████████████▋                                          | 231/455 [05:21<05:50,  1.56s/ queries, google=82.68%, yours=72.29%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the london school\n",
      "Query =  ['the', 'london', 'school']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|███████████████████████████████████████████▊                                          | 232/455 [05:22<04:44,  1.27s/ queries, google=82.76%, yours=72.41%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  chen ph d staff\n",
      "Query =  ['chen', 'ph', 'd', 'staff']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████████████                                          | 233/455 [05:23<04:08,  1.12s/ queries, google=82.83%, yours=72.53%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  11 the hound\n",
      "Query =  ['11', 'the', 'hound']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████████████████████████████████████▏                                         | 234/455 [05:24<04:10,  1.14s/ queries, google=82.91%, yours=72.65%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  service eating contest given\n",
      "Query =  ['service', 'eating', 'contest', 'given']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████████████▍                                         | 235/455 [05:25<04:01,  1.10s/ queries, google=82.98%, yours=72.77%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  2008 standford local programming contest\n",
      "Query =  ['2008', 'standford', 'local', 'programming', 'contest']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████████████▌                                         | 236/455 [05:26<04:32,  1.24s/ queries, google=83.05%, yours=72.46%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  intellectual property enforcement coordinator on\n",
      "Query =  ['intellectual', 'property', 'enforcement', 'coordinator', 'on']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████████████▊                                         | 237/455 [05:29<06:22,  1.75s/ queries, google=83.12%, yours=72.57%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  your account has benn randomly\n",
      "Query =  ['your', 'account', 'has', 'benn', 'randomly']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████████████▉                                         | 238/455 [05:32<07:02,  1.95s/ queries, google=83.19%, yours=72.69%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  1.00 0.00 1.00\n",
      "Query =  ['1.00', '0.00', '1.00']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████████████████████████████▏                                        | 239/455 [05:32<05:30,  1.53s/ queries, google=83.26%, yours=72.80%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  interfaces user and admin users address book add names\n",
      "Query =  ['interfaces', 'user', 'and', 'admin', 'users', 'address', 'book', 'add', 'names']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "I =  8\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████████████████████████████▎                                        | 240/455 [05:35<07:08,  1.99s/ queries, google=83.33%, yours=72.92%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  same webside before that edu stanford university 425\n",
      "Query =  ['same', 'webside', 'before', 'that', 'edu', 'stanford', 'university', '425']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████████████████████████████▌                                        | 241/455 [05:39<08:55,  2.50s/ queries, google=83.40%, yours=72.61%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  13 ho el as\n",
      "Query =  ['13', 'ho', 'el', 'as']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████████████████████████████▋                                        | 242/455 [05:40<07:27,  2.10s/ queries, google=83.06%, yours=72.31%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the posting thread\n",
      "Query =  ['the', 'posting', 'thread']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████████████████████████████▉                                        | 243/455 [05:41<06:19,  1.79s/ queries, google=83.13%, yours=72.43%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  publications send by\n",
      "Query =  ['publications', 'send', 'by']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|██████████████████████████████████████████████                                        | 244/455 [05:43<06:24,  1.82s/ queries, google=83.20%, yours=72.54%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  http you could try\n",
      "Query =  ['http', 'you', 'could', 'try']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|██████████████████████████████████████████████▎                                       | 245/455 [05:44<05:14,  1.50s/ queries, google=83.27%, yours=72.65%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  facilty profile content provider\n",
      "Query =  ['facilty', 'profile', 'content', 'provider']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|██████████████████████████████████████████████▍                                       | 246/455 [05:45<05:11,  1.49s/ queries, google=83.33%, yours=72.76%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  36 bit 18\n",
      "Query =  ['36', 'bit', '18']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|██████████████████████████████████████████████▋                                       | 247/455 [05:46<04:13,  1.22s/ queries, google=83.40%, yours=72.87%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  he has wroked on\n",
      "Query =  ['he', 'has', 'wroked', 'on']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████████████████████████████████▊                                       | 248/455 [05:48<04:30,  1.31s/ queries, google=83.47%, yours=72.98%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  academic calendar masters\n",
      "Query =  ['academic', 'calendar', 'masters']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████████                                       | 249/455 [05:49<04:23,  1.28s/ queries, google=83.13%, yours=72.69%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  3 downloaded 23 feb\n",
      "Query =  ['3', 'downloaded', '23', 'feb']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████████▎                                      | 250/455 [05:51<05:02,  1.48s/ queries, google=83.20%, yours=72.80%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  g4system gmk were can i\n",
      "Query =  ['g4system', 'gmk', 'were', 'can', 'i']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████████▍                                      | 251/455 [05:52<05:14,  1.54s/ queries, google=82.87%, yours=72.91%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  page which contains only the\n",
      "Query =  ['page', 'which', 'contains', 'only', 'the']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████████████████████████████▋                                      | 252/455 [05:55<06:06,  1.80s/ queries, google=82.94%, yours=73.02%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  none unselect all of ibn sina a critical\n",
      "Query =  ['none', 'unselect', 'all', 'of', 'ibn', 'sina', 'a', 'critical']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|███████████████████████████████████████████████▊                                      | 253/455 [05:57<06:52,  2.04s/ queries, google=83.00%, yours=73.12%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  machenery and intelligence\n",
      "Query =  ['machenery', 'and', 'intelligence']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████████                                      | 254/455 [05:59<06:08,  1.83s/ queries, google=83.07%, yours=73.23%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  archive colophon admin logon\n",
      "Query =  ['archive', 'colophon', 'admin', 'logon']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████████▏                                     | 255/455 [06:00<05:28,  1.64s/ queries, google=82.75%, yours=73.33%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  sulair home su home suspect stanford stanford university\n",
      "Query =  ['sulair', 'home', 'su', 'home', 'suspect', 'stanford', 'stanford', 'university']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████████▍                                     | 256/455 [06:04<07:31,  2.27s/ queries, google=82.81%, yours=73.05%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  spam and virus filtering software\n",
      "Query =  ['spam', 'and', 'virus', 'filtering', 'software']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████████▌                                     | 257/455 [06:06<07:14,  2.19s/ queries, google=82.88%, yours=73.15%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  process note 1 fr students\n",
      "Query =  ['process', 'note', '1', 'fr', 'students']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████████████████████████████▊                                     | 258/455 [06:08<07:39,  2.33s/ queries, google=82.95%, yours=72.87%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  research overview school\n",
      "Query =  ['research', 'overview', 'school']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████████████████████████████▉                                     | 259/455 [06:09<06:10,  1.89s/ queries, google=83.01%, yours=72.97%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  deep belowe the\n",
      "Query =  ['deep', 'belowe', 'the']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████████████████████████████▏                                    | 260/455 [06:10<04:51,  1.49s/ queries, google=83.08%, yours=73.08%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  i can change things for\n",
      "Query =  ['i', 'can', 'change', 'things', 'for']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████████████████████████████▎                                    | 261/455 [06:11<04:41,  1.45s/ queries, google=83.14%, yours=73.18%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  similuation our long\n",
      "Query =  ['similuation', 'our', 'long']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████████████████████████████████████████████████▌                                    | 262/455 [06:13<05:10,  1.61s/ queries, google=83.21%, yours=73.28%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  give raise to severe emittance babar database who's\n",
      "Query =  ['give', 'raise', 'to', 'severe', 'emittance', 'babar', 'database', \"who's\"]\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████████████████████████████████████████████████▋                                    | 263/455 [06:16<05:57,  1.86s/ queries, google=82.89%, yours=73.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  page 1 moran bercovici advisorzluan\n",
      "Query =  ['page', '1', 'moran', 'bercovici', 'advisorzluan']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████████████████████████████████████████████████▉                                    | 264/455 [06:18<06:18,  1.98s/ queries, google=82.58%, yours=73.11%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  record lenght the sited together with\n",
      "Query =  ['record', 'lenght', 'the', 'sited', 'together', 'with']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "dict_keys([0, 1, 2, 3, 4, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████████████████████████████████████                                    | 265/455 [06:20<06:22,  2.01s/ queries, google=82.26%, yours=73.21%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  abstracts xx international linac\n",
      "Query =  ['abstracts', 'xx', 'international', 'linac']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████████████████████████████████████▎                                   | 266/455 [06:22<06:29,  2.06s/ queries, google=82.33%, yours=73.31%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the physics department crimefighting organization\n",
      "Query =  ['the', 'physics', 'department', 'crimefighting', 'organization']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|██████████████████████████████████████████████████▍                                   | 267/455 [06:25<07:11,  2.29s/ queries, google=82.40%, yours=73.03%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  health improvement progrma stanford medicine\n",
      "Query =  ['health', 'improvement', 'progrma', 'stanford', 'medicine']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|██████████████████████████████████████████████████▋                                   | 268/455 [06:27<06:43,  2.16s/ queries, google=82.46%, yours=73.13%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  x eido design\n",
      "Query =  ['x', 'eido', 'design']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|██████████████████████████████████████████████████▊                                   | 269/455 [06:27<05:17,  1.71s/ queries, google=82.16%, yours=73.23%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  xi violinist jiaotung university\n",
      "Query =  ['xi', 'violinist', 'jiaotung', 'university']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████████████████████████████████████                                   | 270/455 [06:29<05:07,  1.66s/ queries, google=82.22%, yours=73.33%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  please mailchecks made out\n",
      "Query =  ['please', 'mailchecks', 'made', 'out']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████▏                                  | 271/455 [06:30<04:47,  1.56s/ queries, google=82.29%, yours=73.06%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  chalenges than last year\n",
      "Query =  ['chalenges', 'than', 'last', 'year']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████▍                                  | 272/455 [06:32<04:26,  1.46s/ queries, google=82.35%, yours=72.79%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  safe rosamond l naylor george\n",
      "Query =  ['safe', 'rosamond', 'l', 'naylor', 'george']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████▌                                  | 273/455 [06:33<04:27,  1.47s/ queries, google=82.42%, yours=72.89%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  7252592 mail code contact us to\n",
      "Query =  ['7252592', 'mail', 'code', 'contact', 'us', 'to']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "dict_keys([0, 1, 2, 3, 4, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████▊                                  | 274/455 [06:36<05:37,  1.87s/ queries, google=82.12%, yours=72.63%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  clase sroom for instructors\n",
      "Query =  ['clase', 'sroom', 'for', 'instructors']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████▉                                  | 275/455 [06:37<05:01,  1.68s/ queries, google=82.18%, yours=72.36%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  via the kerr affect and\n",
      "Query =  ['via', 'the', 'kerr', 'affect', 'and']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|████████████████████████████████████████████████████▏                                 | 276/455 [06:38<04:43,  1.58s/ queries, google=82.25%, yours=72.46%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  plasmid & puhe24\n",
      "Query =  ['plasmid', '&', 'puhe24']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|████████████████████████████████████████████████████▎                                 | 277/455 [06:39<04:01,  1.36s/ queries, google=82.31%, yours=72.56%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  students graduate students undergraduates\n",
      "Query =  ['students', 'graduate', 'students', 'undergraduates']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|████████████████████████████████████████████████████▌                                 | 278/455 [06:41<04:30,  1.53s/ queries, google=82.37%, yours=72.66%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  items all day\n",
      "Query =  ['items', 'all', 'day']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|████████████████████████████████████████████████████▋                                 | 279/455 [06:42<03:34,  1.22s/ queries, google=82.44%, yours=72.76%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  completing a post doctoral\n",
      "Query =  ['completing', 'a', 'post', 'doctoral']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████████████████████████████████████▉                                 | 280/455 [06:43<04:01,  1.38s/ queries, google=82.50%, yours=72.50%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  his her particular aread of\n",
      "Query =  ['his', 'her', 'particular', 'aread', 'of']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████████████████████████████████                                 | 281/455 [06:46<04:47,  1.65s/ queries, google=82.56%, yours=72.24%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the abliity to\n",
      "Query =  ['the', 'abliity', 'to']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████████████████████████████████▎                                | 282/455 [06:46<03:44,  1.30s/ queries, google=82.62%, yours=72.34%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  politicans officials and academics\n",
      "Query =  ['politicans', 'officials', 'and', 'academics']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████████████████████████████████▍                                | 283/455 [06:48<04:02,  1.41s/ queries, google=82.69%, yours=72.08%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  expressions library lip synch\n",
      "Query =  ['expressions', 'library', 'lip', 'synch']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████████████████████████████████▋                                | 284/455 [06:50<04:20,  1.52s/ queries, google=82.75%, yours=71.83%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the work was available\n",
      "Query =  ['the', 'work', 'was', 'available']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████████████████████████████████▊                                | 285/455 [06:52<04:59,  1.76s/ queries, google=82.81%, yours=71.93%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  d ivoir croatia cuba\n",
      "Query =  ['d', 'ivoir', 'croatia', 'cuba']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████████                                | 286/455 [06:52<03:54,  1.39s/ queries, google=82.52%, yours=72.03%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the origiinal spirit\n",
      "Query =  ['the', 'origiinal', 'spirit']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████████▏                               | 287/455 [06:54<03:41,  1.32s/ queries, google=82.58%, yours=72.13%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  first page preveous 2009 02 01 author\n",
      "Query =  ['first', 'page', 'preveous', '2009', '02', '01', 'author']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████████████████████████████████████████▍                               | 288/455 [06:56<04:50,  1.74s/ queries, google=82.64%, yours=71.88%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the reefcheck california monitoring\n",
      "Query =  ['the', 'reefcheck', 'california', 'monitoring']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████████████████████████████████████████████████████▌                               | 289/455 [06:58<04:40,  1.69s/ queries, google=82.70%, yours=71.63%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  tressider summer activities fair\n",
      "Query =  ['tressider', 'summer', 'activities', 'fair']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████████████████████████████████████████████████████▊                               | 290/455 [07:00<04:36,  1.68s/ queries, google=82.41%, yours=71.72%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  is so fars cs379c computation models\n",
      "Query =  ['is', 'so', 'fars', 'cs379c', 'computation', 'models']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "dict_keys([0, 1, 2, 3, 4, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████████                               | 291/455 [07:02<05:00,  1.83s/ queries, google=82.13%, yours=71.48%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  and sustainble develpment 2010 pdf+\n",
      "Query =  ['and', 'sustainble', 'develpment', '2010', 'pdf+']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████████▏                              | 292/455 [07:05<05:48,  2.14s/ queries, google=81.85%, yours=71.58%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  health scholars program\n",
      "Query =  ['health', 'scholars', 'program']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████████▍                              | 293/455 [07:05<04:38,  1.72s/ queries, google=81.91%, yours=71.67%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  we help maps\n",
      "Query =  ['we', 'help', 'maps']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|███████████████████████████████████████████████████████▌                              | 294/455 [07:06<03:37,  1.35s/ queries, google=81.97%, yours=71.77%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  public evens page on this\n",
      "Query =  ['public', 'evens', 'page', 'on', 'this']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|███████████████████████████████████████████████████████▊                              | 295/455 [07:07<03:25,  1.29s/ queries, google=82.03%, yours=71.53%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  graduate school of business news\n",
      "Query =  ['graduate', 'school', 'of', 'business', 'news']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|███████████████████████████████████████████████████████▉                              | 296/455 [07:08<03:29,  1.32s/ queries, google=82.09%, yours=71.62%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the receptiors might rev up\n",
      "Query =  ['the', 'receptiors', 'might', 'rev', 'up']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████████████████▏                             | 297/455 [07:09<03:18,  1.25s/ queries, google=82.15%, yours=71.72%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  of education freeman spogli institute\n",
      "Query =  ['of', 'education', 'freeman', 'spogli', 'institute']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████████████████▎                             | 298/455 [07:11<03:48,  1.46s/ queries, google=82.21%, yours=71.81%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the enviroment fsi hasked to define\n",
      "Query =  ['the', 'enviroment', 'fsi', 'hasked', 'to', 'define']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "dict_keys([0, 1, 2, 3, 4, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|████████████████████████████████████████████████████████▌                             | 299/455 [07:13<03:57,  1.52s/ queries, google=82.27%, yours=71.91%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  stanford califorina 94305\n",
      "Query =  ['stanford', 'califorina', '94305']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|████████████████████████████████████████████████████████▋                             | 300/455 [07:14<03:26,  1.33s/ queries, google=82.33%, yours=72.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  webinars will be\n",
      "Query =  ['webinars', 'will', 'be']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|████████████████████████████████████████████████████████▉                             | 301/455 [07:15<02:55,  1.14s/ queries, google=82.39%, yours=72.09%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  pro vost and director of\n",
      "Query =  ['pro', 'vost', 'and', 'director', 'of']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████████████                             | 302/455 [07:17<03:41,  1.45s/ queries, google=82.45%, yours=71.85%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the sun's heartbeat to\n",
      "Query =  ['the', \"sun's\", 'heartbeat', 'to']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████████████████████████████████▎                            | 303/455 [07:19<04:03,  1.60s/ queries, google=82.51%, yours=71.95%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  mikiphone pocket phonogtaph\n",
      "Query =  ['mikiphone', 'pocket', 'phonogtaph']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████████████████████████████████▍                            | 304/455 [07:20<03:35,  1.43s/ queries, google=82.57%, yours=72.04%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  1152 email pacrc\n",
      "Query =  ['1152', 'email', 'pacrc']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████████████████████████████████▋                            | 305/455 [07:20<02:55,  1.17s/ queries, google=82.62%, yours=72.13%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  catapulted both king and\n",
      "Query =  ['catapulted', 'both', 'king', 'and']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████████████████████████████████████████▊                            | 306/455 [07:21<02:50,  1.14s/ queries, google=82.68%, yours=72.22%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  east europe &\n",
      "Query =  ['east', 'europe', '&']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████████████████                            | 307/455 [07:22<02:27,  1.00 queries/s, google=82.41%, yours=71.99%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  admissions continueing medical education\n",
      "Query =  ['admissions', 'continueing', 'medical', 'education']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████████████▏                           | 308/455 [07:24<02:58,  1.21s/ queries, google=82.47%, yours=72.08%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  record for tiney\n",
      "Query =  ['record', 'for', 'tiney']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████████████▍                           | 309/455 [07:25<03:07,  1.29s/ queries, google=82.52%, yours=71.84%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the specified value you can\n",
      "Query =  ['the', 'specified', 'value', 'you', 'can']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████████████▌                           | 310/455 [07:26<03:01,  1.25s/ queries, google=82.58%, yours=71.94%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  with sonar sensors in populate\n",
      "Query =  ['with', 'sonar', 'sensors', 'in', 'populate']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████████████▊                           | 311/455 [07:27<02:49,  1.18s/ queries, google=82.32%, yours=71.70%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  of the yeard\n",
      "Query =  ['of', 'the', 'yeard']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████████████████████████████████████████████████████████▉                           | 312/455 [07:29<03:05,  1.29s/ queries, google=82.37%, yours=71.47%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  have already entered\n",
      "Query =  ['have', 'already', 'entered']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████████████▏                          | 313/455 [07:30<02:37,  1.11s/ queries, google=82.43%, yours=71.57%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  translation of these new\n",
      "Query =  ['translation', 'of', 'these', 'new']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████████████▎                          | 314/455 [07:32<03:22,  1.44s/ queries, google=82.48%, yours=71.66%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  models and conditional estimtion without\n",
      "Query =  ['models', 'and', 'conditional', 'estimtion', 'without']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████████████▌                          | 315/455 [07:34<03:35,  1.54s/ queries, google=82.54%, yours=71.75%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  with a glance cast at\n",
      "Query =  ['with', 'a', 'glance', 'cast', 'at']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████████████▋                          | 316/455 [07:35<03:38,  1.57s/ queries, google=82.59%, yours=71.84%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  links to some menus versa in this\n",
      "Query =  ['links', 'to', 'some', 'menus', 'versa', 'in', 'this']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████████████████████████████████████▉                          | 317/455 [07:38<04:05,  1.78s/ queries, google=82.65%, yours=71.92%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  pta for wich classified collated compared\n",
      "Query =  ['pta', 'for', 'wich', 'classified', 'collated', 'compared']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "dict_keys([0, 1, 2, 3, 4, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████████                          | 318/455 [07:39<04:00,  1.76s/ queries, google=82.70%, yours=71.70%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  drive at musuem way\n",
      "Query =  ['drive', 'at', 'musuem', 'way']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████████▎                         | 319/455 [07:40<03:17,  1.45s/ queries, google=82.76%, yours=71.79%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  president's day monday february 20\n",
      "Query =  [\"president's\", 'day', 'monday', 'february', '20']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████████▍                         | 320/455 [07:41<03:15,  1.45s/ queries, google=82.81%, yours=71.56%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  791 institute stanford\n",
      "Query =  ['791', 'institute', 'stanford']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|████████████████████████████████████████████████████████████▋                         | 321/455 [07:42<02:49,  1.27s/ queries, google=82.55%, yours=71.34%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  or anyof\n",
      "Query =  ['or', 'anyof']\n",
      "I =  0\n",
      "I =  1\n",
      "dict_keys([0, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|████████████████████████████████████████████████████████████▊                         | 322/455 [07:43<02:04,  1.07 queries/s, google=82.61%, yours=71.12%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  voleentering public service & community\n",
      "Query =  ['voleentering', 'public', 'service', '&', 'community']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████████████████████████████████████████████                         | 323/455 [07:44<02:41,  1.23s/ queries, google=82.66%, yours=70.90%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  possible we can\n",
      "Query =  ['possible', 'we', 'can']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████████████████████████████████████████████▏                        | 324/455 [07:45<02:18,  1.06s/ queries, google=82.72%, yours=70.99%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  only ctext for\n",
      "Query =  ['only', 'ctext', 'for']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████████████████████████████████████████████▍                        | 325/455 [07:45<01:47,  1.21 queries/s, google=82.77%, yours=71.08%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  biodesignnews12 03 html jul\n",
      "Query =  ['biodesignnews12', '03', 'html', 'jul']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████████████████████████████████████▌                        | 326/455 [07:47<02:15,  1.05s/ queries, google=82.52%, yours=71.17%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  aeronautics and stronautics\n",
      "Query =  ['aeronautics', 'and', 'stronautics']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████████████████████████████████████▊                        | 327/455 [07:48<02:26,  1.14s/ queries, google=82.57%, yours=71.25%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  and information technologies design\n",
      "Query =  ['and', 'information', 'technologies', 'design']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████████████████████████████████████▉                        | 328/455 [07:50<02:51,  1.35s/ queries, google=82.62%, yours=71.34%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  shown with without\n",
      "Query =  ['shown', 'with', 'without']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████████████████████████████████████▏                       | 329/455 [07:51<02:25,  1.16s/ queries, google=82.67%, yours=71.43%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  posting thread successive\n",
      "Query =  ['posting', 'thread', 'successive']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████████████▎                       | 330/455 [07:52<02:16,  1.09s/ queries, google=82.73%, yours=71.52%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  potential safety or envrionmental consequences\n",
      "Query =  ['potential', 'safety', 'or', 'envrionmental', 'consequences']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████████████▌                       | 331/455 [07:54<03:06,  1.50s/ queries, google=82.78%, yours=71.30%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  visa master card american\n",
      "Query =  ['visa', 'master', 'card', 'american']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████████████▊                       | 332/455 [07:55<02:41,  1.32s/ queries, google=82.83%, yours=71.08%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  stay connected itunes\n",
      "Query =  ['stay', 'connected', 'itunes']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████████████▉                       | 333/455 [07:56<02:17,  1.13s/ queries, google=82.88%, yours=71.17%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  web site econf home options\n",
      "Query =  ['web', 'site', 'econf', 'home', 'options']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████████████████████████████████████████████████████████████▏                      | 334/455 [07:57<02:12,  1.09s/ queries, google=82.93%, yours=70.96%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  law crown map collections\n",
      "Query =  ['law', 'crown', 'map', 'collections']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████████████▎                      | 335/455 [07:58<02:12,  1.11s/ queries, google=82.99%, yours=71.04%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  corpus linguistics aronld zwickys blog of use copy right\n",
      "Query =  ['corpus', 'linguistics', 'aronld', 'zwickys', 'blog', 'of', 'use', 'copy', 'right']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "I =  8\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████████████▌                      | 336/455 [08:01<03:20,  1.68s/ queries, google=82.74%, yours=70.83%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  135 units of doctoral residency december 10 2010 by judith\n",
      "Query =  ['135', 'units', 'of', 'doctoral', 'residency', 'december', '10', '2010', 'by', 'judith']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "I =  8\n",
      "I =  9\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████████████▋                      | 337/455 [08:07<05:49,  2.96s/ queries, google=82.79%, yours=70.92%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the postin threads\n",
      "Query =  ['the', 'postin', 'threads']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████████████▉                      | 338/455 [08:07<04:22,  2.24s/ queries, google=82.54%, yours=70.71%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  heart center nursing\n",
      "Query =  ['heart', 'center', 'nursing']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████████████                      | 339/455 [08:08<03:22,  1.75s/ queries, google=82.60%, yours=70.80%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  coaches and program\n",
      "Query =  ['coaches', 'and', 'program']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████████████▎                     | 340/455 [08:09<02:49,  1.47s/ queries, google=82.65%, yours=70.88%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  cag can be\n",
      "Query =  ['cag', 'can', 'be']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████████████▍                     | 341/455 [08:09<02:12,  1.17s/ queries, google=82.40%, yours=70.67%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  is being used\n",
      "Query =  ['is', 'being', 'used']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████████████▋                     | 342/455 [08:10<01:46,  1.06 queries/s, google=82.46%, yours=70.76%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  then reflesh the\n",
      "Query =  ['then', 'reflesh', 'the']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████████████▊                     | 343/455 [08:10<01:30,  1.23 queries/s, google=82.22%, yours=70.85%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  geant4 discussions hypernews geant4\n",
      "Query =  ['geant4', 'discussions', 'hypernews', 'geant4']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████████████████                     | 344/455 [08:12<01:50,  1.00 queries/s, google=82.27%, yours=70.93%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  chemistry department news\n",
      "Query =  ['chemistry', 'department', 'news']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████████████████▏                    | 345/455 [08:13<01:52,  1.02s/ queries, google=82.32%, yours=71.01%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  about developments changes\n",
      "Query =  ['about', 'developments', 'changes']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████████████████▍                    | 346/455 [08:14<01:52,  1.03s/ queries, google=82.37%, yours=71.10%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  importantfor us\n",
      "Query =  ['importantfor', 'us']\n",
      "I =  0\n",
      "I =  1\n",
      "dict_keys([0, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████████████████▌                    | 347/455 [08:15<01:43,  1.04 queries/s, google=82.42%, yours=70.89%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  quesytions should file a without the text of the\n",
      "Query =  ['quesytions', 'should', 'file', 'a', 'without', 'the', 'text', 'of', 'the']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "I =  8\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████████████████▊                    | 348/455 [08:18<02:57,  1.66s/ queries, google=82.47%, yours=70.98%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  teh made up dramas of\n",
      "Query =  ['teh', 'made', 'up', 'dramas', 'of']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|█████████████████████████████████████████████████████████████████▉                    | 349/455 [08:19<02:28,  1.41s/ queries, google=82.52%, yours=70.77%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  directory gallery alumni ms japan and japanese\n",
      "Query =  ['directory', 'gallery', 'alumni', 'ms', 'japan', 'and', 'japanese']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|██████████████████████████████████████████████████████████████████▏                   | 350/455 [08:21<02:59,  1.71s/ queries, google=82.57%, yours=70.57%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  support graduate students appling doctor\n",
      "Query =  ['support', 'graduate', 'students', 'appling', 'doctor']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|██████████████████████████████████████████████████████████████████▎                   | 351/455 [08:23<02:46,  1.60s/ queries, google=82.62%, yours=70.66%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  consider journal pricing in addition\n",
      "Query =  ['consider', 'journal', 'pricing', 'in', 'addition']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|██████████████████████████████████████████████████████████████████▌                   | 352/455 [08:24<02:36,  1.51s/ queries, google=82.67%, yours=70.74%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  resurection is the man who\n",
      "Query =  ['resurection', 'is', 'the', 'man', 'who']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████████████████████████▋                   | 353/455 [08:26<02:45,  1.62s/ queries, google=82.72%, yours=70.54%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  on campus disruptions\n",
      "Query =  ['on', 'campus', 'disruptions']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████████████████████████▉                   | 354/455 [08:27<02:25,  1.44s/ queries, google=82.77%, yours=70.62%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  rpofessor emeritus terry\n",
      "Query =  ['rpofessor', 'emeritus', 'terry']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████████████████████████████████████                   | 355/455 [08:28<02:05,  1.26s/ queries, google=82.82%, yours=70.70%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  center cerebrovascular neurosurgery epilepsy functional via palou david packard electrical\n",
      "Query =  ['center', 'cerebrovascular', 'neurosurgery', 'epilepsy', 'functional', 'via', 'palou', 'david', 'packard', 'electrical']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "I =  8\n",
      "I =  9\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████████████████████████████████████▎                  | 356/455 [08:32<03:34,  2.16s/ queries, google=82.87%, yours=70.79%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  and auditorum the\n",
      "Query =  ['and', 'auditorum', 'the']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████████████████████████████████████████▍                  | 357/455 [08:32<02:47,  1.71s/ queries, google=82.91%, yours=70.87%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  all subscribers who receive\n",
      "Query =  ['all', 'subscribers', 'who', 'receive']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████████████████▋                  | 358/455 [08:34<02:32,  1.58s/ queries, google=82.96%, yours=70.95%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  edit box set\n",
      "Query =  ['edit', 'box', 'set']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████████████████████████████████████████████████████████████████▊                  | 359/455 [08:34<01:56,  1.22s/ queries, google=83.01%, yours=71.03%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  stanford university webmaster cva\n",
      "Query =  ['stanford', 'university', 'webmaster', 'cva']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|████████████████████████████████████████████████████████████████████                  | 360/455 [08:36<02:02,  1.29s/ queries, google=83.06%, yours=71.11%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  2009 art nx 620\n",
      "Query =  ['2009', 'art', 'nx', '620']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|████████████████████████████████████████████████████████████████████▏                 | 361/455 [08:37<01:54,  1.22s/ queries, google=82.83%, yours=70.91%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  linear accelerator center\n",
      "Query =  ['linear', 'accelerator', 'center']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████▍                 | 362/455 [08:38<01:49,  1.17s/ queries, google=82.87%, yours=70.99%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  page and signins\n",
      "Query =  ['page', 'and', 'signins']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████▌                 | 363/455 [08:39<01:44,  1.13s/ queries, google=82.64%, yours=71.07%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  board for the\n",
      "Query =  ['board', 'for', 'the']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████▊                 | 364/455 [08:39<01:27,  1.05 queries/s, google=82.69%, yours=71.15%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  thoes free swimming tadpole like\n",
      "Query =  ['thoes', 'free', 'swimming', 'tadpole', 'like']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████▉                 | 365/455 [08:40<01:26,  1.05 queries/s, google=82.47%, yours=70.96%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  if they have\n",
      "Query =  ['if', 'they', 'have']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████████▏                | 366/455 [08:41<01:08,  1.30 queries/s, google=82.51%, yours=71.04%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  associate director of korean studies\n",
      "Query =  ['associate', 'director', 'of', 'korean', 'studies']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████████████████▎                | 367/455 [08:42<01:23,  1.05 queries/s, google=82.56%, yours=71.12%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  upper right corner if format kif and\n",
      "Query =  ['upper', 'right', 'corner', 'if', 'format', 'kif', 'and']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████████████████▌                | 368/455 [08:45<02:28,  1.70s/ queries, google=82.34%, yours=70.92%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  danyluk williams college john denero\n",
      "Query =  ['danyluk', 'williams', 'college', 'john', 'denero']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████████████████▋                | 369/455 [08:47<02:12,  1.54s/ queries, google=82.38%, yours=71.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  at stanford welcome\n",
      "Query =  ['at', 'stanford', 'welcome']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████████████████▉                | 370/455 [08:48<02:16,  1.60s/ queries, google=82.43%, yours=71.08%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  watson 98 trained civil\n",
      "Query =  ['watson', '98', 'trained', 'civil']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|██████████████████████████████████████████████████████████████████████                | 371/455 [08:49<01:53,  1.35s/ queries, google=82.48%, yours=71.16%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  terms call number series serchworks\n",
      "Query =  ['terms', 'call', 'number', 'series', 'serchworks']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|██████████████████████████████████████████████████████████████████████▎               | 372/455 [08:50<01:49,  1.32s/ queries, google=82.53%, yours=71.24%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  moedling for genome\n",
      "Query =  ['moedling', 'for', 'genome']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|██████████████████████████████████████████████████████████████████████▌               | 373/455 [08:51<01:32,  1.13s/ queries, google=82.57%, yours=71.31%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  & art hostory\n",
      "Query =  ['&', 'art', 'hostory']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|██████████████████████████████████████████████████████████████████████▋               | 374/455 [08:52<01:17,  1.05 queries/s, google=82.62%, yours=71.39%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  to see more program\n",
      "Query =  ['to', 'see', 'more', 'program']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|██████████████████████████████████████████████████████████████████████▉               | 375/455 [08:53<01:17,  1.04 queries/s, google=82.67%, yours=71.47%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  timing configuration the need to skip to main content home\n",
      "Query =  ['timing', 'configuration', 'the', 'need', 'to', 'skip', 'to', 'main', 'content', 'home']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "I =  8\n",
      "I =  9\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████████████████████████████████████████               | 376/455 [08:57<02:44,  2.08s/ queries, google=82.71%, yours=71.54%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  school learing sgsi 12 12\n",
      "Query =  ['school', 'learing', 'sgsi', '12', '12']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████████████████████████████████████████▎              | 377/455 [08:58<02:20,  1.81s/ queries, google=82.76%, yours=71.35%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the posting if\n",
      "Query =  ['the', 'posting', 'if']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████████████████████████████████████████▍              | 378/455 [08:59<01:49,  1.43s/ queries, google=82.80%, yours=71.43%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  choose the file you would\n",
      "Query =  ['choose', 'the', 'file', 'you', 'would']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████████████████████████████████████████▋              | 379/455 [09:00<01:39,  1.31s/ queries, google=82.85%, yours=71.50%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  scholar publishing sustainability suse open coordinator juilie green\n",
      "Query =  ['scholar', 'publishing', 'sustainability', 'suse', 'open', 'coordinator', 'juilie', 'green']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████████████████████████████████████████████▊              | 380/455 [09:03<02:19,  1.86s/ queries, google=82.63%, yours=71.32%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  standford university photo by fred\n",
      "Query =  ['standford', 'university', 'photo', 'by', 'fred']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████████████████              | 381/455 [09:05<02:09,  1.76s/ queries, google=82.68%, yours=71.13%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  here without your permission\n",
      "Query =  ['here', 'without', 'your', 'permission']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████████████████▏             | 382/455 [09:06<01:50,  1.52s/ queries, google=82.72%, yours=71.20%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  of nand into solidstate\n",
      "Query =  ['of', 'nand', 'into', 'solidstate']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████████████████▍             | 383/455 [09:07<01:36,  1.34s/ queries, google=82.77%, yours=71.02%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  drive suite 6 stanford califnornia\n",
      "Query =  ['drive', 'suite', '6', 'stanford', 'califnornia']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████████████████▌             | 384/455 [09:08<01:48,  1.53s/ queries, google=82.81%, yours=70.83%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  petersen milind purohit\n",
      "Query =  ['petersen', 'milind', 'purohit']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████████████████▊             | 385/455 [09:09<01:35,  1.36s/ queries, google=82.86%, yours=70.91%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  information center lane readingroom\n",
      "Query =  ['information', 'center', 'lane', 'readingroom']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████████████████████████████████████████████▉             | 386/455 [09:12<01:49,  1.59s/ queries, google=82.90%, yours=70.73%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  education action program\n",
      "Query =  ['education', 'action', 'program']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████████████████████████████████████████████████▏            | 387/455 [09:12<01:33,  1.38s/ queries, google=82.95%, yours=70.80%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  left and you should\n",
      "Query =  ['left', 'and', 'you', 'should']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████████████████████████████████████████████████▎            | 388/455 [09:13<01:19,  1.19s/ queries, google=82.99%, yours=70.88%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  to storeup\n",
      "Query =  ['to', 'storeup']\n",
      "I =  0\n",
      "I =  1\n",
      "dict_keys([0, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████████████████████████████████████████████████▌            | 389/455 [09:14<01:02,  1.06 queries/s, google=83.03%, yours=70.69%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  pulpation obesity &\n",
      "Query =  ['pulpation', 'obesity', '&']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████████▋            | 390/455 [09:14<00:59,  1.09 queries/s, google=83.08%, yours=70.77%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  is availble from many sources\n",
      "Query =  ['is', 'availble', 'from', 'many', 'sources']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████████▉            | 391/455 [09:16<01:03,  1.01 queries/s, google=83.12%, yours=70.84%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  of energy last update\n",
      "Query =  ['of', 'energy', 'last', 'update']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|██████████████████████████████████████████████████████████████████████████            | 392/455 [09:16<00:57,  1.10 queries/s, google=83.16%, yours=70.92%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  involved in neurotransmision by using\n",
      "Query =  ['involved', 'in', 'neurotransmision', 'by', 'using']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|██████████████████████████████████████████████████████████████████████████▎           | 393/455 [09:19<01:32,  1.49s/ queries, google=83.21%, yours=70.99%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  public lecures seminars and courses\n",
      "Query =  ['public', 'lecures', 'seminars', 'and', 'courses']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|██████████████████████████████████████████████████████████████████████████▍           | 394/455 [09:21<01:28,  1.45s/ queries, google=83.25%, yours=70.81%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  isn t configured to accomodate that were installed\n",
      "Query =  ['isn', 't', 'configured', 'to', 'accomodate', 'that', 'were', 'installed']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|██████████████████████████████████████████████████████████████████████████▋           | 395/455 [09:24<01:56,  1.93s/ queries, google=83.04%, yours=70.63%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  despite the cosmetic problems\n",
      "Query =  ['despite', 'the', 'cosmetic', 'problems']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|██████████████████████████████████████████████████████████████████████████▊           | 396/455 [09:25<01:39,  1.69s/ queries, google=83.08%, yours=70.71%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  does not provd such simulation policy the europecenter walter\n",
      "Query =  ['does', 'not', 'provd', 'such', 'simulation', 'policy', 'the', 'europecenter', 'walter']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "I =  8\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|███████████████████████████████████████████████████████████████████████████           | 397/455 [09:27<01:54,  1.97s/ queries, google=83.12%, yours=70.53%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  systems usacycling clifbar &\n",
      "Query =  ['systems', 'usacycling', 'clifbar', '&']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|███████████████████████████████████████████████████████████████████████████▏          | 398/455 [09:29<01:39,  1.74s/ queries, google=82.91%, yours=70.60%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  cedical record date of birth\n",
      "Query =  ['cedical', 'record', 'date', 'of', 'birth']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████████████████████████████▍          | 399/455 [09:30<01:29,  1.61s/ queries, google=82.96%, yours=70.43%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  byhtmlme pl\n",
      "Query =  ['byhtmlme', 'pl']\n",
      "I =  0\n",
      "I =  1\n",
      "dict_keys([0, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████████████████████████████▌          | 400/455 [09:30<01:08,  1.24s/ queries, google=82.75%, yours=70.25%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  over 1300 stanford\n",
      "Query =  ['over', '1300', 'stanford']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████████████████████████████▊          | 401/455 [09:31<01:00,  1.12s/ queries, google=82.79%, yours=70.32%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  id passwirds page for more\n",
      "Query =  ['id', 'passwirds', 'page', 'for', 'more']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████████████████████████████▉          | 402/455 [09:32<01:03,  1.20s/ queries, google=82.84%, yours=70.15%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  peru by studying\n",
      "Query =  ['peru', 'by', 'studying']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████████████████████████████████████████████▏         | 403/455 [09:33<00:51,  1.00 queries/s, google=82.88%, yours=70.22%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  moovies read more photo robert\n",
      "Query =  ['moovies', 'read', 'more', 'photo', 'robert']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████████████████████████████████████████████▎         | 404/455 [09:34<00:49,  1.03 queries/s, google=82.92%, yours=70.05%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  care overveiw community south on el camino\n",
      "Query =  ['care', 'overveiw', 'community', 'south', 'on', 'el', 'camino']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████████████████████████████████████████████▌         | 405/455 [09:36<01:03,  1.28s/ queries, google=82.96%, yours=69.88%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  no 2 june 2005\n",
      "Query =  ['no', '2', 'june', '2005']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████████████████████████████████████████████▋         | 406/455 [09:36<00:53,  1.08s/ queries, google=83.00%, yours=69.95%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  university department of history 450 please suggest a\n",
      "Query =  ['university', 'department', 'of', 'history', '450', 'please', 'suggest', 'a']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████████████████████████████████████████████████████████████████████████▉         | 407/455 [09:39<01:19,  1.66s/ queries, google=83.05%, yours=69.78%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  ipsoforum uncatergorized ipsofacto is an\n",
      "Query =  ['ipsoforum', 'uncatergorized', 'ipsofacto', 'is', 'an']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████████         | 408/455 [09:42<01:24,  1.80s/ queries, google=82.84%, yours=69.61%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  care for about 135\n",
      "Query =  ['care', 'for', 'about', '135']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████████▎        | 409/455 [09:43<01:10,  1.53s/ queries, google=82.89%, yours=69.68%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  by slac to members\n",
      "Query =  ['by', 'slac', 'to', 'members']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████████▍        | 410/455 [09:44<01:05,  1.46s/ queries, google=82.93%, yours=69.76%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  1979 113114 if\n",
      "Query =  ['1979', '113114', 'if']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████████▋        | 411/455 [09:44<00:50,  1.15s/ queries, google=82.73%, yours=69.59%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  those operations that the complier\n",
      "Query =  ['those', 'operations', 'that', 'the', 'complier']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████████████████████████████████████████████████████████████████████████▊        | 412/455 [09:46<00:52,  1.21s/ queries, google=82.77%, yours=69.42%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  archaeological prehistory and events events east\n",
      "Query =  ['archaeological', 'prehistory', 'and', 'events', 'events', 'east']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "dict_keys([0, 1, 2, 3, 4, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|██████████████████████████████████████████████████████████████████████████████        | 413/455 [09:48<01:04,  1.53s/ queries, google=82.81%, yours=69.49%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  york deffer lp plaintiff\n",
      "Query =  ['york', 'deffer', 'lp', 'plaintiff']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|██████████████████████████████████████████████████████████████████████████████▎       | 414/455 [09:49<01:00,  1.48s/ queries, google=82.85%, yours=69.57%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  years qalys results\n",
      "Query =  ['years', 'qalys', 'results']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|██████████████████████████████████████████████████████████████████████████████▍       | 415/455 [09:50<00:50,  1.27s/ queries, google=82.89%, yours=69.64%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  on facebook conncet the cloud bio slides\n",
      "Query =  ['on', 'facebook', 'conncet', 'the', 'cloud', 'bio', 'slides']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|██████████████████████████████████████████████████████████████████████████████▋       | 416/455 [09:52<01:00,  1.54s/ queries, google=82.93%, yours=69.71%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  transformations old buildings new\n",
      "Query =  ['transformations', 'old', 'buildings', 'new']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████████████████████████████▊       | 417/455 [09:54<01:03,  1.66s/ queries, google=82.97%, yours=69.78%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  723 1450 650 564\n",
      "Query =  ['723', '1450', '650', '564']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████████████       | 418/455 [09:56<01:00,  1.64s/ queries, google=83.01%, yours=69.86%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  navigational home education\n",
      "Query =  ['navigational', 'home', 'education']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████████████▏      | 419/455 [09:57<00:58,  1.62s/ queries, google=82.82%, yours=69.93%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  a 20 discount\n",
      "Query =  ['a', '20', 'discount']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████████████▍      | 420/455 [09:58<00:47,  1.35s/ queries, google=82.86%, yours=70.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  environment 2011 stanford\n",
      "Query =  ['environment', '2011', 'stanford']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████████████▌      | 421/455 [09:59<00:47,  1.39s/ queries, google=82.90%, yours=70.07%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  dsc_7433 dsc_7434 dsc_7435 dsc_7454 dsc_7461\n",
      "Query =  ['dsc_7433', 'dsc_7434', 'dsc_7435', 'dsc_7454', 'dsc_7461']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████████████▊      | 422/455 [10:01<00:47,  1.44s/ queries, google=82.94%, yours=70.14%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  column datatype null description\n",
      "Query =  ['column', 'datatype', 'null', 'description']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████████████▉      | 423/455 [10:02<00:44,  1.38s/ queries, google=82.98%, yours=70.21%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  undergraduate educater at stanford for\n",
      "Query =  ['undergraduate', 'educater', 'at', 'stanford', 'for']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|████████████████████████████████████████████████████████████████████████████████▏     | 424/455 [10:04<00:48,  1.57s/ queries, google=83.02%, yours=70.05%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  gift stanford home search this\n",
      "Query =  ['gift', 'stanford', 'home', 'search', 'this']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|████████████████████████████████████████████████████████████████████████████████▎     | 425/455 [10:05<00:43,  1.45s/ queries, google=83.06%, yours=70.12%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  the low enegry\n",
      "Query =  ['the', 'low', 'enegry']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████████████████████████████████████████████▌     | 426/455 [10:06<00:34,  1.20s/ queries, google=83.10%, yours=70.19%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  sliders lecture topic\n",
      "Query =  ['sliders', 'lecture', 'topic']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████████████████████████████████████████████▋     | 427/455 [10:07<00:28,  1.04s/ queries, google=82.90%, yours=70.26%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  520 galvez mall parkinf\n",
      "Query =  ['520', 'galvez', 'mall', 'parkinf']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████████████████████████████████████████████▉     | 428/455 [10:08<00:26,  1.01 queries/s, google=82.94%, yours=70.33%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  outlin choices are switched\n",
      "Query =  ['outlin', 'choices', 'are', 'switched']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████████████████     | 429/455 [10:09<00:25,  1.02 queries/s, google=82.98%, yours=70.40%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  fraternity ae phi sorority chabad\n",
      "Query =  ['fraternity', 'ae', 'phi', 'sorority', 'chabad']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████████▎    | 430/455 [10:10<00:26,  1.08s/ queries, google=82.79%, yours=70.23%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  ao recruiment talk\n",
      "Query =  ['ao', 'recruiment', 'talk']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████████▍    | 431/455 [10:11<00:23,  1.04 queries/s, google=82.83%, yours=70.07%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  1 1 htlm etc in\n",
      "Query =  ['1', '1', 'htlm', 'etc', 'in']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████████▋    | 432/455 [10:12<00:23,  1.01s/ queries, google=82.87%, yours=70.14%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  & masculinities race &\n",
      "Query =  ['&', 'masculinities', 'race', '&']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████████▊    | 433/455 [10:13<00:25,  1.16s/ queries, google=82.91%, yours=70.21%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  reserve material for current\n",
      "Query =  ['reserve', 'material', 'for', 'current']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|██████████████████████████████████████████████████████████████████████████████████    | 434/455 [10:15<00:25,  1.23s/ queries, google=82.95%, yours=70.28%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  atcc misc commesnts\n",
      "Query =  ['atcc', 'misc', 'commesnts']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████████████████████████████████████████████████▏   | 435/455 [10:15<00:21,  1.09s/ queries, google=82.99%, yours=70.34%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  posting which takes you\n",
      "Query =  ['posting', 'which', 'takes', 'you']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████████████████████████████████████████████████▍   | 436/455 [10:16<00:20,  1.06s/ queries, google=83.03%, yours=70.41%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  resources stanford university student affairs\n",
      "Query =  ['resources', 'stanford', 'university', 'student', 'affairs']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████████████████████████████████████████████████▌   | 437/455 [10:18<00:23,  1.33s/ queries, google=83.07%, yours=70.48%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  insitute for gender\n",
      "Query =  ['insitute', 'for', 'gender']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████████████████████████████████████████████████▊   | 438/455 [10:19<00:19,  1.15s/ queries, google=83.11%, yours=70.32%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  estate maps and records\n",
      "Query =  ['estate', 'maps', 'and', 'records']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████████████████████████████████████████████████▉   | 439/455 [10:20<00:18,  1.16s/ queries, google=83.14%, yours=70.39%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  role of adding value in\n",
      "Query =  ['role', 'of', 'adding', 'value', 'in']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████████▏  | 440/455 [10:21<00:17,  1.17s/ queries, google=83.18%, yours=70.45%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  yim and kuhan papa\n",
      "Query =  ['yim', 'and', 'kuhan', 'papa']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████████▎  | 441/455 [10:22<00:14,  1.03s/ queries, google=82.99%, yours=70.29%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  febuary 8 2012 5 30\n",
      "Query =  ['febuary', '8', '2012', '5', '30']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████████▌  | 442/455 [10:23<00:14,  1.08s/ queries, google=83.03%, yours=70.14%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  slac stanford eud hypernews user\n",
      "Query =  ['slac', 'stanford', 'eud', 'hypernews', 'user']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████████▋  | 443/455 [10:25<00:15,  1.26s/ queries, google=83.07%, yours=70.20%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  makes an application\n",
      "Query =  ['makes', 'an', 'application']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|███████████████████████████████████████████████████████████████████████████████████▉  | 444/455 [10:26<00:14,  1.30s/ queries, google=83.11%, yours=70.27%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  center for opportunity policy in\n",
      "Query =  ['center', 'for', 'opportunity', 'policy', 'in']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████████████  | 445/455 [10:28<00:13,  1.39s/ queries, google=83.15%, yours=70.34%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  college of veterinary nutrition\n",
      "Query =  ['college', 'of', 'veterinary', 'nutrition']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████████████▎ | 446/455 [10:29<00:12,  1.39s/ queries, google=83.18%, yours=70.40%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  developed the notion of a\n",
      "Query =  ['developed', 'the', 'notion', 'of', 'a']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████████████▍ | 447/455 [10:31<00:11,  1.43s/ queries, google=83.22%, yours=70.47%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  alternativecertification for students stanferd\n",
      "Query =  ['alternativecertification', 'for', 'students', 'stanferd']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████████████▋ | 448/455 [10:35<00:14,  2.08s/ queries, google=83.26%, yours=70.31%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  vcimage generate on\n",
      "Query =  ['vcimage', 'generate', 'on']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████████████████████████████████████████████████▊ | 449/455 [10:35<00:10,  1.69s/ queries, google=83.30%, yours=70.38%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  hp support website api doxygen documantation p04 06\n",
      "Query =  ['hp', 'support', 'website', 'api', 'doxygen', 'documantation', 'p04', '06']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "I =  5\n",
      "I =  6\n",
      "I =  7\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████████████████████████████████████████████████████████████████████████████████ | 450/455 [10:38<00:10,  2.10s/ queries, google=83.11%, yours=70.22%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  student research applications for\n",
      "Query =  ['student', 'research', 'applications', 'for']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████████████████████████████████████████████████████████████████████████████████▏| 451/455 [10:40<00:07,  1.91s/ queries, google=83.15%, yours=70.29%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  lower roughness surfaces curved pins\n",
      "Query =  ['lower', 'roughness', 'surfaces', 'curved', 'pins']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████████████████████████████████████████████████████████████████████████████████▍| 452/455 [10:41<00:05,  1.69s/ queries, google=83.19%, yours=70.35%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  room students and faculty search\n",
      "Query =  ['room', 'students', 'and', 'faculty', 'search']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "I =  4\n",
      "dict_keys([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████▌| 453/455 [10:42<00:03,  1.58s/ queries, google=83.22%, yours=70.42%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  jim pleased our\n",
      "Query =  ['jim', 'pleased', 'our']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████▊| 454/455 [10:43<00:01,  1.24s/ queries, google=83.04%, yours=70.26%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  to skin strain changes\n",
      "Query =  ['to', 'skin', 'strain', 'changes']\n",
      "I =  0\n",
      "I =  1\n",
      "I =  2\n",
      "I =  3\n",
      "dict_keys([0, 1, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 455/455 [10:43<00:00,  1.06s/ queries, google=83.08%, yours=70.33%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query =  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set verbose=True for debugging output\n",
    "# For reference, our implementation takes ~1 min, 40 sec to run and gets 82.42% accuracy\n",
    "dev_eval(cs, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='empirical'></a>\n",
    "## V. Task 2: Spelling Correction with Empirical Edit Costs (25%)\n",
    "\n",
    "\n",
    "### V.1. Improved Edit Probability Model\n",
    "\n",
    "Now that our spelling corrector is working correctly with a basic edit probability model, we will turn our attention to a somewhat more realistic approach to edit probabilities. In this task, we will learn these edit probabilities from the empirical error data provided in `data/training_set/edit1s.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V.1.1. Empirical Edit Costs\n",
    "\n",
    "As outlined in [Section III](#dataset) above, you have been given a list of query pairs that are precisely edit distance 1 from each other. The ﬁrst step for this task is to devise a simple algorithm to determine which speciﬁc edit exists between the two queries in each pair. By aggregating the counts of all such edits over all queries, you can estimate the probability of each individual edit. The edit probability calculation is described in more detail in the [lecture handout on spelling correction](http://web.stanford.edu/class/cs276/handouts/spell_correction.pdf). As an example, if you need to determine the probability of the letter 'e' being (mistakenly) replaced by the letter 'a' in a query, you should calculate:\n",
    "$$\n",
    "    P(\\texttt{sub}[a, e]) = \\frac{\\texttt{count}(\\texttt{sub}[a, e])}{\\texttt{count}(e)}.\n",
    "$$\n",
    "Note that the insertion and deletion operator probabilities are conditioned on the character before the character being operated on &mdash; which also means that you should devise an appropriate solution to handle the special case of insertions or deletions occurring at the beginning of a word. Finally, to account for the inevitable problem of data sparsity in our edit training ﬁle, you should apply Laplace add-one smoothing to the edit probabilities, as described in the lecture handout (linked above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tee submission/empirical_edit_probability_model.py\n",
    "\n",
    "class Edit:\n",
    "    \"\"\"Represents a single edit in Damerau-Levenshtein distance.\n",
    "    We use this class to count occurrences of different edits in the training data.\n",
    "    \"\"\"\n",
    "    INSERTION = 1\n",
    "    DELETION = 2\n",
    "    TRANSPOSITION = 3\n",
    "    SUBSTITUTION = 4\n",
    "\n",
    "    def __init__(self, edit_type, c1=None, c2=None):\n",
    "        \"\"\"\n",
    "        Members:\n",
    "            edit_type (int): One of Edit.{NO_EDIT,INSERTION,DELETION,\n",
    "                TRANSPOSITION,SUBSTITUTION}.\n",
    "            c1 (str): First (in original) char involved in the edit.\n",
    "            c2 (str): Second (in original) char involved in the edit.\n",
    "        \"\"\"\n",
    "        self.edit_type = edit_type\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "\n",
    "\n",
    "class EmpiricalEditProbabilityModel(BaseEditProbabilityModel):\n",
    "\n",
    "    START_CHAR = ''      # Used to indicate start-of-query\n",
    "    NO_EDIT_PROB = 0.92  # Hyperparameter for probability assigned to no-edit\n",
    "\n",
    "    def __init__(self, training_set_path='pa2-data/training_set/edit1s.txt'):\n",
    "        \"\"\"Builds the necessary data structures to compute log-probabilities of\n",
    "        distance-1 edits in constant time. In particular, counts the unigrams\n",
    "        (single characters), bigrams (of 2 characters), alphabet size, and\n",
    "        edit count for insertions, deletions, substitutions, and transpositions.\n",
    "\n",
    "        Hint: Use the `Edit` class above. It may be easier to write the `get_edit`\n",
    "        function first, since you should call that function here.\n",
    "\n",
    "        Note: We suggest using tqdm with the size of the training set (819722) to track\n",
    "        the initializers progress when parsing the training set file.\n",
    "\n",
    "        Args:\n",
    "            training_set_path (str): Path to training set of empirical error data.\n",
    "        \"\"\"\n",
    "        # Your code needs to initialize all four of these data structures\n",
    "        self.unigram_counts = Counter()  # Maps chars c1 -> count(c1)\n",
    "        self.bigram_counts = Counter()   # Maps tuples (c1, c2) -> count((c1, c2))\n",
    "        self.alphabet_size = 0           # Counts all possible characters\n",
    "\n",
    "        # Maps edit-types -> dict mapping tuples (c1, c2) -> count(edit[c1, c2])\n",
    "        # Example usage: \n",
    "        #   > e = Edit(Edit.SUBSTITUTION, 'a', 'b')\n",
    "        #   > edit_count = self.edit_counts[e.edit_type][(e.c1, e.c2)]\n",
    "        self.edit_counts = {edit_type: Counter()\n",
    "                            for edit_type in (Edit.INSERTION, Edit.DELETION,\n",
    "                                              Edit.SUBSTITUTION, Edit.TRANSPOSITION)}\n",
    "\n",
    "        with open(training_set_path, 'r') as training_set:\n",
    "            for example in tqdm(training_set, total=819722):\n",
    "                edited, original = example.strip().split('\\t')\n",
    "\n",
    "                ### Begin your code\n",
    "\n",
    "                ### End your code\n",
    "\n",
    "    def get_edit(self, edited, original):\n",
    "        \"\"\"Gets an `Edit` object describing the type of edit performed on `original`\n",
    "        to produce `edited`.\n",
    "\n",
    "        Note: Only edits with an edit distance of at most 1 are valid inputs.\n",
    "\n",
    "        Args:\n",
    "            edited (str): Raw query, which contains exactly one edit from `original`.\n",
    "            original (str): True query. Want to find the edit which turns this into `edited`.\n",
    "\n",
    "        Returns:\n",
    "            edit (Edit): `Edit` object representing the edit to apply to `original` to get `edited`.\n",
    "                If `edited == original`, returns None.\n",
    "        \"\"\"\n",
    "        ### Begin your code\n",
    "\n",
    "        ### End your code\n",
    "\n",
    "    def get_edit_logp(self, edited, original):\n",
    "        \"\"\"Gets the log-probability of editing `original` to arrive at `edited`.\n",
    "        The `original` and `edited` arguments are both single terms that are at\n",
    "        most one edit apart.\n",
    "        \n",
    "        Note: The order of the arguments is chosen so that it reads like an\n",
    "        assignment expression:\n",
    "            > edited := EDIT_FUNCTION(original)\n",
    "        or, alternatively, you can think of it as a (unnormalized) conditional probability:\n",
    "            > log P(edited | original)\n",
    "\n",
    "        Args:\n",
    "            edited (str): Edited term.\n",
    "            original (str): Original term.\n",
    "\n",
    "        Returns:\n",
    "            logp (float): Log-probability of `edited` given `original`\n",
    "                under this `EditProbabilityModel`.\n",
    "        \"\"\"\n",
    "        ### Begin your code\n",
    "\n",
    "        ### End your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cells to evaluate your spelling corrector on the dev set using your empirical edit probability model. We will also evaluate your model on a private test set after submission. For full credit, your spelling corrector with uniform edit probability model should achieve accuracy within 1% of the staff implementation *on the test set.* **We do not provide test set queries, but as a guideline for performance, the staff implementation gets 87.91% accuracy on the dev set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build spelling corrector for evaluation on the dev set\n",
    "# For reference, our initialization times are 25 sec for lm, and 1 min, 40 sec for epm\n",
    "lm = LanguageModel()\n",
    "epm = EmpiricalEditProbabilityModel()\n",
    "cg = CandidateGenerator(lm, epm)\n",
    "cs = CandidateScorer(lm, cg, mu=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set verbose=True for debugging output\n",
    "# For reference our implementation takes ~2 min, 30 sec to run and gets 87.91% accuracy\n",
    "dev_eval(cs, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='written'></a>\n",
    "## VI. Written Report (20%)\n",
    "\n",
    "Be sure to document any design decisions you made, and give some brief rationale for them. Please keep your report concise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VI.1. Overall System Design (5%)\n",
    "\n",
    "Provide a concise (at most 5 sentences) description of the overall system design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  > Your Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VI.2. Smoothing and Related Techniques (5%)\n",
    "\n",
    "Give a short analysis of smoothing techniques used in this assignment. For example, you might produce a plot comparing different values for $\\lambda$ in unigram-bigram interpolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  > Your Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VI.3. Optimizations for Candidate Generation (5%)\n",
    "\n",
    "Provide a brief description of the techniques you used for optimizing candidate generation. Be sure to include an analysis of the amount by which each optimization sped up the overall spelling correction system, as well as any changes in accuracy you were able to measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  > Your Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VI.4. Tuning Parameters (5%)\n",
    "Provide at least two plots showing how accuracy varies as you change parameter values (*e.g.,* $\\mu$ and $\\lambda$). Comment briefly (1-2 sentences) on each plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  > Your Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='extra'></a>\n",
    "## VII. Extra Credit (Optional, up to 10%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have listed a few ideas here, but really any extensions that go above and beyond the scope of tasks 1 and 2 will be considered.\n",
    "\n",
    "1. **Expanded edit model.** We saw (or will see) in lecture that there are sometimes spelling errors that may not be within a \"naive\" edit distance 2 of the correct phrase, but that may have a conceptual basis that makes them very common and understandable. (Substituting 'ph' for 'f', or vice versa, is one such example.) Can you incorporate these types of errors into the edit probabilities of your edit probability model?\n",
    "2. **Empirical edit costs using Wikipedia.** In task 2, you used the dataset of queries 1 edit distance apart to learn edit probabilities. If you look at the queries in this dataset, you will observe that most of these queries are related to the Stanford corpus, the same corpus used to build the language model. It would be interesting to explore what happens if the channel model and language model are learned from diﬀerent datasets (and hence diﬀerent distributions of the underlying data). To this end, you can use a dataset of spelling errors collected from Wikipedia and available on Peter Norvig’s website (http://norvig.com/ngrams/spell-errors.txt).\n",
    "3. **Alternate Smoothing.** Try other smoothing algorithms (such as Kneser-Ney smoothing) to better capture probabilities in the training corpus.\n",
    "4. **K-gram index.** To deal with unseen words, it is possible to develop a measure for the probability of that word being spelled correctly by developing a character k-gram index over your corpus. For example, a q not followed by a u should lead to a low probability. This index can also help you generate candidate corrections much more eﬃciently.\n",
    "5. **Levenshtein Automata.** You can do even faster candidate generation using a Levenshtein transducer (http://en.wikipedia.org/wiki/Levenshtein_transducer), which uses a ﬁnite state automata for fuzzy matching of words. There is an experimental implementation in Python at https://gist.github.com/491973, but it needs to be generalized to perform the transposition operation too. This tutorial might be helpful: http://blog.notdot.net/2010/07/Damn-Cool-Algorithms-Levenshtein-Automata.\n",
    "\n",
    "Finally, we will give a small amount of extra credit to the best spell correction systems, measured in terms of both accuracy and running time (as computed on our hidden test data). The top 5 systems according to either metric will receive 5% each, while the next 15 systems will receive 2.5% each.\n",
    "\n",
    "**If you decide to tackle an extra credit option, give a brief description of your approach and results below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  > Your Answer Here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
